{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb02fa04-9945-45ed-8595-9c14f719ae0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import json \n",
    "import gradio as gr\n",
    "from user_info import get_user_info\n",
    "import ast, html, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29522113-015b-4a8f-80d0-8ff050771f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/ubuntu/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login(token='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')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3dfba82-e515-4863-a254-6583b990c843",
   "metadata": {},
   "source": [
    "## Download PEFT Model Config and Merge with Base Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ca54ec7-4537-4db9-8657-6d38964bfe1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LlamaForCausalLM\n",
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "peft_model_id = \"lakshay/work-details-peft\"\n",
    "config = PeftConfig.from_pretrained(peft_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755c117a-f9f9-4d7b-8216-25e53aaeabe2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91f0e4f0-aa84-40d3-96c0-9d8e5bee16c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "833a1a6702a84a06ab4f6ca907545ed9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import LlamaForCausalLM\n",
    "from peft import PeftModel\n",
    "\n",
    "base_model = LlamaForCausalLM.from_pretrained('meta-llama/Llama-2-7b-chat-hf')\n",
    "peft_model_id = \"lakshay/work-details-peft\"\n",
    "model = PeftModel.from_pretrained(base_model, peft_model_id)\n",
    "merged_model = model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819760b7-34fc-406a-b736-1dd8ebe29535",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7406c73c-d99f-4e73-8e37-16ef4f6e6736",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LlamaTokenizer\n",
    "tokenizer = LlamaTokenizer.from_pretrained('lakshay/work-details')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea23e0b6-0baa-420d-be42-07bc2730f615",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e3fffb-a589-4a0f-9ad1-72fe1b1957a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a67c0c3-cce5-484e-9e4b-2f629618d608",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8061e49e-52f3-4c33-a6c8-91b3f004d1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling_params = SamplingParams(temperature=0, max_tokens=4096)\n",
    "# llm = LLM(model='../tmp/work-details-merged-model',tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a361244-919d-48ea-9301-ed9ca6b44e7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b8b90e7-ace3-4bfe-abff-1ac57fca8989",
   "metadata": {},
   "source": [
    "### Download work-details model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bed3a78-b983-46e5-8630-66bf57bff02a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 01-22 16:01:33 llm_engine.py:73] Initializing an LLM engine with config: model='lakshay/work-details', tokenizer='lakshay/work-details', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=1, quantization=None, enforce_eager=False, seed=0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85a95fa561eb4cd89c68a1fb46978131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00006.safetensors:   0%|          | 0.00/4.86G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2518f43c51a4a61a29fc7e4dedb0f57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00006.safetensors:   0%|          | 0.00/4.86G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07b1550556914b63a948bad505eff630",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00006.safetensors:   0%|          | 0.00/4.86G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7a0482de2c743558616bc7cd24538a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00006-of-00006.safetensors:   0%|          | 0.00/2.68G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a3fa2d96d4f426cbe950713f96904ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00006.safetensors:   0%|          | 0.00/4.84G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6c62b5476a5439dbdcbb31f8a6dbdaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00005-of-00006.safetensors:   0%|          | 0.00/4.86G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sampling_params = SamplingParams(temperature=0, max_tokens=4096)\n",
    "llm = LLM(model='lakshay/work-details')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097b27b8-f4a9-4576-b70d-0b4777918554",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499bb847-98a8-4b6c-8ce9-3a79343c6a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = pd.read_csv('custom_data/iimjobs_eval_df.csv')\n",
    "\n",
    "def convert_to_json(input_string):\n",
    "    # Replace single quotes at the start and end of keys and values with double quotes\n",
    "    # This regex specifically targets the start of keys/values and the end of keys/values\n",
    "    corrected_string = re.sub(r\"(\\{|\\,)\\s*\\'\", r'\\1 \"', input_string)  # Start of key/value\n",
    "    corrected_string = re.sub(r\"\\'\\s*(\\,|\\})\", r'\" \\1', corrected_string)  # End of key/value\n",
    "    corrected_string = re.sub(r\"\\'\\s*:\", r'\":', corrected_string)  # Key end\n",
    "    corrected_string = re.sub(r\":\\s*\\'\", r': \"', corrected_string)  # Value start\n",
    "\n",
    "    try:\n",
    "        # Convert the string to a valid JSON\n",
    "        valid_json = json.loads(corrected_string)\n",
    "        print(f'it worked!')\n",
    "        return valid_json\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f'Error thrown in JSON converter is {e}')\n",
    "        return input_string\n",
    "\n",
    "def make_eval_prompt(raw_text):\n",
    "    \n",
    "    \n",
    "    work_prompt = f'''\n",
    "    You are an accurate agent working for a job platform. You will be given the raw \n",
    "    unstructured text of a user's resume, and the task is to extract only the following details about the \n",
    "    work experience of the user from the resume in a JSON style format: company name, designation, start date and the end date.\n",
    "    Please provide the data in a concise and parseable JSON format. Ensure the JSON syntax is correct\n",
    "    with proper use of double quotes, commas, and braces. Dates should be in \"mm/yyyy\" format\n",
    "\n",
    "    This is the resume text:\\n{{resume_text}}\\n\n",
    "    This is the output in the required_format:\\n\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    eval_prompt = eval_prompt.format(resume_text=raw_text)\n",
    "\n",
    "    return eval_prompt\n",
    "\n",
    "def parse_user_work_ex(info_json):\n",
    "    work_ex = []\n",
    "    try:\n",
    "        for x in info_json['professional_info'][0]:\n",
    "            \n",
    "            user_dict = {}\n",
    "            exp_dict = x\n",
    "        \n",
    "            keys = ['id','designation','fromExpMonth','fromExpYear','toExpMonth','toExpYear'] \n",
    "        \n",
    "            for k in keys:\n",
    "                user_dict[k] = exp_dict[k]\n",
    "                \n",
    "            user_dict['company'] = exp_dict['organization']['name']\n",
    "            work_ex.append(user_dict)\n",
    "    except:\n",
    "        return work_ex\n",
    "            \n",
    "    return work_ex\n",
    "\n",
    "\n",
    "\n",
    "def get_response_from_model(user_id):\n",
    "\n",
    "    es_output = get_user_info(user_id)\n",
    "    resume_text = es_output['resume'][0]\n",
    "    work_ex = parse_user_work_ex(es_output)\n",
    "    if resume_text:\n",
    "        eval_prompt = make_eval_prompt(resume_text)\n",
    "    \n",
    "    outputs = llm.generate(eval_prompt, sampling_params)\n",
    "    out_text = outputs[0].outputs[0].text\n",
    "    ot = html.unescape(out_text)\n",
    "    generated_text = ot\n",
    "    \n",
    "    try:\n",
    "        out_json = ast.literal_eval(generated_text)\n",
    "        return json.dumps(out_json,indent=4), json.dumps(work_ex,indent=4)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'couldnt JSONify this {e}')\n",
    "        gt = convert_to_json(generated_text)\n",
    "        return json.dumps(gt, indent=4), json.dumps(work_ex,indent=4)\n",
    "\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=get_response_from_model,\n",
    "    inputs=[gr.Textbox(label=\"UserID\")],\n",
    "    outputs=[gr.Textbox(label=\"LLM Output\"),gr.Textbox(label=\"User Info from ElasticSearch\")],\n",
    "    allow_flagging=\"manual\"\n",
    ")\n",
    "\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1482bc8d-88e1-4ab1-b835-a0a61214d9ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
