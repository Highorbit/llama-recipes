{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# llama-recipes/src/llama_recipes/utils/dataset_utils.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 1: Load the model\n",
    "\n",
    "Point model_id to model weight folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "train_data = load_from_disk(\"custom_data/phi2/workex_shell.hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jan 10 16:30:57 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A10G                    Off | 00000000:00:1E.0 Off |                    0 |\n",
      "|  0%   29C    P0              55W / 300W |      4MiB / 23028MiB |      4%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/ubuntu/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login(token='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Important \n",
    "\n",
    "It is important to consider here which model we're using to parse the resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e41d6bcdb784801be043089689d370f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/phi-2\", torch_dtype=\"auto\", trust_remote_code=True,device_map='auto',)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-2\", trust_remote_code=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jan 10 16:31:10 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A10G                    Off | 00000000:00:1E.0 Off |                    0 |\n",
      "|  0%   30C    P0              59W / 300W |   5626MiB / 23028MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      9496      C   ...oedge/llama-recipes/env/bin/python3     5614MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# inputs = tokenizer('''def print_prime(n):\n",
    "#    \"\"\"\n",
    "#    Print all primes between 1 and n\n",
    "#    \"\"\"''', return_tensors=\"pt\", return_attention_mask=False)\n",
    "\n",
    "# outputs = model.generate(**inputs, max_length=200)\n",
    "# text = tokenizer.batch_decode(outputs)[0]\n",
    "# print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from transformers import LlamaForCausalLM, LlamaTokenizer\n",
    "\n",
    "# model_id=\"meta-llama/Llama-2-7b-chat-hf\"\n",
    "\n",
    "# tokenizer = LlamaTokenizer.from_pretrained(model_id)\n",
    "\n",
    "# model = LlamaForCausalLM.from_pretrained(model_id, load_in_8bit=True, device_map='auto', torch_dtype=torch.float16, token='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.append('/home/ec2-user/SageMaker/llama_root/src')\n",
    "sys.path.append('../llama-recipes/src/llama_recipes/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Check base model\n",
    "\n",
    "Run the base model on an example input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "eval_prompt = f'''\n",
    "You are an accurate agent working for a job platform. You will be given the raw \n",
    "unstructured text of a user's resume, and the task is to extract the details about the work experience of the \n",
    "user from the resume. Please provide the data in a concise JSON format. The JSON should include a \n",
    "\"work_experience\" key with an array of objects. Each object represents a job and should contain keys for \n",
    "\"company\", \"role\", \"start_date\", \"end_date\". Dates should be in \"mm/yyyy\" format. \n",
    "Ensure the JSON syntax is correct, with proper use of quotes, commas, and braces. Here is an example structure::\n",
    "\n",
    "Please follow this structure closely and keep the response within the token limit.\" \\n{{query_format}}\\n\n",
    "\n",
    "This is the resume text:\\n{{resume_text}}\\n\n",
    "This is the output in the required_format:\\n\n",
    "'''\n",
    "\n",
    "work_format = '''\n",
    "[\n",
    "    {\"company\":\"Example Company 1\",\n",
    "    \"role\":\"Example Role 1\",\n",
    "    \"start_date\":\"mm/yyyy\",\n",
    "    \"end_date\":\"mm/yyyy\"},\n",
    "    {\"company\":\"Example Company 2\",\n",
    "    \"role\":\"Example Role 2\",\"\n",
    "    start_date\":\"mm/yyyy\",\n",
    "    \"end_date\":\"mm/yyyy\"}\n",
    "]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "example_resume_text = '''\n",
    " S\\n EVANAND\\n\\n\\nEmail: sevaanand863@gmail.com\\nMobile: +919110416415\\n\\n\\nPROFESSIONAL SUMMARY:\\n Having 2+ years of technical experience in Analysis, Design, Development, Testing\\n and Implementation of Client Server Application and Data warehousing ETL (Extract,\\n Transform and Load) in Informatica Power Center 10.4 and INFORMATICA intelligent\\n cloud services.\\n Main areas of expertise are Developing and Testing the data warehousing\\n projects with data quality standards.\\n Extensive experience in Extraction, Transformation and Loading of data\\n directly from heterogeneous source systems like fat fles, Oracle by using\\n Informatica power center.\\n Tuned several mappings for the better performance and involved in Performance\\n Testing.\\n Implemented exceptional handling mechanism by using Exception transformation &amp;\\n Human Task.\\n Creating Informatica IICS mappings for the diferent plans using various\\n transformations.\\n Have working experience in Informatica Intelligent Cloud Services IICS components -\\n application integration, data integration, Informatica data quality and Informatica\\n power center and CRM application - Salesforce.\\n Worked on SCD Type1,SCD Type2 in IICS\\n Worked on Mapping, Mapping Task, Mapplet, Task Flows\\n Experience on all important General transformations.\\n Used informatica developer tool to develop the mapping with power center\\n transformations.\\n Customized SQL override queries where ever possible to minimize the use of Joiner,\\n Aggregator and Lookup Transformations.\\n Developed all the mappings according to the design document and mapping specs\\n provided and performed unit testing.\\n Used Parameterization for Mapping, Workfows and sessions.\\n Worked on running &amp; scheduling the Informatica jobs using Shell Scripts written on\\n the UNIX box.\\n Error handling &amp; issue analysis during the testing and maintenance.\\n Hands on dynamic parameter fle creation.\\n Identifying the bottlenecks and implement the Performance tuning &amp;\\n Optimization techniques in power center.\\n Review and initial approval for various Docs like IDS, IRS, PDI, KEDB, Mapping\\n sheets.\\n Good Knowledge on Data Warehousing concepts like Star Schema, Dimensions\\n and Fact tables.\\n Optimizing Informatica Mappings and Sessions to improve the performance.\\n Experience of handling slowly changing dimensions to maintain complete\\n history using Type I, Type II and Type III strategies.\\n Created UNIX Shell scripts to run the Informatica Workfows &amp; controlling the ETL\\n fow.\\n Hands on Admin activities.\\n Excellent problem-solving skills with strong technical background and good\\n interpersonal skills.\\n\\n\\n\\n\\nEXPERIENCE SUMMARY:\\n, Worked as a Programmer Analyst with COGNIZANT from Jan 2022 to April 2023.\\n\\n Worked as a Software Engineer with Birla Soft LTD from Jan 2021 to Jan 2022.\\n\\n\\n\\n\\n TECHNICAL ENVIRONMENT:\\nOperating System : Windows, Linux\\nTools : Informatica developer, IICS, PUTTY, SQL Developer and WinSCP\\nRDBMS : Oracle ,SQL, PostgreSQL\\nLanguages : Unix,\\nScheduling Tools : Autosys, Control-M\\n\\n\\n\\n PROJECT PROFILE:\\n\\n\\n #PROJECT 1\\n\\n Client : Verizon\\n Project Name : HR Union Recruit in\\n Domain : Telecom\\n Role : IICS Developer\\n Environment : IICS, Oracle 11g, PostgreSQL , Windows 10\\n\\nProject Description:\\n The Project HR Union involves the migration of severance&rsquo;s data in PeopleSoft to\\nPostgreSQL.\\n\\nInformatica Cloud&rsquo;s Data Integration Services consume the Data from Peoplesoft system\\nand perform the\\n\\nbusiness logic to load in Severance&rsquo;s database (PostgreSQL) and then provide the data to\\ndownstream\\n\\nvendors in the form of Files.\\n Responsibilities:\\n\\n Creating Informatica IICS mappings for the diferent plans using various\\n transformations.\\n Have working experience in Informatica Intelligent Cloud Services IICS\\n components - application integration, data integration, Informatica data quality\\n and Informatica power center and CRM application - Salesforce.\\n Analysis of the specifcations provided by the clients.\\n Used Various Transformations such as Sorted, Lookup, Joiner, Aggregator,\\n Sequence Generator. Lookup, Normalizer, Transaction Control Transformation.\\n Worked on Diferent tasks like Mapping Task Replication Task, Synchronization\\n Task, Power Center Task in IICS.\\n Designed, Developed and implemented ETL Processes using IICS Data\\n Integration\\n Created IICS connection using various cloud connectors in IICS Administrator\\n Extensively used informatica IICS&ndash; Mapping, Mapping Task, Task Flow.\\n, Developed complex mappings using transformations such as the Source\\n qualifer, Joiner, Aggregator, Update Strategy, Expression, Connected Lookup,\\n Unconnected Lookup and Router transformations.\\n Created informatica mappings for stage, Dimensions and Fact table loads.\\n Created SCD type-1 and type-2 mappings for loading the dimension tables.\\n Done extensive testing and wrote queries in SQL to ensure the loading of the\\n data.\\n Developed and implemented the coding of Informatica Mapping for the\\n diferent stages of ETL.\\n Involved in Unit testing\\n On-time Production migration without defects\\n Involved in Post production Support.\\n\\n\\n\\n\\n#Project 2\\n\\n Client : Discover Fin bank\\n Domain : Banking\\n Environment : Informatica power center 9.X, Oracle10g\\n Role : Informatica Support and Developer\\n\\n\\n\\nDISCRIPTIOIN:\\n\\n This application was designed to load member and subscriber eligibility information\\nas received from the customers in the form of fat fles and oracle database. The system\\nwas designed to store the eligibility information of the members belonging to the various\\ncontracts for the various vendor customer services being provided to them by the client.\\nIt was used to store the historical information pertaining to each and every member who\\nwas entitled to receive the customer services. The various other front-end applications\\nwould access this database to determine the authenticity of the members and the type of\\nservices they were entitled to the system.\\nResponsibilities:\\n\\n Understanding existing business model and customer requirements.\\n Understanding the mapping specifcations and requirements.\\n Managing priorities of tasks, scheduling and tracking progress.\\n Extraction of data from various sources using Informatica.\\n Designed various mappings for extracting data from various sources involving fat\\n fles and relational tables.\\n Used Source Analyzer and Warehouse Designer to import the source and target\\n database schemas and the mapping designer to map source to the target.\\n Used Transformation Developer to create the flters, joiner, update strategy, lookups\\n and\\n Aggregation transformations, which are used in mappings.\\n Created various tasks like sessions, worklets, and workfows in the workfow\\n manager to test the mapping during development.\\n To keep track of historical data slowly changing dimensions are implemented.\\n Created and Monitored Batches and Sessions using Informatica Power Centre.\\n Created and executed sessions and batches using Server Manager.\\n Worked with Mapping Variables and Mapping Parameters.\\n Developed all the mappings according to the design document and mapping specs\\n provided and performed unit testing.\\n, Created test plan, Test Design, Test scripts and responsible for implementation of\\n Test cases as Manual test scripts.\\n Developed mapping to load the data in slowly changing dimension.\\n Checked the output according to the specifcations.\\n Confgured and ran the Debugger from within the Mapping Designer to troubleshoot\\n the mapping before the normal run of the workfow.\\n Tuned several mappings for the better performance and involved in Performance\\n Testing.\\n Documenting test cases and Informatica mappings\\n Prepared documentation for business data fow from source to target and also for\\n the changes made to the mappings/sessions existing to eliminate the errors.\\n Provide weekly status report to the Project Manager and discuss issues related to\\n quality and deadlines.'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ep = eval_prompt.format(resume_text=example_resume_text, query_format=work_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from transformers import TextStreamer\n",
    "\n",
    "# model_input = tokenizer(ep,return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     print(tokenizer.decode(model.generate(**model_input, max_new_tokens=1024)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "We can see that the base model only repeats the conversation.\n",
    "\n",
    "### Step 4: Prepare model for PEFT\n",
    "\n",
    "Let's prepare the model for Parameter Efficient Fine Tuning (PEFT):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.train()\n",
    "\n",
    "# def create_peft_config(model):\n",
    "#     from peft import (\n",
    "#         get_peft_model,\n",
    "#         LoraConfig,\n",
    "#         TaskType,\n",
    "#         prepare_model_for_int8_training,\n",
    "#     )\n",
    "\n",
    "#     peft_config = LoraConfig(\n",
    "#         task_type=TaskType.CAUSAL_LM,\n",
    "#         inference_mode=False,\n",
    "#         r=64,\n",
    "#         lora_alpha=32,\n",
    "#         lora_dropout=0.05,\n",
    "#         target_modules = [\"q_proj\", \"v_proj\"]\n",
    "#     )\n",
    "    \n",
    "#     # peft_config = LoraConfig(\n",
    "#     #     task_type=TaskType.CAUSAL_LM,\n",
    "#     #     inference_mode=False,\n",
    "#     #     r=8,\n",
    "#     #     lora_alpha=32,\n",
    "#     #     lora_dropout=0.05,\n",
    "#     #     target_modules = [\"q_proj\", \"v_proj\"]\n",
    "#     # )\n",
    "\n",
    "#     # prepare int-8 model for training\n",
    "#     model = prepare_model_for_int8_training(model)\n",
    "#     model = get_peft_model(model, peft_config)\n",
    "#     model.print_trainable_parameters()\n",
    "#     return model, peft_config\n",
    "\n",
    "# # create peft config\n",
    "# model, lora_config = create_peft_config(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/peft/utils/other.py:141: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 15,728,640 || all params: 2,795,412,480 || trainable%: 0.5626590033682615\n"
     ]
    }
   ],
   "source": [
    "from peft import (\n",
    "        get_peft_model,\n",
    "        LoraConfig,\n",
    "        TaskType,\n",
    "        prepare_model_for_int8_training)\n",
    "\n",
    "peft_config = LoraConfig(r=8,lora_alpha=16,\n",
    "                         target_modules=['Wqkv','out_proj'],\n",
    "                         bias=\"none\",\n",
    "                         lora_dropout=0.05, # Conventional\n",
    "                         task_type=\"CAUSAL_LM\")\n",
    "\n",
    "model = prepare_model_for_int8_training(model)\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Step 5: Define an optional profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import TrainerCallback\n",
    "from contextlib import nullcontext\n",
    "enable_profiler = False\n",
    "output_dir = \"tmp/linear_workex\"\n",
    "\n",
    "config = {\n",
    "    'lora_config': peft_config,\n",
    "    'learning_rate': 1e-4,\n",
    "    'num_train_epochs': 1,\n",
    "    'gradient_accumulation_steps': 2,\n",
    "    'per_device_train_batch_size': 2,\n",
    "    'gradient_checkpointing': False,\n",
    "}\n",
    "\n",
    "# Set up profiler\n",
    "if enable_profiler:\n",
    "    wait, warmup, active, repeat = 1, 1, 2, 1\n",
    "    total_steps = (wait + warmup + active) * (1 + repeat)\n",
    "    schedule =  torch.profiler.schedule(wait=wait, warmup=warmup, active=active, repeat=repeat)\n",
    "    profiler = torch.profiler.profile(\n",
    "        schedule=schedule,\n",
    "        on_trace_ready=torch.profiler.tensorboard_trace_handler(f\"{output_dir}/logs/tensorboard\"),\n",
    "        record_shapes=True,\n",
    "        profile_memory=True,\n",
    "        with_stack=True)\n",
    "    \n",
    "    class ProfilerCallback(TrainerCallback):\n",
    "        def __init__(self, profiler):\n",
    "            self.profiler = profiler\n",
    "            \n",
    "        def on_step_end(self, *args, **kwargs):\n",
    "            self.profiler.step()\n",
    "\n",
    "    profiler_callback = ProfilerCallback(profiler)\n",
    "else:\n",
    "    profiler = nullcontext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jan 10 08:04:27 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.12             Driver Version: 535.104.12   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A10G                    On  | 00000000:00:1E.0 Off |                    0 |\n",
      "|  0%   21C    P0              55W / 300W |  15310MiB / 23028MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A     29768      C   ...r/anaconda3/envs/python3/bin/python    15302MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Fine tune the model\n",
    "\n",
    "Here, we fine tune the model for a single epoch which takes a bit more than an hour on a A100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1024.00 MiB. GPU 0 has a total capacty of 22.19 GiB of which 449.50 MiB is free. Including non-PyTorch memory, this process has 21.74 GiB memory in use. Of the allocated memory 20.70 GiB is allocated by PyTorch, and 761.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 29\u001b[0m\n\u001b[1;32m     20\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     21\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     22\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[profiler_callback] \u001b[38;5;28;01mif\u001b[39;00m enable_profiler \u001b[38;5;28;01melse\u001b[39;00m [],\n\u001b[1;32m     26\u001b[0m )\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Start training\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/trainer.py:1537\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1535\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1537\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1538\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1539\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1540\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1542\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/trainer.py:1854\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1851\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   1853\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 1854\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1856\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1857\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1859\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1860\u001b[0m ):\n\u001b[1;32m   1861\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1862\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/trainer.py:2735\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2732\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   2734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 2735\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2737\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mn_gpu \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   2738\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()  \u001b[38;5;66;03m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/trainer.py:2758\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2756\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2757\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2758\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2759\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   2760\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   2761\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/accelerate/utils/operations.py:680\u001b[0m, in \u001b[0;36mconvert_outputs_to_fp32.<locals>.forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 680\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/accelerate/utils/operations.py:668\u001b[0m, in \u001b[0;36mConvertOutputsToFp32.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 668\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_fp32(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/torch/amp/autocast_mode.py:16\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_autocast\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[0;32m---> 16\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/peft/peft_model.py:1073\u001b[0m, in \u001b[0;36mPeftModelForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, **kwargs)\u001b[0m\n\u001b[1;32m   1062\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward in MPTForCausalLM does not support inputs_embeds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1063\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_model(\n\u001b[1;32m   1064\u001b[0m             input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1065\u001b[0m             attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1070\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1071\u001b[0m         )\n\u001b[0;32m-> 1073\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1074\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1075\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1076\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1077\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1078\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1079\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1080\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1081\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1082\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1084\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m _get_batch_size(input_ids, inputs_embeds)\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;66;03m# concat prompt attention mask\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/peft/tuners/tuners_utils.py:103\u001b[0m, in \u001b[0;36mBaseTuner.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any):\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/microsoft/phi-2/834565c23f9b28b96ccbeabe614dd906b6db551a/modeling_phi.py:953\u001b[0m, in \u001b[0;36mPhiForCausalLM.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, labels, **kwargs)\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    946\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    947\u001b[0m     input_ids: torch\u001b[38;5;241m.\u001b[39mLongTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    951\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    952\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m CausalLMOutputWithPast:\n\u001b[0;32m--> 953\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    954\u001b[0m     lm_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(hidden_states)\n\u001b[1;32m    956\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/microsoft/phi-2/834565c23f9b28b96ccbeabe614dd906b6db551a/modeling_phi.py:915\u001b[0m, in \u001b[0;36mPhiModel.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask)\u001b[0m\n\u001b[1;32m    912\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membd(input_ids)\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mh:\n\u001b[0;32m--> 915\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/microsoft/phi-2/834565c23f9b28b96ccbeabe614dd906b6db551a/modeling_phi.py:770\u001b[0m, in \u001b[0;36mParallelBlock.forward\u001b[0;34m(self, hidden_states, past_key_values, attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    768\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln(hidden_states)\n\u001b[0;32m--> 770\u001b[0m attn_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmixer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    772\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    773\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    774\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    775\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(attn_outputs, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    776\u001b[0m     attn_outputs \u001b[38;5;241m=\u001b[39m attn_outputs[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/microsoft/phi-2/834565c23f9b28b96ccbeabe614dd906b6db551a/modeling_phi.py:722\u001b[0m, in \u001b[0;36mMHA.forward\u001b[0;34m(self, x, past_key_values, attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_head \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_head_kv:\n\u001b[1;32m    720\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m past_key_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    721\u001b[0m         \u001b[38;5;66;03m# If `past_key_values` are not supplied, we run self-attention\u001b[39;00m\n\u001b[0;32m--> 722\u001b[0m         attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_self_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    723\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    724\u001b[0m         \u001b[38;5;66;03m# If `past_key_values` are supplied, it means that we might have cached values and\u001b[39;00m\n\u001b[1;32m    725\u001b[0m         \u001b[38;5;66;03m# could take advantage of cross-attention\u001b[39;00m\n\u001b[1;32m    726\u001b[0m         attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cross_attn(x, past_key_values, attention_mask)\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/microsoft/phi-2/834565c23f9b28b96ccbeabe614dd906b6db551a/modeling_phi.py:621\u001b[0m, in \u001b[0;36mMHA._forward_self_attn\u001b[0;34m(self, x, key_padding_mask)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckpointing:\n\u001b[1;32m    619\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minner_attn, qkv, key_padding_mask\u001b[38;5;241m=\u001b[39mkey_padding_mask)\n\u001b[0;32m--> 621\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minner_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqkv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/torch/amp/autocast_mode.py:16\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_autocast\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[0;32m---> 16\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/torch/amp/autocast_mode.py:16\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_autocast\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[0;32m---> 16\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/microsoft/phi-2/834565c23f9b28b96ccbeabe614dd906b6db551a/modeling_phi.py:373\u001b[0m, in \u001b[0;36mSelfAttention.forward\u001b[0;34m(self, qkv, causal, key_padding_mask, **kwargs)\u001b[0m\n\u001b[1;32m    370\u001b[0m     padding_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfull((batch_size, seqlen), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m10000.0\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mscores\u001b[38;5;241m.\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mscores\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    371\u001b[0m     padding_mask\u001b[38;5;241m.\u001b[39mmasked_fill_(key_padding_mask, \u001b[38;5;241m0.0\u001b[39m)\n\u001b[0;32m--> 373\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[43mscores\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrearrange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpadding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mb s -> b 1 1 s\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m causal:\n\u001b[1;32m    376\u001b[0m     causal_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtriu(torch\u001b[38;5;241m.\u001b[39mfull((seqlen, seqlen), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m10000.0\u001b[39m, device\u001b[38;5;241m=\u001b[39mscores\u001b[38;5;241m.\u001b[39mdevice), \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1024.00 MiB. GPU 0 has a total capacty of 22.19 GiB of which 449.50 MiB is free. Including non-PyTorch memory, this process has 21.74 GiB memory in use. Of the allocated memory 20.70 GiB is allocated by PyTorch, and 761.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "from transformers import default_data_collator, Trainer, TrainingArguments\n",
    "\n",
    "# Define training args\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "    bf16=True,  # Use BF16 if available\n",
    "    # logging strategies\n",
    "    logging_dir=f\"{output_dir}/logs\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=5,\n",
    "    save_strategy=\"no\",\n",
    "    optim=\"adamw_torch_fused\",\n",
    "    max_steps=total_steps if enable_profiler else -1,\n",
    "    **{k:v for k,v in config.items() if k != 'lora_config'}\n",
    ")\n",
    "\n",
    "with profiler:\n",
    "    # Create Trainer instance\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_data,\n",
    "        data_collator=default_data_collator,\n",
    "        callbacks=[profiler_callback] if enable_profiler else [],\n",
    "    )\n",
    "\n",
    "    # Start training\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done, on the 9th of Jan, the year of our lord 2024\n"
     ]
    }
   ],
   "source": [
    "print('done, on the 9th of Jan, the year of our lord 2024')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 7:\n",
    "Save model checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 8:\n",
    "Try the fine tuned model on the same example again to see the learning progress:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_df = pd.read_csv('custom_data/model_eval_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(161, 5)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head Digital Solutions/Digital Transformation Leader\n",
      "Vijayasree Patnaik\n",
      "Email: vijayasreepatnaik1@gmail.com; Phone: +91 7410569056\n",
      "\n",
      "\n",
      "Career Highlights & Summary\n",
      "\n",
      " Overall 23+ years of experience in Solution Architecture, Presales, Product Management\n",
      " and Engineering delivery management for Enterprise solutions\n",
      " In depth experience in driving Digital transformation journey for Utilities, Oil&Gas and\n",
      " Telecom industries\n",
      " Digital transformation presales, solutioning and Program deliveries (cloud and analytics)\n",
      " Digital transformation presales, solutioning and project deliveries (ServiceNow and\n",
      " Salesforce enterprise platforms)\n",
      " Experience in Managed Services Delivery Platform for global customers (more than 200+\n",
      " customers). Managing global stakeholders\n",
      " Strategic product management experience working with business teams to develop IT\n",
      " strategy for new and existing services and automation opportunities\n",
      " Product lifecycle management experience (product roadmap, strategy, vendor\n",
      " management, delivery management, capacity planning and solution ownership)\n",
      " End-to-End experience in application lifecycle management, working closely with\n",
      " customers doing requirement analysis, use case development, solution architecture and\n",
      " project delivery\n",
      "\n",
      "Technical Skills\n",
      "\n",
      " Digital Transformation solutioning (Cloud, IIOT, analytics, Digital Utilities)\n",
      " Microsoft Azure Platform, GCP\n",
      " Domains  Oil&Gas, Manufacturing, Energy & Utilities, Telecom\n",
      " ServiceNow, Salesforce Platform experience\n",
      " AI & ML, Python\n",
      " Enterprise mobility solutions, Telecom OSS, NFV/SDN, Industry 4.0\n",
      "\n",
      "Professional Summary\n",
      "\n",
      "Current: Cyient Limited Dec2021  Till Date\n",
      "Role: Sr Director/Head Digital Aftermarket Services\n",
      "\n",
      "Technical Skills  Salesforce, ServiceNow, Analytics, Cloud Migration, FSM, Energy&Utilities, Python\n",
      "\n",
      " Industry 4.0 solutioning\n",
      " Solutioning and Program Delivery management for customers across Telecom, Utilities and\n",
      " manufacturing for digital services\n",
      " Building Digital Aftermarket Service solutions for customers across domains (Telecom NOC,\n",
      " Energy & Utilities, Manufacturing)\n",
      " Customer engagement and driving the customer satisfaction\n",
      " People Management\n",
      "\n",
      "\n",
      "Current: HCL Technologies Aug2020 \n",
      "Dec2021\n",
      "Role: General Manager/Solution Architect Presales and Solutioning\n",
      "\n",
      "Technical Skills  Energy & Utilities, Digital Transformation, Managed Services\n",
      "\n",
      " Presales solutioning and managing RFP bids for utilities domain  Bids contain cloud\n",
      " migrations, digital transformation initiatives, enterprise platform implementations and\n",
      " managed services\n",
      " Account mining for identifying proactive opportunities for existing customers\n",
      " Practice Management\n",
      " o Sales Collateral (white papers, blogs, marketing collaterals)\n",
      " o Value Propositions\n",
      " o Automation Opportunities\n",
      " People Management and competency development\n",
      ",Past: Honeywell July2018  Aug2020\n",
      "\n",
      "Role: Digital Transformation CoE Leader\n",
      "\n",
      "Technical Skills  Enterprise Architecture, Cloud Platform (Microsoft Azure), Python, SaaS for\n",
      "Honeywell Forge solution suite (Data Lake, Asset Performance Management, Process Monitoring\n",
      "solutions, Data Analytics, Dashboard), Oil&Gas domain\n",
      "\n",
      " Industry 4.0 solutioning\n",
      " Solutioning and architecture vision, creating architecture blueprint and architecture\n",
      " strategy for digital transformation projects (IIOT, cloud, analytics)\n",
      " Provide Strategical advice and guidance to the Solution Architects and regional sales team.\n",
      " RFP and Presales support\n",
      " Engineering Delivery Management\n",
      " o Agile product development leading scrum teams and leading product backlog\n",
      " o Lead the digital engineering project deliveries and KPIs (Quality, schedule,\n",
      " productivity)\n",
      " Responsible for Cloud Operations and customer implementations for Honeywell Forge\n",
      " Platform (Microsoft Azure)\n",
      " Leading engineering team of size of 60+ members\n",
      " Global stakeholder management (managing EMEA, RNAM and APAC regional stakeholders)\n",
      "\n",
      "Past: Ericsson Oct2010 \n",
      "July2018\n",
      "\n",
      "Role: Strategic Product Manager\n",
      "Technical Skills  Cloud Technologies (Microsoft Azure), Telecom OSS (Service Assurance and\n",
      "Fulfilment), Mobility Solutions for Field Services (MWFM)\n",
      "\n",
      " Solutioning and architecture vision, creating architecture blueprint and architecture\n",
      " strategy.\n",
      " Product Requirements & Strategy by leveraging market and customer analysis.\n",
      " Strategic Product roadmap for SD Tools (Product IT strategy, Roadmap planning &\n",
      " development)\n",
      " Agile product development leading scrum teams and leading product backlog\n",
      " Solutioning to evolve OSS platform to NFV/SDN (Network Cloud Platform) implementation\n",
      " strategy.\n",
      " Identify the products/solutions for NFV/SDN transformation and impact analysis for the\n",
      " Service Assurance and Fulfilment\n",
      " Customer and Business line interfacing for requirements management for existing and new\n",
      " services, planning the requirements in the roadmap, working with internal delivery teams\n",
      " and 3pp vendors for solution delivery.\n",
      " Customer and stakeholder relationship management and driver for managing their\n",
      " requirements.\n",
      " Enterprise Architecture evolution  As Is and To Be Analysis.\n",
      " Developed WFM practice from scratch (upto 60 members) and driven the competency\n",
      " development.\n",
      " Lead and mentor team for technical issues & operational stability of the cloud platform\n",
      "\n",
      "Past: Wipro Technologies June 2009  Oct 2010\n",
      "Role: Consultant\n",
      "Technical skills  Field Service Management, Mobility Solutions, Asset Management, Energy &\n",
      "Utilities Domain\n",
      " Presales support (RFP proposals, Customer Demos)\n",
      " Requirement Management use case development  Writing Business and Product\n",
      " Requirements\n",
      " Solution Architecture & Design, Technical Architecture\n",
      " Deliver end to end transformation programmes for Mobile Workforce Management Projects\n",
      " Competency Development and primary driver for Centre of Excellence (CoE) team\n",
      " Consulting assignments for Mobile Workforce Management Solutions\n",
      " Business Development - Was responsible for tapping new business / assignments within\n",
      " existing accounts\n",
      "\n",
      "Past: Satyam Computers Oct 2008  June 2009\n",
      "\n",
      "Role: Project Lead\n",
      "Technical skills  Presales, Project Management\n",
      "Technical skills  Project Management\n",
      ", Project Management\n",
      " Presales and solutioning support\n",
      "\n",
      "Past: Infosys Technologies Ltd Oct 2000  Oct 2008\n",
      "\n",
      "Role: Programmer Analyst/Functional Lead\n",
      "Technical skills  Java, Field Service Management, Mobility Solutions, Oracle, SQL Server, Energy &\n",
      "Utilities Domain, Asset Management, Smart Metering Solutions\n",
      "\n",
      " Customer Requirement Management, use case development  Writing Business and\n",
      " Product Requirements\n",
      " Solution Architecture & Design, Technical Architecture\n",
      " Application Development, Testing, Deployment and Maintenance\n",
      " 3pp Product Configurations, Customizations and Deployment\n",
      " Technical leadership for the team\n",
      " Hands on experience in coding, product configurations, testing and operations support\n",
      " 4+ yrs. at onsite assignments (US) working closely with customers for end to end delivery\n",
      " of customer requirements through ofshore delivery model and onsite operations\n",
      " Project and delivery management for utilities customers\n",
      "\n",
      "Academic Credentials & Certifcations\n",
      "Bachelor of Engineering (Mechanical Engineering) from CET, Bhubaneswar, Orissa in 2000\n",
      "\n",
      "Pursuing Executive PG Diploma from IIIT B in Artificial Intelligence and Machine Learning (AI & ML)\n",
      "\n",
      "Certifcations  Important professional certifications completed\n",
      "Enterprise Architecture\n",
      " o Enterprise Architecture certification by Cordial Sweden\n",
      " o TOGAF Training/certification\n",
      "Technical\n",
      " o CLF-C01 - AWS Certified Cloud Practitioner\n",
      " o AI-900: Microsoft Azure AI Fundamentals\n",
      " o AZ-900: Microsoft Azure Fundamentals\n",
      " o Solution Architect Experienced from Ericsson\n",
      "Process\n",
      " o ITIL V3 Foundation, eTOM Process\n"
     ]
    }
   ],
   "source": [
    "rt = eval_df.sample()['resume'].values[0]\n",
    "rt = html.unescape(rt)\n",
    "print(rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "eval_prompt = f'''\n",
    "You are an accurate agent working for a job platform. You will be given the raw \n",
    "unstructured text of a user's resume, and the task is to extract the entire work experience of the \n",
    "user from the resume. The response should be presented into a numbered list with each item of the list \n",
    "being an unbroken line of text containing the complete and accurate information about the work experience of the users. \n",
    "Here is an example structure:\\n\n",
    "1. Designation 1 @ Company 1 [From \"mm/yyy\" to \"mm/yyyy\"] : \"complete job description as given in resume\"\\n\n",
    "2. Designation 2 @ Company 2 [From \"mm/yyy\" to \"mm/yyyy\"] :  \"complete job description as given in resume\"\\n\n",
    "Please follow this structure accurately and keep the response within the token limit.\" \n",
    "\n",
    "This is the resume text:\\n{{resume_text}}\\n\n",
    "This is the output in the required_format:\\n'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ep = eval_prompt.format(resume_text=rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'streamer': <transformers.generation.streamers.TextStreamer object at 0x7f46b0423160>} not recognized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are an accurate agent working for a job platform. You will be given the raw \n",
      "unstructured text of a user's resume, and the task is to extract the entire work experience of the \n",
      "user from the resume. The response should be presented into a numbered list with each item of the list \n",
      "being an unbroken line of text containing the complete and accurate information about the work experience of the users. \n",
      "Here is an example structure:\n",
      "\n",
      "1. Designation 1 @ Company 1 [From \"mm/yyy\" to \"mm/yyyy\"] : \"complete job description as given in resume\"\n",
      "\n",
      "2. Designation 2 @ Company 2 [From \"mm/yyy\" to \"mm/yyyy\"] :  \"complete job description as given in resume\"\n",
      "\n",
      "Please follow this structure accurately and keep the response within the token limit.\" \n",
      "\n",
      "This is the resume text:\n",
      "Head Digital Solutions/Digital Transformation Leader\n",
      "Vijayasree Patnaik\n",
      "Email: vijayasreepatnaik1@gmail.com; Phone: +91 7410569056\n",
      "\n",
      "\n",
      "Career Highlights & Summary\n",
      "\n",
      " Overall 23+ years of experience in Solution Architecture, Presales, Product Management\n",
      " and Engineering delivery management for Enterprise solutions\n",
      " In depth experience in driving Digital transformation journey for Utilities, Oil&Gas and\n",
      " Telecom industries\n",
      " Digital transformation presales, solutioning and Program deliveries (cloud and analytics)\n",
      " Digital transformation presales, solutioning and project deliveries (ServiceNow and\n",
      " Salesforce enterprise platforms)\n",
      " Experience in Managed Services Delivery Platform for global customers (more than 200+\n",
      " customers). Managing global stakeholders\n",
      " Strategic product management experience working with business teams to develop IT\n",
      " strategy for new and existing services and automation opportunities\n",
      " Product lifecycle management experience (product roadmap, strategy, vendor\n",
      " management, delivery management, capacity planning and solution ownership)\n",
      " End-to-End experience in application lifecycle management, working closely with\n",
      " customers doing requirement analysis, use case development, solution architecture and\n",
      " project delivery\n",
      "\n",
      "Technical Skills\n",
      "\n",
      " Digital Transformation solutioning (Cloud, IIOT, analytics, Digital Utilities)\n",
      " Microsoft Azure Platform, GCP\n",
      " Domains  Oil&Gas, Manufacturing, Energy & Utilities, Telecom\n",
      " ServiceNow, Salesforce Platform experience\n",
      " AI & ML, Python\n",
      " Enterprise mobility solutions, Telecom OSS, NFV/SDN, Industry 4.0\n",
      "\n",
      "Professional Summary\n",
      "\n",
      "Current: Cyient Limited Dec2021  Till Date\n",
      "Role: Sr Director/Head Digital Aftermarket Services\n",
      "\n",
      "Technical Skills  Salesforce, ServiceNow, Analytics, Cloud Migration, FSM, Energy&Utilities, Python\n",
      "\n",
      " Industry 4.0 solutioning\n",
      " Solutioning and Program Delivery management for customers across Telecom, Utilities and\n",
      " manufacturing for digital services\n",
      " Building Digital Aftermarket Service solutions for customers across domains (Telecom NOC,\n",
      " Energy & Utilities, Manufacturing)\n",
      " Customer engagement and driving the customer satisfaction\n",
      " People Management\n",
      "\n",
      "\n",
      "Current: HCL Technologies Aug2020 \n",
      "Dec2021\n",
      "Role: General Manager/Solution Architect Presales and Solutioning\n",
      "\n",
      "Technical Skills  Energy & Utilities, Digital Transformation, Managed Services\n",
      "\n",
      " Presales solutioning and managing RFP bids for utilities domain  Bids contain cloud\n",
      " migrations, digital transformation initiatives, enterprise platform implementations and\n",
      " managed services\n",
      " Account mining for identifying proactive opportunities for existing customers\n",
      " Practice Management\n",
      " o Sales Collateral (white papers, blogs, marketing collaterals)\n",
      " o Value Propositions\n",
      " o Automation Opportunities\n",
      " People Management and competency development\n",
      ",Past: Honeywell July2018  Aug2020\n",
      "\n",
      "Role: Digital Transformation CoE Leader\n",
      "\n",
      "Technical Skills  Enterprise Architecture, Cloud Platform (Microsoft Azure), Python, SaaS for\n",
      "Honeywell Forge solution suite (Data Lake, Asset Performance Management, Process Monitoring\n",
      "solutions, Data Analytics, Dashboard), Oil&Gas domain\n",
      "\n",
      " Industry 4.0 solutioning\n",
      " Solutioning and architecture vision, creating architecture blueprint and architecture\n",
      " strategy for digital transformation projects (IIOT, cloud, analytics)\n",
      " Provide Strategical advice and guidance to the Solution Architects and regional sales team.\n",
      " RFP and Presales support\n",
      " Engineering Delivery Management\n",
      " o Agile product development leading scrum teams and leading product backlog\n",
      " o Lead the digital engineering project deliveries and KPIs (Quality, schedule,\n",
      " productivity)\n",
      " Responsible for Cloud Operations and customer implementations for Honeywell Forge\n",
      " Platform (Microsoft Azure)\n",
      " Leading engineering team of size of 60+ members\n",
      " Global stakeholder management (managing EMEA, RNAM and APAC regional stakeholders)\n",
      "\n",
      "Past: Ericsson Oct2010 \n",
      "July2018\n",
      "\n",
      "Role: Strategic Product Manager\n",
      "Technical Skills  Cloud Technologies (Microsoft Azure), Telecom OSS (Service Assurance and\n",
      "Fulfilment), Mobility Solutions for Field Services (MWFM)\n",
      "\n",
      " Solutioning and architecture vision, creating architecture blueprint and architecture\n",
      " strategy.\n",
      " Product Requirements & Strategy by leveraging market and customer analysis.\n",
      " Strategic Product roadmap for SD Tools (Product IT strategy, Roadmap planning &\n",
      " development)\n",
      " Agile product development leading scrum teams and leading product backlog\n",
      " Solutioning to evolve OSS platform to NFV/SDN (Network Cloud Platform) implementation\n",
      " strategy.\n",
      " Identify the products/solutions for NFV/SDN transformation and impact analysis for the\n",
      " Service Assurance and Fulfilment\n",
      " Customer and Business line interfacing for requirements management for existing and new\n",
      " services, planning the requirements in the roadmap, working with internal delivery teams\n",
      " and 3pp vendors for solution delivery.\n",
      " Customer and stakeholder relationship management and driver for managing their\n",
      " requirements.\n",
      " Enterprise Architecture evolution  As Is and To Be Analysis.\n",
      " Developed WFM practice from scratch (upto 60 members) and driven the competency\n",
      " development.\n",
      " Lead and mentor team for technical issues & operational stability of the cloud platform\n",
      "\n",
      "Past: Wipro Technologies June 2009  Oct 2010\n",
      "Role: Consultant\n",
      "Technical skills  Field Service Management, Mobility Solutions, Asset Management, Energy &\n",
      "Utilities Domain\n",
      " Presales support (RFP proposals, Customer Demos)\n",
      " Requirement Management use case development  Writing Business and Product\n",
      " Requirements\n",
      " Solution Architecture & Design, Technical Architecture\n",
      " Deliver end to end transformation programmes for Mobile Workforce Management Projects\n",
      " Competency Development and primary driver for Centre of Excellence (CoE) team\n",
      " Consulting assignments for Mobile Workforce Management Solutions\n",
      " Business Development - Was responsible for tapping new business / assignments within\n",
      " existing accounts\n",
      "\n",
      "Past: Satyam Computers Oct 2008  June 2009\n",
      "\n",
      "Role: Project Lead\n",
      "Technical skills  Presales, Project Management\n",
      "Technical skills  Project Management\n",
      ", Project Management\n",
      " Presales and solutioning support\n",
      "\n",
      "Past: Infosys Technologies Ltd Oct 2000  Oct 2008\n",
      "\n",
      "Role: Programmer Analyst/Functional Lead\n",
      "Technical skills  Java, Field Service Management, Mobility Solutions, Oracle, SQL Server, Energy &\n",
      "Utilities Domain, Asset Management, Smart Metering Solutions\n",
      "\n",
      " Customer Requirement Management, use case development  Writing Business and\n",
      " Product Requirements\n",
      " Solution Architecture & Design, Technical Architecture\n",
      " Application Development, Testing, Deployment and Maintenance\n",
      " 3pp Product Configurations, Customizations and Deployment\n",
      " Technical leadership for the team\n",
      " Hands on experience in coding, product configurations, testing and operations support\n",
      " 4+ yrs. at onsite assignments (US) working closely with customers for end to end delivery\n",
      " of customer requirements through ofshore delivery model and onsite operations\n",
      " Project and delivery management for utilities customers\n",
      "\n",
      "Academic Credentials & Certifcations\n",
      "Bachelor of Engineering (Mechanical Engineering) from CET, Bhubaneswar, Orissa in 2000\n",
      "\n",
      "Pursuing Executive PG Diploma from IIIT B in Artificial Intelligence and Machine Learning (AI & ML)\n",
      "\n",
      "Certifcations  Important professional certifications completed\n",
      "Enterprise Architecture\n",
      " o Enterprise Architecture certification by Cordial Sweden\n",
      " o TOGAF Training/certification\n",
      "Technical\n",
      " o CLF-C01 - AWS Certified Cloud Practitioner\n",
      " o AI-900: Microsoft Azure AI Fundamentals\n",
      " o AZ-900: Microsoft Azure Fundamentals\n",
      " o Solution Architect Experienced from Ericsson\n",
      "Process\n",
      " o ITIL V3 Foundation, eTOM Process\n",
      "\n",
      "This is the output in the required_format:\n",
      "1. Sr Director/Head Digital Aftermarket Services @ Cyient Limited Dec2021  Till Date : Technical Skills  Salesforce, ServiceNow, Analytics, Cloud Migration, FSM, Energy&Utilities, Python. Industry 4.0 solutioning. Solutioning and Program Delivery management for customers across Telecom, Utilities and manufacturing for digital services. Building Digital Aftermarket Service solutions for customers across domains (Telecom NOC, Energy & Utilities, Manufacturing). Customer engagement and driving the customer satisfaction. People Management.\n",
      "2. General Manager/Solution Architect Presales and Solutioning @ HCL Technologies Aug2020  Dec2021 : Technical Skills  Energy & Utilities, Digital Transformation, Managed Services. Presales solutioning and managing RFP bids for utilities domain  Bids contain cloud migrations, digital transformation initiatives, enterprise platform implementations and managed services. Account mining for identifying proactive opportunities for existing customers. Practice Management.\n",
      "3. Digital Transformation CoE Leader @ Honeywell July2018  Aug2020 : Technical Skills  Enterprise Architecture, Cloud Platform (Microsoft Azure), Python, SaaS for Honeywell Forge solution suite (Data Lake, Asset Performance Management, Process Monitoring solutions, Data Analytics, Dashboard), Oil&Gas domain. Industry 4.0 solutioning. Solutioning and architecture vision, creating architecture blueprint and architecture strategy for digital transformation projects (IIOT, cloud, analytics). Provide Strategical advice and guidance to the Solution Architects and regional sales team. RFP and Presales support. Engineering Delivery Management. Leading engineering team of size of 60+ members. Global stakeholder management (managing EMEA, RNAM and APAC regional stakeholders).\n",
      "4. Strategic Product Manager @ Ericsson Oct2010  July2018 : Technical Skills  Cloud Technologies (Microsoft Azure), Telecom OSS (Service Assurance and Fulfilment), Mobility Solutions for Field Services (MWFM). Solutioning and architecture vision, creating architecture blueprint and architecture strategy. Product Requirements & Strategy by leveraging market and customer analysis. Strategic Product roadmap for SD Tools (Product IT strategy, Roadmap planning & development) . Identify the products/solutions for NFV/SDN transformation and impact analysis for the Service Assurance and Fulfilment. Customer and Business line interfacing for requirements management for existing and new services, planning the requirements in the roadmap, working with internal delivery teams and 3pp vendors for solution delivery. Customer and stakeholder relationship management and driver for managing their requirements. Enterprise Architecture evolution  As Is and To Be Analysis. Developed WFM practice from scratch (upto 60 members) and driven the competency development. Lead and mentor team for technical issues & operational stability of the cloud platform.\n",
      "5. Consultant @ Wipro Technologies June 2009  Oct 2010 : Technical skills  Field Service Management, Mobility Solutions, Asset Management, Energy & Utilities Domain. Presales support (RFP proposals, Customer Demos) . Requirement Management use case development  Writing Business and Product Requirements. Solution Architecture & Design, Technical Architecture. Deliver end to end transformation programmes for Mobile Workforce Management Projects. Competency Development and primary driver for Centre of Excellence (CoE) team. Consulting assignments for Mobile Workforce Management Solutions. Business Development - Was responsible for tapping new business / assignments within existing accounts.\n",
      "6. Project Lead @ Wipro Technologies June 2009  Oct 2010 : Technical skills  Presales, Project Management.\n",
      "7. Programmer Analyst/Functional Lead @ Infosys Technologies Ltd Oct 2008  June 2009 : Technical skills  Java, Field Service Management, Mobility Solutions, Oracle, SQL Server, Energy & Utilities Domain, Asset Management, Smart Metering Solutions. Customer Requirement Management, use case development  Writing Business and Product Requirements. Solution Architecture & Design, Technical Architecture. Application Development, Testing, Deployment and Maintenance. 3pp Product Configurations, Customizations and Deployment. Technical leadership for the team. Hands on experience in coding, product configurations, testing and operations support. 4+ yrs. at onsite assignments (US) working closely with customers for end to end delivery of customer requirements through ofshore delivery model and onsite operations. Project and delivery management for utilities customers.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import TextStreamer\n",
    "\n",
    "streamer = TextStreamer(tokenizer)\n",
    "model_input = tokenizer(ep,streamer=streamer,return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(tokenizer.decode(model.generate(**model_input, max_new_tokens=2048)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# eval_prompt = f'''\n",
    "# You are a helpful language model working for a job platform. You will be given the raw \n",
    "#  unstructured text of a user's resume, and the task is to extract the work experience of the \n",
    "#  user from the raw text in the following format: \\n{{work_format}}\\n\n",
    "\n",
    "#  This is the resume text:\\n{{resume_text}}\\n\n",
    "#  This is the output in the required format:\\n\n",
    "# '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# work_format = '''{\n",
    "#     'work_experience': [{'company': 'company Name 1',\n",
    "#                          'role': 'job designation 1',\n",
    "#                          'start_date': 'mm/yyyy',\n",
    "#                          'end_date': 'mm/yyyy',\n",
    "#                          'description': 'complete Job description taken from resume'},\n",
    "#                         {'company': 'company name 2',\n",
    "#                          'role': 'job designation 2',\n",
    "#                          'start_date': mm/yyyy',\n",
    "#                          'end_date': 'mm/yyyy',\n",
    "#                          'description': 'complete Job description taken from resume'}]\n",
    "# }'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baf77cfa300d4b249a39518675faf5be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/134M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/lakshay/linear-work-peft/commit/b7a96f16e2f4f721a146fd3558f5953bfc3232f5', commit_message='Upload model', commit_description='', oid='b7a96f16e2f4f721a146fd3558f5953bfc3232f5', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub('lakshay/linear-work-peft',token='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Personal Information Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75804f0963d448fbb0e7ba1e1d423bba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/16.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/lakshay/llama2-test/commit/9460af41bdcca6c6b9cafac27d3ee09a4bd6c36a', commit_message='Upload model', commit_description='', oid='9460af41bdcca6c6b9cafac27d3ee09a4bd6c36a', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub('lakshay/llama2-test',token='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', max_shard_size='2GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PI validation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_data = pd.read_csv('custom_data/validation_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_data.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_data.resume.values[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "error_list = list()\n",
    "correct_list = list()\n",
    "\n",
    "for uid,rt in tqdm(validation_data[['id','resume']].sample(frac=1).values[:200]):\n",
    "\n",
    "    eval_prompt = pi_eval_prompt.substitute(\n",
    "                pi_format=pi_format,\n",
    "                resume_text=rt)\n",
    "\n",
    "    sample_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    try:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            full_document = tokenizer.decode(model.generate(**sample_input, max_new_tokens=200)[0], skip_special_tokens=True)\n",
    "    except:\n",
    "        print('feck')\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        out_str = full_document.replace(eval_prompt,'').replace('$','')\n",
    "        out_json = ast.literal_eval(out_str)\n",
    "        u_info = {}\n",
    "        u_info[uid] = out_json\n",
    "        correct_list.append(u_info)\n",
    "    except:\n",
    "        error_list.append(full_document)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# correct_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'hello there, $, yes'.replace('there,','').replace('$','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(correct_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct_list\n",
    "\n",
    "with open('custom_data/validation_output.pkl','wb') as f:\n",
    "    pickle.dump(correct_list,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65b66f79022e4d62b7980aaa0d6e8ae4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_config.json:   0%|          | 0.00/581 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "\n                        Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit\n                        the quantized model. If you want to dispatch the model on the CPU or the disk while keeping\n                        these modules in 32-bit, you need to set `load_in_8bit_fp32_cpu_offload=True` and pass a custom\n                        `device_map` to `from_pretrained`. Check\n                        https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu\n                        for more details.\n                        ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m model_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlakshay/llama2-test\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# tokenizer = LlamaTokenizer.from_pretrained(model_id)\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mLlamaForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_in_8bit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat16\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhf_rthVXJBMwUqJSEayJxkiKZtRSIwFLEVwot\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/modeling_utils.py:3646\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3642\u001b[0m         device_map_without_lm_head \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   3643\u001b[0m             key: device_map[key] \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m device_map\u001b[38;5;241m.\u001b[39mkeys() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m modules_to_not_convert\n\u001b[1;32m   3644\u001b[0m         }\n\u001b[1;32m   3645\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map_without_lm_head\u001b[38;5;241m.\u001b[39mvalues() \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisk\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map_without_lm_head\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[0;32m-> 3646\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3647\u001b[0m \u001b[38;5;250m                \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3648\u001b[0m \u001b[38;5;124;03m                Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit\u001b[39;00m\n\u001b[1;32m   3649\u001b[0m \u001b[38;5;124;03m                the quantized model. If you want to dispatch the model on the CPU or the disk while keeping\u001b[39;00m\n\u001b[1;32m   3650\u001b[0m \u001b[38;5;124;03m                these modules in 32-bit, you need to set `load_in_8bit_fp32_cpu_offload=True` and pass a custom\u001b[39;00m\n\u001b[1;32m   3651\u001b[0m \u001b[38;5;124;03m                `device_map` to `from_pretrained`. Check\u001b[39;00m\n\u001b[1;32m   3652\u001b[0m \u001b[38;5;124;03m                https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu\u001b[39;00m\n\u001b[1;32m   3653\u001b[0m \u001b[38;5;124;03m                for more details.\u001b[39;00m\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;124;03m                \"\"\"\u001b[39;00m\n\u001b[1;32m   3655\u001b[0m             )\n\u001b[1;32m   3656\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m device_map_without_lm_head\n\u001b[1;32m   3658\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m device_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: \n                        Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit\n                        the quantized model. If you want to dispatch the model on the CPU or the disk while keeping\n                        these modules in 32-bit, you need to set `load_in_8bit_fp32_cpu_offload=True` and pass a custom\n                        `device_map` to `from_pretrained`. Check\n                        https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu\n                        for more details.\n                        "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer\n",
    "\n",
    "model_id=\"lakshay/llama2-test\"\n",
    "\n",
    "# tokenizer = LlamaTokenizer.from_pretrained(model_id)\n",
    "\n",
    "model = LlamaForCausalLM.from_pretrained(model_id, load_in_8bit=True, device_map='auto', torch_dtype=torch.float16, token='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "2d58e898dde0263bc564c6968b04150abacfd33eed9b19aaa8e45c040360e146"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
