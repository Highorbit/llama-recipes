{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 1: Load the model\n",
    "\n",
    "Point model_id to model weight folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "train_data = load_from_disk(\"../custom_data/mistral/linear_work_data.hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon May  6 16:15:49 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.154.05             Driver Version: 535.154.05   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A10G                    Off | 00000000:00:1E.0 Off |                    0 |\n",
      "|  0%   31C    P0              55W / 300W |      0MiB / 23028MiB |      4%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/ubuntu/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login(token='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Important \n",
    "\n",
    "It is important to consider here which model we're using to parse the resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BitsAndBytesConfig\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c869f604af342c388b54d787241956f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_id=\"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map='auto',token='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.append('/home/ec2-user/SageMaker/llama_root/src')\n",
    "sys.path.append('../llama-recipes/src/llama_recipes/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Check base model\n",
    "\n",
    "Run the base model on an example input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "eval_prompt = f'''\n",
    "You are an accurate agent working for a job platform. You will be given the raw \n",
    "unstructured text of a user's resume, and the task is to extract details of the user's \n",
    "work experience. The details required are the designation, company name, start date and end date.\n",
    "The response should be broken into a numbered list with each item of the list \n",
    "containing the complete and accurate information about the work experience of the users.\n",
    "1. Designation 1 @ Company 1 [From \"mm/yyy\" to \"mm/yyyy\"] : \\n\n",
    "2. Designation 2 @ Company 2 [From \"mm/yyy\" to \"mm/yyyy\"] : \\n\n",
    "Please follow this structure closely and keep the response within the token limit. Do not \" \n",
    "\n",
    "This is the resume text:\\n{{resume_text}}\\n\n",
    "This is the output in the required_format:\\n'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample1 = '''\n",
    "VEDANK SINGH 20 20\n",
    "Full-Stack Developer 11 20\n",
    "Mob: (+91)8004827441 11 4\n",
    "E-mail ID: 11 4\n",
    "vedank.singh@outlook.com 11 4\n",
    "LinkedIn: 11 4\n",
    "https://www.linkedin.com/in/vedank-singh-078838109 11 4\n",
    "Professional Summary: 14 20\n",
    "• 11 4\n",
    "Determined, passionate and hardworking IT professional with 4+ years of 11 4\n",
    "experience in Full Stack development. I am highly adept at Java, JavaScript, 11 4\n",
    "Python, Oracle Database, SpringBoot, React and Public Speaking. 11 4\n",
    "• 11 4\n",
    "Excellent code reviews and code debugging skills. 11 4\n",
    "• 12 4\n",
    "Experienced in all stages of SDLC from requirement gathering to deployment. 11 4\n",
    "Professional Experience: 14 20\n",
    "Technical Skill Set: 14 20\n",
    "Period 11 20\n",
    "Company 11 20\n",
    "Role 11 20\n",
    "31/05/21 to Present 11 4\n",
    "JP Morgan Chase & Co. 11 4\n",
    "Software Engineer 11 4\n",
    "16/04/18 to 28/05/21 11 4\n",
    "Tata Consultancy Services 11 4\n",
    "System Engineer 11 4\n",
    "Programming languages 11 20\n",
    "Java, Javascript, Python 11 4\n",
    "Web Designing Languages 11 20\n",
    "React.js, HTML, CSS, AJAX, JQuery 11 4\n",
    "Frameworks 11 20\n",
    "Flask, Servlet, SpringBoot, Microservices, 11 4\n",
    "Anaconda, Kerberos, Pandas, IDA, REST 11 4\n",
    "Operating Systems 11 20\n",
    "Linux (Redhat), Windows 11 4\n",
    "Database 11 20\n",
    "Oracle 11 4\n",
    "Tools 11 20\n",
    "Sourcetree, Bitbucket, Git, SVN, Jenkins, 11 4\n",
    "Jules, Postman, Jmeter, Autosys, Jira, 11 4\n",
    "Putty, Confluence, DevPlus 11 4\n",
    "Servers 11 20\n",
    "Apache Tomcat, Gunicorn 11 4\n",
    "Testing Framework 11 20\n",
    "Pytest, Mockito 11 4\n",
    "'''\n",
    "\n",
    "sample2 = '''\n",
    "Professional Summary: 14 20\n",
    "• 11 4\n",
    "Determined, passionate and hardworking IT professional with 4+ years of 11 4\n",
    "experience in Full Stack development. I am highly adept at Java, JavaScript, 11 4\n",
    "Python, Oracle Database, SpringBoot, React and Public Speaking. 11 4\n",
    "• 11 4\n",
    "Excellent code reviews and code debugging skills. 11 4\n",
    "• 12 4\n",
    "Experienced in all stages of SDLC from requirement gathering to deployment. 11 4\n",
    "Professional Experience: 14 20\n",
    "Technical Skill Set: 14 20\n",
    "Period 11 20\n",
    "Company 11 20\n",
    "Role 11 20\n",
    "31/05/21 to Present 11 4\n",
    "JP Morgan Chase & Co. 11 4\n",
    "Software Engineer 11 4\n",
    "16/04/18 to 28/05/21 11 4\n",
    "Tata Consultancy Services 11 4\n",
    "System Engineer 11 4\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ep = eval_prompt.format(resume_text=sample2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are an accurate agent working for a job platform. You will be given the raw \n",
      "unstructured text of a user's resume, and the task is to extract details of the user's \n",
      "work experience. The details required are the designation, company name, start date and end date.\n",
      "The response should be broken into a numbered list with each item of the list \n",
      "containing the complete and accurate information about the work experience of the users.\n",
      "1. Designation 1 @ Company 1 [From \"mm/yyy\" to \"mm/yyyy\"]\n",
      "\n",
      "2. Designation 2 @ Company 2 [From \"mm/yyy\" to \"mm/yyyy\"]\n",
      "\n",
      "Please follow this structure closely and keep the response within the token limit.\" \n",
      "\n",
      "This is the resume text:\n",
      "\n",
      "Professional Summary: 14 20\n",
      "• 11 4\n",
      "Determined, passionate and hardworking IT professional with 4+ years of 11 4\n",
      "experience in Full Stack development. I am highly adept at Java, JavaScript, 11 4\n",
      "Python, Oracle Database, SpringBoot, React and Public Speaking. 11 4\n",
      "• 11 4\n",
      "Excellent code reviews and code debugging skills. 11 4\n",
      "• 12 4\n",
      "Experienced in all stages of SDLC from requirement gathering to deployment. 11 4\n",
      "Professional Experience: 14 20\n",
      "Technical Skill Set: 14 20\n",
      "Period 11 20\n",
      "Company 11 20\n",
      "Role 11 20\n",
      "31/05/21 to Present 11 4\n",
      "JP Morgan Chase & Co. 11 4\n",
      "Software Engineer 11 4\n",
      "16/04/18 to 28/05/21 11 4\n",
      "Tata Consultancy Services 11 4\n",
      "System Engineer 11 4\n",
      "\n",
      "\n",
      "This is the output in the required_format:\n",
      "\n",
      "1. Software Engineer @ JP Morgan Chase & Co. [From \"05/21\" to \"Present\"]\n",
      "\n",
      "2. System Engineer @ Tata Consultancy Services [From \"04/18\" to \"05/21\"]\n",
      "Time taken :3.920314073562622\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "model_input = tokenizer(ep,return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(tokenizer.decode(model.generate(**model_input, max_new_tokens=1024)[0], skip_special_tokens=True))\n",
    "\n",
    "print(f'Time taken :{time.time()-start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "We can see that the base model only repeats the conversation.\n",
    "\n",
    "### Step 4: Prepare model for PEFT\n",
    "\n",
    "Let's prepare the model for Parameter Efficient Fine Tuning (PEFT):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/infoedge/llama-recipes/env/lib/python3.10/site-packages/peft/utils/other.py:141: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 27,262,976 || all params: 7,268,995,072 || trainable%: 0.3750583915652433\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "def create_peft_config(model):\n",
    "    from peft import (\n",
    "        get_peft_model,\n",
    "        LoraConfig,\n",
    "        TaskType,\n",
    "        prepare_model_for_int8_training,\n",
    "    )\n",
    "\n",
    "    peft_config = LoraConfig(\n",
    "        task_type=TaskType.CAUSAL_LM,\n",
    "        inference_mode=False,\n",
    "        r=64,\n",
    "        lora_alpha=32,\n",
    "        lora_dropout=0.05,\n",
    "        target_modules = [\"q_proj\", \"v_proj\"]\n",
    "    )\n",
    "    \n",
    "    # peft_config = LoraConfig(\n",
    "    #     task_type=TaskType.CAUSAL_LM,\n",
    "    #     inference_mode=False,\n",
    "    #     r=8,\n",
    "    #     lora_alpha=32,\n",
    "    #     lora_dropout=0.05,\n",
    "    #     target_modules = [\"q_proj\", \"v_proj\"]\n",
    "    # )\n",
    "\n",
    "    # prepare int-8 model for training\n",
    "    model = prepare_model_for_int8_training(model)\n",
    "    model = get_peft_model(model, peft_config)\n",
    "    model.print_trainable_parameters()\n",
    "    return model, peft_config\n",
    "\n",
    "# create peft config\n",
    "model, lora_config = create_peft_config(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Step 5: Define an optional profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import TrainerCallback\n",
    "from contextlib import nullcontext\n",
    "enable_profiler = False\n",
    "output_dir = \"tmp/linear_workex\"\n",
    "\n",
    "config = {\n",
    "    'lora_config': lora_config,\n",
    "    'learning_rate': 1e-4,\n",
    "    'num_train_epochs': 4,\n",
    "    'gradient_accumulation_steps': 2,\n",
    "    'per_device_train_batch_size': 2,\n",
    "    'gradient_checkpointing': False,\n",
    "}\n",
    "\n",
    "# Set up profiler\n",
    "if enable_profiler:\n",
    "    wait, warmup, active, repeat = 1, 1, 2, 1\n",
    "    total_steps = (wait + warmup + active) * (1 + repeat)\n",
    "    schedule =  torch.profiler.schedule(wait=wait, warmup=warmup, active=active, repeat=repeat)\n",
    "    profiler = torch.profiler.profile(\n",
    "        schedule=schedule,\n",
    "        on_trace_ready=torch.profiler.tensorboard_trace_handler(f\"{output_dir}/logs/tensorboard\"),\n",
    "        record_shapes=True,\n",
    "        profile_memory=True,\n",
    "        with_stack=True)\n",
    "    \n",
    "    class ProfilerCallback(TrainerCallback):\n",
    "        def __init__(self, profiler):\n",
    "            self.profiler = profiler\n",
    "            \n",
    "        def on_step_end(self, *args, **kwargs):\n",
    "            self.profiler.step()\n",
    "\n",
    "    profiler_callback = ProfilerCallback(profiler)\n",
    "else:\n",
    "    profiler = nullcontext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon May  6 13:30:12 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.154.05             Driver Version: 535.154.05   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A10G                    Off | 00000000:00:1E.0 Off |                    0 |\n",
      "|  0%   40C    P0             104W / 300W |   7246MiB / 23028MiB |      1%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      1485      C   ...oedge/llama-recipes/env/bin/python3     7238MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Fine tune the model\n",
    "\n",
    "Here, we fine tune the model for a single epoch which takes a bit more than an hour on a A100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "/home/ubuntu/infoedge/llama-recipes/env/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='256' max='256' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [256/256 1:00:38, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.070800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.858700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.807000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.845600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.783500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.741000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.694200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.629800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.852700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.737400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>1.850800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.544500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>1.771800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.592500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>1.560800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.576200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>1.689500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.540200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>1.592100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.703500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>1.636200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.630100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>1.645500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.696800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>1.688400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.678400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>1.706000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.600800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>1.621600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.585400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>1.548200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.671400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>1.591800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.530200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>1.462700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.528700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185</td>\n",
       "      <td>1.576700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.554200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>1.571500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.571300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>205</td>\n",
       "      <td>1.507300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.529700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>215</td>\n",
       "      <td>1.610600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.564400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>1.487800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1.619600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>235</td>\n",
       "      <td>1.563400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.544400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>245</td>\n",
       "      <td>1.516600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.542200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>255</td>\n",
       "      <td>1.502400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import default_data_collator, Trainer, TrainingArguments\n",
    "\n",
    "# Define training args\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "    bf16=True,  # Use BF16 if available\n",
    "    # logging strategies\n",
    "    logging_dir=f\"{output_dir}/logs\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=5,\n",
    "    save_strategy=\"no\",\n",
    "    optim=\"adamw_torch_fused\",\n",
    "    max_steps=total_steps if enable_profiler else -1,\n",
    "    **{k:v for k,v in config.items() if k != 'lora_config'}\n",
    ")\n",
    "\n",
    "with profiler:\n",
    "    # Create Trainer instance\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_data,\n",
    "        data_collator=default_data_collator,\n",
    "        callbacks=[profiler_callback] if enable_profiler else [],\n",
    "    )\n",
    "\n",
    "    # Start training\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 7:\n",
    "Save model checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 8:\n",
    "Try the fine tuned model on the same example again to see the learning progress:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_df = pd.read_csv('../custom_data/model_eval_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(161, 5)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import html, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaurav Dev subhamkr1995dob@gmail.com\n",
      "\n",
      " 6289038260\n",
      "Software Developer\n",
      "B-Tech graduate having a keen interest in coding and development, Ramgarh, India\n",
      "meticulous, responsible and committed engineer with a get it done\n",
      "attitude linkedin.com/in/gaurav-dev-031a65141\n",
      "\n",
      " github.com/Gaurav-Dev24\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "EDUCATION SKILLS\n",
      "Bachelor's in Technology React React-Redux JavaScript Tailwind CSS\n",
      "Heritage Institute of Technology, Kolkata\n",
      "10/2017 - 08/2020, Bootstrap & CSS HTML\n",
      "Courses\n",
      " Computer Science and\n",
      " Engineering\n",
      " PERSONAL PROJECTS\n",
      "Diploma Portfolio Website\n",
      "Government Polytechnic, Dhanbad Complete portfolio website with attractive user interface and cool\n",
      "06/2014 - 05/2017, animations. Tech Stack - React.\n",
      "Courses Shopping Cart\n",
      " Computer Science and The Shopping Cart project is a web application that allows users to\n",
      " Engineering browse and purchase products online. Tech Stack- React, Context\n",
      " API.\n",
      "\n",
      " Todo Web App using Redux\n",
      "INTERNSHIPS & COURSES Todo app with CRUD (Create, Read, Update, Delete) functionality in\n",
      " React is a web application that allows user-friendly interface.Tech\n",
      " Stack - React, Redux.\n",
      "Full Stack JavaScript Boot-camp 2.0\n",
      "Ineuron.ai\n",
      "10/2022 - 09/2023,\n",
      "Achievements/Tasks CERTIFICATES\n",
      " I have learned everything about JavaScript with React, REACT\n",
      " Tailwind/Bootstrap, CSS & HTML. Build industry-ready HACKER RANK\n",
      " projects for web and mobile.\n",
      " JAVASCRIPT\n",
      "Shopping Cart HACKER RANK\n",
      "\n",
      "Ineuron.ai HTML & CSS\n",
      "05/2023, LEARN CODE ONLINE\n",
      "Achievements/Tasks\n",
      " GIT & GITHUB\n",
      " The Shopping Cart project is a web application that LEARN CODE ONLINE\n",
      " allows users to browse and purchase products online.\n",
      " The application is built using React, Context API, and\n",
      " usereducer hook, which allows us to manage complex\n",
      " state changes eciently. ACHIEVEMENTS\n",
      " Qualied JELET\n",
      "Web Development Intern 2017\n",
      "Bharat Intern\n",
      "07/2023, Qualied Jharkhand Ploytechnic\n",
      " 2014\n",
      "Achievements/Tasks\n",
      " Implemented JavaScript,HTML and CSS to create\n",
      " Temperature Converter App & Netix UI Clone\n",
      " LANGUAGES\n",
      " ENGLISH HINDI\n",
      "ORGANIZATIONS Full Professional Prociency Full Professional Prociency\n",
      "Axis Bank Limited (09/2021 - 10/2022)\n",
      "ASSISTANT MANAGER\n",
      "\n",
      " INTERESTS\n",
      " TRAVELING SINGING CODING\n"
     ]
    }
   ],
   "source": [
    "rt = eval_df.sample(random_state=random.randint(0,10000))['resume'].values[0]\n",
    "rt = html.unescape(rt)\n",
    "\n",
    "print(rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "eval_prompt = f'''\n",
    "You are an accurate agent working for a job platform. You will be given the raw \n",
    "unstructured text of a user's resume, and the task is to extract the entire work experience of the \n",
    "user from the resume. The response should be presented into a numbered list with each item of the list \n",
    "being an unbroken line of text containing the complete and accurate information about the work experience of the users. \n",
    "Here is an example structure:\\n\n",
    "1. Designation 1 @ Company 1 [From \"mm/yyy\" to \"mm/yyyy\"] : \"complete job description as given in resume\"\\n\n",
    "2. Designation 2 @ Company 2 [From \"mm/yyy\" to \"mm/yyyy\"] :  \"complete job description as given in resume\"\\n\n",
    "Please follow this structure accurately and keep the response within the token limit.\" \n",
    "\n",
    "This is the resume text:\\n{{resume_text}}\\n\n",
    "This is the output in the required_format:\\n'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ep = eval_prompt.format(resume_text=rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are an accurate agent working for a job platform. You will be given the raw \n",
      "unstructured text of a user's resume, and the task is to extract the entire work experience of the \n",
      "user from the resume. The response should be presented into a numbered list with each item of the list \n",
      "being an unbroken line of text containing the complete and accurate information about the work experience of the users. \n",
      "Here is an example structure:\n",
      "\n",
      "1. Designation 1 @ Company 1 [From \"mm/yyy\" to \"mm/yyyy\"] : \"complete job description as given in resume\"\n",
      "\n",
      "2. Designation 2 @ Company 2 [From \"mm/yyy\" to \"mm/yyyy\"] :  \"complete job description as given in resume\"\n",
      "\n",
      "Please follow this structure accurately and keep the response within the token limit.\" \n",
      "\n",
      "This is the resume text:\n",
      " Yogita B Kaskar\n",
      " ykaskar@yahoo.com | +91 92235 29541 | Mumbai, India\n",
      "\n",
      " SOFTWARE TESTINGISQTB CERTIFIED TESTER\n",
      "\n",
      " SUMMARY\n",
      " Over 16 years experience working as a Manual QA Engineer for Testing life cycle including preparation of\n",
      " Test Strategy,Test Plan,Test Cases,Test Summary report,Defect report .\n",
      " 4 years automation Testing in BFSI and Loan Industry and Insurance Industry .Expertise in Automation testing\n",
      " tools as Selenium WebDriver ,Test NG, JIRA,Maven,Cucumber,Jenkin ,SOAP,REST,POSTMAN ,GitHub .9 to 11\n",
      " months in cypress automation project\n",
      " Expert in testing life cycle including Risk Analysis ,Planning process,Test Design,Test execution,Defec t\n",
      " Tracking,Management and Test Reporting\n",
      " Experience with Agile scrum ,Waterfall,TDD Methodology .Presented Progress of Testing Process at\n",
      " Walkthrough and Inspection\n",
      " Experience with Business functionality testing ,End to End Testing ,UAT ,Regression Testin g ,Performance\n",
      " Testing ,Documentation and Reporting\n",
      " Different types of functional and non-functional testings such as unit, integration, system, and acceptance\n",
      " testing.\n",
      " Proficient with all phase of SDLC (Software Development Life Cycle) Agile framework and STLC (Software\n",
      " Test Life Cycle) and ensured successful delivery of all testing metrics.\n",
      " Adpet at identifying and reporting project bugs and ensuring resolution of the same by the development team\n",
      " in JIRA\n",
      " Served as a liaison to the test implement team to ensure accurate testing, and regression testing.\n",
      " Expertise in Analysis of Results and reporting suggestions and defects\n",
      " Sound knowledge on Test NG Framework for Unit testing , Maven as Project building tool ,Jenkin for\n",
      " continuous Integration\n",
      " Web services testing SOAP UI ,XML and WSDL .Experience in WEB Services testing like RESTAPI ,SOAPUI\n",
      " and POSTMAN\n",
      " Mobile testing using Android Studio and Appium\n",
      " API testing automation using REST Assured JAVA\n",
      " An independent thinker with high achievement orientation, whose roles have evolved through proven abilities\n",
      " and persistent high performance.\n",
      " Report generation and taking screenshots while testing\n",
      " -------------------------------------------------------------------------------------------------------------------MySQL Queries | Test Case\n",
      " Development | Quality Assurance | Functional/Regression Testing | Process Improvements | Agile methodology | Project\n",
      " Management | Defect Management | Automation | Documentation | Team Player\n",
      " -------------------------------------------------------------------------------------------------------------------Software: C, C++, Java,Java\n",
      " Script ,Selenium,Cypress ,Squish,QTP,Jenkins , JIRA,TestRail ,TFS,Git,SoapUI,Postman,REST,UNIX, Jmeter, Python,\n",
      " Appium,Android ,IOS,Maven,Solaris, VC++, BREW, Embedded VC++, 3.0 (SDK Programming), AWT, SWING,Web Based\n",
      " application testing in Chrome,Mozilla and other browsers ,database testing-SQL server,Oracle,SQLite\n",
      "\n",
      "\n",
      " EXPERIENCE\n",
      "\n",
      "\n",
      "\n",
      "Opendr Business Services Pvt. LTD., Mumbai – (March2023- May2023)\n",
      " Company has healthcare domain. Analyze User stories before starting the Sprint. Actively\n",
      " participitated in Agile ceremonies i.e. grooming session, Sprint Planning Meeting, Scrum Meeting,\n",
      " Sprint Review Meeting & Sprint Retrospective Meeting. Involved in handling client ticket.\n",
      ", Yogita B Kaskar\n",
      " ykaskar@yahoo.com | +91 92235 29541 | Mumbai, India\n",
      "Project Title : Opendoctor\n",
      " CRM System for managing patient Order, Scheduling an Appointment for exam in different location\n",
      " CRM system to login multiple practice and referring user.\n",
      " Patient interface to enroll new patient and self- appointment Scheduling from patient.\n",
      " Validating real-time insurance coverage at the time of Appoint scheduling.\n",
      "\n",
      "\n",
      "\n",
      "Yethi Consulting\n",
      "Software Tester D e c 2021-Nov2022\n",
      "• Worked as a Functional tester at the client side BFSI and Loan Domain\n",
      "• Experience in Finacle ,Loans –SalesForce , Payment ,Collection\n",
      "\n",
      "• Responsible for analysing Bussiness,Functional ,Business Requirement Documents and preparing Complete TestPlan\n",
      " including System Test Plan,Integration TestPlan,QA Project Plan\n",
      "• Worked Data Driven testing using Selenium Web Driver ,TestNG functions\n",
      "• Involved in Design and implementation Selenium WebDriver Automation Frameworks for Smoke and regression\n",
      " testSuits\n",
      "• Used Maven for WebDriver Framework\n",
      "• Involved in automation frameworks in selenium WebDriver using Behavior Driven Approach like Cucumber\n",
      "• Used Postman API to get convenient, visual display of query results.\n",
      "• Parameterised Testcases using different Annotation\n",
      "• Implemented PageObjectModel Automation framework for JAVA,Selenium WebDriver And Cucumber\n",
      "• Developed and executed SQL queries to verify Proper Insertion ,Deletion and Update into the Supporting Database\n",
      "• Web Service Request Response Validations using POSTMAN and SOAP UI\n",
      "• Worked with Developer ,Business Analyst and Project Manager to determine Requirements\n",
      "\n",
      "\n",
      "Wohlig Pvt Limited\n",
      "\n",
      "\n",
      "Software Tester, Sep2020 – Nov 2021\n",
      "Web based testing in manual Testing. Mobile testing ,API testing. API testing using tools like SoapUI,\n",
      "POSTMAN ,REST etc.\n",
      "• Used Postman API to get convenient, visual display of query results.\n",
      "• Over one years of IT industry experience as Mobile application testing using APPIUM in the field of Android,IOS.\n",
      " Experience in Testing front end applications for Android and IOS phones\n",
      "• Used Selenium –Java Automation for Web based Project\n",
      "• Analysis of nightly execution and prepare bug Report in JIRA\n",
      "• Strong in Database Testing and Writing the SQL queries.\n",
      "• Web Service Request Response Validations using POSTMAN and SOAP UI\n",
      "• Integrated with Continuous Integration tools Jenkins for running test on nightly basis automatically.\n",
      "• Performance testing using Loadrunner and Jmeter\n",
      "• Excellent experience with source version control tools such as TFS&Git\n",
      "• Attended Daily Scrum Meeting and participated in weekly project status meeting and updated the testing Progress.\n",
      "• Projects Worked On: Retail ecommerce based Projects\n",
      ", Yogita B Kaskar\n",
      " ykaskar@yahoo.com | +91 92235 29541 | Mumbai, India\n",
      "\n",
      "\n",
      "TATA POWER COMPANYMumbai, India\n",
      "Software Tester, Nov2003 - June2019\n",
      "Offering 16+ years experience. Accountable for end-to-end software testing responsibilities as part of 12-15 member\n",
      "team. Responsibilities include project planning and monitoring, SQA quality assurance, configuration management,\n",
      "DAR/CAR, risk management, issue/bug-fixing management, development of process templates such as QPM, OPD, OPF,\n",
      "QPM, &PPM. Reporting to Project Team Leader.\n",
      "• Ensuring all the assigned software development and maintenance projects are completed as per defined timelines,\n",
      " improved project productivity, project defect density and other critical project management & delivery elements.\n",
      "Testing Excellence\n",
      "• Understand customer requirements.\n",
      "• Attended Daily Scrum Meeting and participated in weekly project status meeting and updated the testing Progress.\n",
      "• Implemented and maintained Agile standards and methodology.\n",
      "• Analysis of nightly execution and prepare bug Report in JIRA\n",
      "• Review, creation and execution of test cases, test scripts and documentations related to functional, backend and\n",
      " integration testing based on the user stories.\n",
      "• Participated in walkthroughs and defect report meetings periodically.\n",
      "• Managed software defect information, interacted with Business users to fix severity and priority of issues.\n",
      "• Attend the bug triage meeting every day in scrum call\n",
      "• Authoring and executing test cases, checking and installing the required set-ups, conducting integration/immigration\n",
      " testing, bug-fixing and ensuring successful deployment of test cases.\n",
      "• Adopting various testing methodologies for functional/regression testing and re-testing of released versions.\n",
      "• Monitoring and reviewing all documentation such as requirement, design and test plans; ensuring updation of the\n",
      " documents as per guidelines as a Peer Reviewer; designing and implementing the QA processes.\n",
      "• Idenifying and reporting the defects and bugs to the team; resolving the issues and minimizing the project risk.\n",
      "• Analyzing the project data related to testing and audits and ensuring compliance with the company/client requirements\n",
      " and norms; presenting the analysis data to senior leadership teams for informed decision making.\n",
      "• Analyzing project management and other technical documents to deduce the process gaps and ensure 100%\n",
      " compliance.\n",
      "\n",
      "• CMS (Combat Management System) for the Indian Navy (Cochin Shipyard Ltd); created and executed Unit Test\n",
      " Cases,Integration Test Cases, PSAT (Acceptance Test Cases), TVPR, ITP and TVPR/ITP Reports.\n",
      "• OGC Server (WMS, WCS and WFS) Web based testing for TCS; executed test cases, tracked and reported defects,\n",
      " conducted regression/re-testing of released versions, reported bugs, indentified test scenariors and more.\n",
      "• CCCOM, CCNCOM and CCC project for client Defense Electronics Research Lab (DLRL).\n",
      "• TCT, Mission Management, Data Fusion, LIU, SC2-SMS, SC2-NMS, DDU, FCC MK-11, MRSAM, and AAD projects.\n",
      "INDIAGAMES LTD, Mumbai, India\n",
      "Tester,June 2003 – Aug2003\n",
      "• Engaged in analysis and review of project requirements, regression testing, generating test defect documents and\n",
      " submitting the same to the development team for bug fixing.\n",
      "• Liaised with the Development team for validating testing on various mobile platforms.\n",
      "• Worked with a game testing client and recommended usage of different latest technology phones for improved testing\n",
      " results; identified bugs cutting the edges of the phones.\n",
      "LIONBRIDGE TECHNOLOGIES LTDMumbai, India\n",
      "Software Tester, Aug2002 –Nov 2002\n",
      "• Part of a 4 member team working on project – SASIXp responsible for testing activities such as requirement analysis,\n",
      ", Yogita B Kaskar\n",
      " ykaskar@yahoo.com | +91 92235 29541 | Mumbai, India\n",
      " regression testing, generating of test defect reports, ensuring bug fixing, and review of software documents.\n",
      "• Tracked and reported in a timely manner identified bugs/issues to the development team.\n",
      "• Ensured all requirements are adequately verified and documented within scope.\n",
      "HEXAWARE LTDMumbai, India\n",
      "Software Tester, 10/2000 – 11/2001\n",
      "• Gained experience of working with VC++ and SDK programming while working on porting projects; debugged issues\n",
      " with emulators.\n",
      "• Completed the modules allotted such as the console, keyboard, field, collections, and calendar class amongst others.\n",
      "\n",
      "IIT-MUMBAI (DEPARTMENT OF ELECTRICAL ENGINEERING)Mumbai, India\n",
      "Project Engineer, 1/1999 – 7/2000\n",
      "• Joined as a Fresher and performed research on the subject of Wavelet transformation; worked on project – Transient\n",
      " Detection using Wavelet Transform and debugged and coded in the Java Applets.\n",
      "• Engaged in developmental work using Java; designed and implemented software for user specific data and processing.\n",
      "• Technologies:Java, AWT, SWING, C, and Sun Solaris Workstation.\n",
      "\n",
      "\n",
      " EDUCATION\n",
      "\n",
      "TERNA ENGINEERING COLLEGE (UNIVERSITY OF MUMBAI)Mumbai, India\n",
      "B.E – Electronics\n",
      " CERTIFICATION\n",
      "Certification of ISTQB\n",
      "Certification in Audit|CMMI Interpretation\n",
      "\n",
      "\n",
      " TECHNICAL SKILLS\n",
      "\n",
      " C | C++ | Python| Java| JavaScript| Selenium| Squish| QTP| Jenkins| JIRA| TestRail| TFS| SQL| SqlLite | SoapUI|\n",
      " Postman| Oracle| VC++ | HTML | .NET | RFT | Win Runner | Load Runner | Web Testing| Database Testing |\n",
      " Mobile ,Games and API testing\n",
      "\n",
      "This is the output in the required_format:\n",
      "1. Functional tester @ Yethi Consulting FROM 09/2021 TO 11/2022 : Worked as a Functional tester at the client side BFSI and Loan Domain. Experience in Finacle ,Loans –SalesForce , Payment ,Collection. Responsible for analysing Bussiness,Functional ,Business Requirement Documents and preparing Complete TestPlan including System Test Plan,Integration TestPlan,QA Project Plan. Worked Data Driven testing using Selenium Web Driver ,TestNG functions. Involved in designing and implementing Selenium WebDriver Automation Frameworks for Smoke and regression testSuits. Used Maven for WebDriver Framework. Involved in automation frameworks in selenium WebDriver using Behavior Driven Approach like Cucumber. Used Postman API to get convenient, visual display of query results. Parameterised Testcases using different Annotation. Implemented PageObjectModel Automation framework for JAVA,Selenium WebDriver And Cucumber. Developed and executed SQL queries to verify Proper Insertion ,Deletion and Update into the Supporting Database. Web Service Request Response Validations using POSTMAN and SOAP UI. Worked with Developer ,Business Analyst and Project Manager to determine Requirements.\n",
      "2. Software Tester @ TATA POWER COMPANY FROM 11/2003 TO 06/2019 : Accountable for end-to-end software testing responsibilities as part of 12-15 member team. Responsibilities include project planning and monitoring, SQA quality assurance, configuration management, DAR/CAR, risk management, issue/bug-fixing management, development of process templates such as QPM, OPD, OPF, QPM, &PPM. Reporting to Project Team Leader. Ensuring all the assigned software development and maintenance projects are completed as per defined timelines, improved project productivity, project defect density and other critical project management & delivery elements. Testing Excellence. Understand customer requirements. Attended Daily Scrum Meeting and participated in weekly project status meeting and updated the testing Progress. Implemented and maintained Agile standards and methodology. Analysis of nightly execution and prepare bug Report in JIRA. Review, creation and execution of test cases, test scripts and documentations related to functional, backend and integration testing based on the user stories. Participated in walkthroughs and defect report meetings periodically. Managed software defect information, interacted with Business users to fix severity and priority of issues. Attend the bug triage meeting every day in scrum call. Authoring and executing test cases, checking and installing the required set-ups, conducting integration/immigration testing, bug-fixing and ensuring successful deployment of test cases. Adopting various testing methodologies for functional/regression testing and re-testing of released versions. Monitoring and reviewing all documentation such as requirement, design and test plans; ensuring updation of the documents as per guidelines as a Peer Reviewer; designing and implementing the QA processes. Idenifying and reporting the defects and bugs to the team; resolving the issues and minimizing the project risk. Analyzing project data related to testing and audits and ensuring compliance with the company/client requirements and norms; presenting the analysis data to senior leadership teams for informed decision making. Analyzing project management and other technical documents to deduce the process gaps and ensure 100% compliance.\n",
      "3. Tester @ INDIAGAMES LTD FROM 06/2003 TO 08/2003 : Engaged in analysis and review of project requirements, regression testing, generating of test defect documents and submitting the same to the development team for bug fixing. Liaised with the Development team for validating testing on various mobile platforms. Worked with a game testing client and recommended usage of different latest technology phones for improved testing results; identified bugs cutting the edges of the phones.\n",
      "4. Software Tester @ HEXAWARE LTD FROM 10/2000 TO 11/2001 : Joined as a Fresher and performed research on the subject of Wavelet transformation; worked on project – Transient Detection using Wavelet Transform and debugged and coded in the Java Applets. Engaged in developmental work using Java; designed and implemented software for user specific data and processing. Technologies:Java, AWT, SWING, C, and Sun Solaris Workstation.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import TextStreamer\n",
    "\n",
    "streamer = TextStreamer(tokenizer)\n",
    "model_input = tokenizer(ep,return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(tokenizer.decode(model.generate(**model_input, max_new_tokens=1024)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d10c4551b84447b38dd7729fc9f4b517",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/109M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/lakshay/linear-work-peft/commit/8f26b5b94e0eab70f00f4ac481c42076890982fc', commit_message='Upload model', commit_description='', oid='8f26b5b94e0eab70f00f4ac481c42076890982fc', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub('lakshay/linear-work-peft',token='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "2d58e898dde0263bc564c6968b04150abacfd33eed9b19aaa8e45c040360e146"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
