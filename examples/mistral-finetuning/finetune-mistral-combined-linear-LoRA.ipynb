{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 1: Load the model\n",
    "\n",
    "Point model_id to model weight folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "train_data = load_from_disk(\"../custom_data/mistral/combined_work_edu_data.hf/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu May  9 16:17:52 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.154.05             Driver Version: 535.154.05   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A10G                    Off | 00000000:00:1E.0 Off |                    0 |\n",
      "|  0%   23C    P8               9W / 300W |      0MiB / 23028MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/ubuntu/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login(token='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Important \n",
    "\n",
    "It is important to consider here which model we're using to parse the resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BitsAndBytesConfig\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12b58e4c511a4f1cb453b575837a5861",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_id=\"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map='auto',token='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.append('/home/ec2-user/SageMaker/llama_root/src')\n",
    "sys.path.append('../llama-recipes/src/llama_recipes/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Check base model\n",
    "\n",
    "Run the base model on an example input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "eval_prompt = f'''\n",
    "You are an accurate agent working for a job platform. You will be given the raw \n",
    "unstructured text of a user's resume, and the task is to extract details of the user's \n",
    "work experience. The details required are the designation, company name, start date and end date.\n",
    "The response should be broken into a numbered list with each item of the list \n",
    "containing the complete and accurate information about the work experience of the users.\n",
    "1. Designation 1 @ Company 1 [From \"mm/yyy\" to \"mm/yyyy\"] : \\n\n",
    "2. Designation 2 @ Company 2 [From \"mm/yyy\" to \"mm/yyyy\"] : \\n\n",
    "Please follow this structure closely and keep the response within the token limit. Do not \" \n",
    "\n",
    "This is the resume text:\\n{{resume_text}}\\n\n",
    "This is the output in the required_format:\\n'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample1 = '''\n",
    "VEDANK SINGH 20 20\n",
    "Full-Stack Developer 11 20\n",
    "Mob: (+91)8004827441 11 4\n",
    "E-mail ID: 11 4\n",
    "vedank.singh@outlook.com 11 4\n",
    "LinkedIn: 11 4\n",
    "https://www.linkedin.com/in/vedank-singh-078838109 11 4\n",
    "Professional Summary: 14 20\n",
    "• 11 4\n",
    "Determined, passionate and hardworking IT professional with 4+ years of 11 4\n",
    "experience in Full Stack development. I am highly adept at Java, JavaScript, 11 4\n",
    "Python, Oracle Database, SpringBoot, React and Public Speaking. 11 4\n",
    "• 11 4\n",
    "Excellent code reviews and code debugging skills. 11 4\n",
    "• 12 4\n",
    "Experienced in all stages of SDLC from requirement gathering to deployment. 11 4\n",
    "Professional Experience: 14 20\n",
    "Technical Skill Set: 14 20\n",
    "Period 11 20\n",
    "Company 11 20\n",
    "Role 11 20\n",
    "31/05/21 to Present 11 4\n",
    "JP Morgan Chase & Co. 11 4\n",
    "Software Engineer 11 4\n",
    "16/04/18 to 28/05/21 11 4\n",
    "Tata Consultancy Services 11 4\n",
    "System Engineer 11 4\n",
    "Programming languages 11 20\n",
    "Java, Javascript, Python 11 4\n",
    "Web Designing Languages 11 20\n",
    "React.js, HTML, CSS, AJAX, JQuery 11 4\n",
    "Frameworks 11 20\n",
    "Flask, Servlet, SpringBoot, Microservices, 11 4\n",
    "Anaconda, Kerberos, Pandas, IDA, REST 11 4\n",
    "Operating Systems 11 20\n",
    "Linux (Redhat), Windows 11 4\n",
    "Database 11 20\n",
    "Oracle 11 4\n",
    "Tools 11 20\n",
    "Sourcetree, Bitbucket, Git, SVN, Jenkins, 11 4\n",
    "Jules, Postman, Jmeter, Autosys, Jira, 11 4\n",
    "Putty, Confluence, DevPlus 11 4\n",
    "Servers 11 20\n",
    "Apache Tomcat, Gunicorn 11 4\n",
    "Testing Framework 11 20\n",
    "Pytest, Mockito 11 4\n",
    "'''\n",
    "\n",
    "sample2 = '''\n",
    "Professional Summary: 14 20\n",
    "• 11 4\n",
    "Determined, passionate and hardworking IT professional with 4+ years of 11 4\n",
    "experience in Full Stack development. I am highly adept at Java, JavaScript, 11 4\n",
    "Python, Oracle Database, SpringBoot, React and Public Speaking. 11 4\n",
    "• 11 4\n",
    "Excellent code reviews and code debugging skills. 11 4\n",
    "• 12 4\n",
    "Experienced in all stages of SDLC from requirement gathering to deployment. 11 4\n",
    "Professional Experience: 14 20\n",
    "Technical Skill Set: 14 20\n",
    "Period 11 20\n",
    "Company 11 20\n",
    "Role 11 20\n",
    "31/05/21 to Present 11 4\n",
    "JP Morgan Chase & Co. 11 4\n",
    "Software Engineer 11 4\n",
    "16/04/18 to 28/05/21 11 4\n",
    "Tata Consultancy Services 11 4\n",
    "System Engineer 11 4\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ep = eval_prompt.format(resume_text=sample2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are an accurate agent working for a job platform. You will be given the raw \n",
      "unstructured text of a user's resume, and the task is to extract details of the user's \n",
      "work experience. The details required are the designation, company name, start date and end date.\n",
      "The response should be broken into a numbered list with each item of the list \n",
      "containing the complete and accurate information about the work experience of the users.\n",
      "1. Designation 1 @ Company 1 [From \"mm/yyy\" to \"mm/yyyy\"]\n",
      "\n",
      "2. Designation 2 @ Company 2 [From \"mm/yyy\" to \"mm/yyyy\"]\n",
      "\n",
      "Please follow this structure closely and keep the response within the token limit.\" \n",
      "\n",
      "This is the resume text:\n",
      "\n",
      "Professional Summary: 14 20\n",
      "• 11 4\n",
      "Determined, passionate and hardworking IT professional with 4+ years of 11 4\n",
      "experience in Full Stack development. I am highly adept at Java, JavaScript, 11 4\n",
      "Python, Oracle Database, SpringBoot, React and Public Speaking. 11 4\n",
      "• 11 4\n",
      "Excellent code reviews and code debugging skills. 11 4\n",
      "• 12 4\n",
      "Experienced in all stages of SDLC from requirement gathering to deployment. 11 4\n",
      "Professional Experience: 14 20\n",
      "Technical Skill Set: 14 20\n",
      "Period 11 20\n",
      "Company 11 20\n",
      "Role 11 20\n",
      "31/05/21 to Present 11 4\n",
      "JP Morgan Chase & Co. 11 4\n",
      "Software Engineer 11 4\n",
      "16/04/18 to 28/05/21 11 4\n",
      "Tata Consultancy Services 11 4\n",
      "System Engineer 11 4\n",
      "\n",
      "\n",
      "This is the output in the required_format:\n",
      "\n",
      "1. Software Engineer @ JP Morgan Chase & Co. [From \"05/21\" to \"Present\"]\n",
      "\n",
      "2. System Engineer @ Tata Consultancy Services [From \"04/18\" to \"05/21\"]\n",
      "Time taken :3.920314073562622\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "model_input = tokenizer(ep,return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(tokenizer.decode(model.generate(**model_input, max_new_tokens=1024)[0], skip_special_tokens=True))\n",
    "\n",
    "print(f'Time taken :{time.time()-start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "We can see that the base model only repeats the conversation.\n",
    "\n",
    "### Step 4: Prepare model for PEFT\n",
    "\n",
    "Let's prepare the model for Parameter Efficient Fine Tuning (PEFT):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/infoedge/llama-recipes/env/lib/python3.10/site-packages/peft/utils/other.py:141: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 27,262,976 || all params: 7,268,995,072 || trainable%: 0.3750583915652433\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "def create_peft_config(model):\n",
    "    from peft import (\n",
    "        get_peft_model,\n",
    "        LoraConfig,\n",
    "        TaskType,\n",
    "        prepare_model_for_int8_training,\n",
    "    )\n",
    "\n",
    "    peft_config = LoraConfig(\n",
    "        task_type=TaskType.CAUSAL_LM,\n",
    "        inference_mode=False,\n",
    "        r=64,\n",
    "        lora_alpha=32,\n",
    "        lora_dropout=0.05,\n",
    "        target_modules = [\"q_proj\", \"v_proj\"]\n",
    "    )\n",
    "    \n",
    "    # peft_config = LoraConfig(\n",
    "    #     task_type=TaskType.CAUSAL_LM,\n",
    "    #     inference_mode=False,\n",
    "    #     r=8,\n",
    "    #     lora_alpha=32,\n",
    "    #     lora_dropout=0.05,\n",
    "    #     target_modules = [\"q_proj\", \"v_proj\"]\n",
    "    # )\n",
    "\n",
    "    # prepare int-8 model for training\n",
    "    model = prepare_model_for_int8_training(model)\n",
    "    model = get_peft_model(model, peft_config)\n",
    "    model.print_trainable_parameters()\n",
    "    return model, peft_config\n",
    "\n",
    "# create peft config\n",
    "model, lora_config = create_peft_config(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Step 5: Define an optional profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import TrainerCallback\n",
    "from contextlib import nullcontext\n",
    "enable_profiler = False\n",
    "output_dir = \"tmp/linear_workex\"\n",
    "\n",
    "config = {\n",
    "    'lora_config': lora_config,\n",
    "    'learning_rate': 1e-4,\n",
    "    'num_train_epochs': 4,\n",
    "    'gradient_accumulation_steps': 2,\n",
    "    'per_device_train_batch_size': 2,\n",
    "    'gradient_checkpointing': False,\n",
    "}\n",
    "\n",
    "# Set up profiler\n",
    "if enable_profiler:\n",
    "    wait, warmup, active, repeat = 1, 1, 2, 1\n",
    "    total_steps = (wait + warmup + active) * (1 + repeat)\n",
    "    schedule =  torch.profiler.schedule(wait=wait, warmup=warmup, active=active, repeat=repeat)\n",
    "    profiler = torch.profiler.profile(\n",
    "        schedule=schedule,\n",
    "        on_trace_ready=torch.profiler.tensorboard_trace_handler(f\"{output_dir}/logs/tensorboard\"),\n",
    "        record_shapes=True,\n",
    "        profile_memory=True,\n",
    "        with_stack=True)\n",
    "    \n",
    "    class ProfilerCallback(TrainerCallback):\n",
    "        def __init__(self, profiler):\n",
    "            self.profiler = profiler\n",
    "            \n",
    "        def on_step_end(self, *args, **kwargs):\n",
    "            self.profiler.step()\n",
    "\n",
    "    profiler_callback = ProfilerCallback(profiler)\n",
    "else:\n",
    "    profiler = nullcontext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu May  9 16:18:57 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.154.05             Driver Version: 535.154.05   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A10G                    Off | 00000000:00:1E.0 Off |                    0 |\n",
      "|  0%   29C    P0              60W / 300W |   5966MiB / 23028MiB |      1%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A     16467      C   ...oedge/llama-recipes/env/bin/python3     5958MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Fine tune the model\n",
    "\n",
    "Here, we fine tune the model for a single epoch which takes a bit more than an hour on a A100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 16:18:59.175563: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-09 16:19:00.211387: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-09 16:19:01.740571: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "/home/ubuntu/infoedge/llama-recipes/env/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='256' max='256' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [256/256 1:00:26, Epoch 3/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.169600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.021500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.971000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.925500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.868100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.939200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.828800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.808600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.815200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.821400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>1.686700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.738700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>1.726000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.640700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>1.652400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.685100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>1.739100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.738400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>1.732700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.759800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>1.688800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.659900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>1.818800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.717100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>1.624200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.781400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>1.602600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.716800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>1.685900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.765100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>1.614900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.660900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>1.703400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.590500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>1.522900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.635200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185</td>\n",
       "      <td>1.644500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.623400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>1.747700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.657600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>205</td>\n",
       "      <td>1.641800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.730300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>215</td>\n",
       "      <td>1.627200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.665100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>1.602200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1.684000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>235</td>\n",
       "      <td>1.691000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.580600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>245</td>\n",
       "      <td>1.598600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.587000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>255</td>\n",
       "      <td>1.583100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import default_data_collator, Trainer, TrainingArguments\n",
    "\n",
    "# Define training args\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "    bf16=True,  # Use BF16 if available\n",
    "    # logging strategies\n",
    "    logging_dir=f\"{output_dir}/logs\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=5,\n",
    "    save_strategy=\"no\",\n",
    "    optim=\"adamw_torch_fused\",\n",
    "    max_steps=total_steps if enable_profiler else -1,\n",
    "    **{k:v for k,v in config.items() if k != 'lora_config'}\n",
    ")\n",
    "\n",
    "with profiler:\n",
    "    # Create Trainer instance\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_data,\n",
    "        data_collator=default_data_collator,\n",
    "        callbacks=[profiler_callback] if enable_profiler else [],\n",
    "    )\n",
    "\n",
    "    # Start training\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 7:\n",
    "Save model checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 8:\n",
    "Try the fine tuned model on the same example again to see the learning progress:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_df = pd.read_csv('../custom_data/model_eval_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(161, 5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import html, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Last Updated on August 12th, 2023\n",
      "\n",
      " Atchaya Meena B Va\n",
      " § github.com/meenabva # bvaameena@gmail.com\n",
      "\n",
      "Education\n",
      " National Institute of Technology, Karnataka 2018 - 2022\n",
      " BTech in Electronics and Communication CGPA: 7.21\n",
      "\n",
      "Relevant Coursework\n",
      " Courses: Computer Programming in C, Deep Learning and Neural Networks, Speech and Audio Processing,\n",
      " Image and Video Processing.\n",
      "\n",
      "Skills\n",
      " Languages: Java, Python, JavaScript/TypeScript, HTML/CSS\n",
      " Frameworks: Springboot, React, Node.js, Angular, Express.js\n",
      " Databases: MySQL, MongoDB\n",
      " Tools: Git/GitHub, VS Code, Eclipse IDE, Figma\n",
      " Interpersonal Skills: Teamworker, Fast Learner, Adaptable, Dependable\n",
      "\n",
      "Experience\n",
      " Capgemini | Associate Software Engineer Sept 2022 - Present\n",
      " • Developed REST APIs using ExpressJs and Spring Boot.\n",
      " • Utilized React and Angular for front-end development.\n",
      " • Enhanced user-friendliness of the front-end interface.\n",
      " • Achieved a 2nd-place victory in a department-wide Hackathon competition.\n",
      "\n",
      "Projects\n",
      " ToDo List | Springboot, MongoDB, React June 2023\n",
      " • Created a Full Stack Application to store ToDo items.\n",
      "\n",
      " • Implemented user authentication using Spring Security and JWT\n",
      "\n",
      "\n",
      " Online Pharmacy Store | Express.js, MongoDB, React, Angular Oct 2022\n",
      " • Developed a full-stack web application for a Pharmacy store.\n",
      "\n",
      " • Developed both User Side and Admin side of the store.\n",
      "\n",
      " • Implemented user authentication using JWT.\n",
      "\n",
      " • Made Use of Github to collaborate with team.\n",
      "\n",
      "\n",
      " Deep Learning for sentiment classification of text data | Python, Numpy, OpenCV, Jupyter Notebook Jan 2022\n",
      " • Used word embedding method to extract features from the preprocessed text data.\n",
      "\n",
      " • Passed the features through different deep learning models to classify the text data as either positive or negative.\n",
      "\n",
      "\n",
      " Gender identification from children’s speech | Python, Numpy, OpenCV, Jupyter Notebook Oct 2021\n",
      " • Cleaned up the audio data for feature extraction.\n",
      "\n",
      " • Made usage of python libraries to extract features from audio samples of children’s voice.\n",
      "\n",
      " • Classified the data as either male or female by feeding different feature combinations through ANN, DNN and a\n",
      "\n",
      " Random forest classifier.\n",
      "\n",
      "Courses\n",
      " • Java Web Services and REST API with Spring Boot – Udemy\n",
      " • Java Microservices with Spring Cloud: Developing Services – Pluralsight\n",
      " • Developing Front-End Apps with React – Coursera\n",
      " • Foundations of User Experience (UX) Design – Coursera\n"
     ]
    }
   ],
   "source": [
    "rt = eval_df.sample(random_state=random.randint(0,10000))['resume'].values[0]\n",
    "rt = html.unescape(rt)\n",
    "\n",
    "print(rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "eval_prompt = f'''\n",
    "You are an accurate agent working for a job platform. You will be given the raw \n",
    "unstructured text of a user's resume, and the task is to extract the entire work experience of the \n",
    "user from the resume. The response should be presented into a numbered list with each item of the list \n",
    "being an unbroken line of text containing the complete and accurate information about the work experience of the users. \n",
    "Here is an example structure:\\n\n",
    "1. Designation 1 @ Company 1 [From \"mm/yyy\" to \"mm/yyyy\"] :\\n\n",
    "2. Designation 2 @ Company 2 [From \"mm/yyy\" to \"mm/yyyy\"] :\\n\n",
    "Please follow this structure accurately and keep the response within the token limit.\" \n",
    "\n",
    "This is the resume text:\\n{{resume_text}}\\n\n",
    "This is the output in the required_format:\\n'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "edu_prompt = f'''\n",
    "[INST]You are an accurate agent working for a job platform. You will be given the raw \n",
    "unstructured text of a user's resume, and the task is to extract the education history of the \n",
    "user at the graduate and post graduate level only. The response should be broken into a numbered list with each item of the list \n",
    "containing the complete and accurate information about the education of the users. Here is an example structure:\\n\n",
    "1. Degree/Program Name 1 @ Institute 1 [From \"mm/yyyy\" to \"mm/yyyy\"] :\\n\n",
    "2. Degree/Program Name 2 @ Institute 2 [From \"mm/yyyy\" to \"mm/yyyy\"] :\\n\n",
    "Please follow this structure closely and keep the response within the token limit[\\INST] \n",
    "\n",
    "This is the resume text:\\n{{resume_text}}\\n\n",
    "This is the output in the required_format:\\n\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "edu_p = edu_prompt.format(resume_text=rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ep = eval_prompt.format(resume_text=rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> \n",
      "You are an accurate agent working for a job platform. You will be given the raw \n",
      "unstructured text of a user's resume, and the task is to extract the entire work experience of the \n",
      "user from the resume. The response should be presented into a numbered list with each item of the list \n",
      "being an unbroken line of text containing the complete and accurate information about the work experience of the users. \n",
      "Here is an example structure:\n",
      "\n",
      "1. Designation 1 @ Company 1 [From \"mm/yyy\" to \"mm/yyyy\"] :\n",
      "\n",
      "2. Designation 2 @ Company 2 [From \"mm/yyy\" to \"mm/yyyy\"] :\n",
      "\n",
      "Please follow this structure accurately and keep the response within the token limit.\" \n",
      "\n",
      "This is the resume text:\n",
      "Neeraj Mourya Professional Summary\n",
      "Software Engineer Analytical and Innovative Software Engineer with 1.5 years of experience in\n",
      " creating robust and efficient software solutions and deploying them on Linux\n",
      "Contact and Windows servers. I'm dedicated to creating clean, scalable, and user-\n",
      " centric solutions. Seeking opportunities to contribute my technical skills and\n",
      "Phone passion for software development to create cutting-edge solutions.\n",
      "+91 9673473826\n",
      "\n",
      "Email\n",
      " Experience [1.5 yrs]\n",
      "neerajmourya9165@gmail.com\n",
      " September 2022 - Present\n",
      "Address Nexgensis Technologies Private Limited l Viman Nagar, Pune\n",
      "Kharadi,Pune-411014 Software Engineer\n",
      " Working on the backend part of the applications in Django using Python and\n",
      "Education maintaining databases.\n",
      " Involved in direct client interaction and in the software development life\n",
      "BE - 2021 74.48% cycle(SDLC) of tracking the requirements gathering, analysis, detailed design,\n",
      "Computer Science and development.\n",
      "Savitribai Phule University Creating automated alerts, notifications, and APIs as per requirement.\n",
      " Working closely with cross-functional teams(DevOps, Frontend,QA,Integration)\n",
      " to improve the user interface and integrate the API’s.\n",
      "HSC - 2016 62.62%\n",
      " Writing scripts for data transformation and data generation using numpy and\n",
      "S V Union Jr. College\n",
      " pandas libraries.\n",
      " Handling day-to-day issues and fine-tuning the applications for enhanced\n",
      "SSC - 2014 71.71% performance.\n",
      "Stella Maris High School\n",
      " Projects\n",
      " 1-Raams(Rental and Asset Management Service)\n",
      "Skills Purpose: Providing a web and mobile application for PG property owners to\n",
      " streamline property management.\n",
      " Implemented the MVT Architecture for developing the web application using Django\n",
      " Framework(Backend), ReactJS (web app), and Flutter(Mobile app).\n",
      " C, C++\n",
      " Utilized Django rest Framework for creating REST APIs and collaborated with other\n",
      " Python\n",
      " teams to integrate these API’s.\n",
      " Django Framework and DRF\n",
      " Used SQL and Django ORM queries for interacting with the database and\n",
      " SQL, POSTGRESQL\n",
      " performing CRUD operations and providing various analytics.\n",
      " HTML,CSS\n",
      " GCP Dialogflow 2-Manufacturing Industry Plant Analysis\n",
      " GIT (Github)\n",
      " Purpose: Enhancing efficiency and reducing downtime by improving production\n",
      " AWS EC2,S3\n",
      " rates in the plant.\n",
      " Linux\n",
      " Implemented data visualization processes by storing data in databases and\n",
      " Postman\n",
      " creating REST APIs for visualization and comparison of this stored data.\n",
      "Personal Traits Designed and implemented a solution that monitors and analyzes production lines\n",
      " in real-time.\n",
      " Implemented a feature that detects and alerts relevant personnel in case of\n",
      " breakdowns.\n",
      " Continuous Learner Achieved a 20% increase in production efficiency through streamlined processes,\n",
      " Collaborative team player leading to cost savings and higher productivity.\n",
      " Strong problem solving skills Decreased breakdown time by 20-30% through proactive maintenance and\n",
      " Agile Mindset improved troubleshooting techniques.\n",
      "\n",
      " September 2020 - March 2021\n",
      "Language\n",
      " Cloudage l Kondwa, Pune\n",
      " Intern\n",
      " English Implemented a virtual assistant solution for the company that will be available\n",
      " Hindi 24*7 for customer queries resolution using GCP DialogFlow.\n",
      " Marathi Integrated the virtual assistant with the company's website, Google Assistant, and\n",
      " other platforms like Telegram, Whatsapp, etc.\n",
      " Creating Python scripts for data transformation and data cleaning in order to feed\n",
      " the data to the model.\n",
      "\n",
      "This is the output in the required_format:\n",
      "1. Software Engineer @ Nexgensis Technologies Private Limited FROM 09/2022 TO present\n",
      "2. Intern @ Cloudage FROM 09/2020 TO 03/2021\n",
      "\n",
      "</s>\n",
      "\n",
      "You are an accurate agent working for a job platform. You will be given the raw \n",
      "unstructured text of a user's resume, and the task is to extract the entire work experience of the \n",
      "user from the resume. The response should be presented into a numbered list with each item of the list \n",
      "being an unbroken line of text containing the complete and accurate information about the work experience of the users. \n",
      "Here is an example structure:\n",
      "\n",
      "1. Designation 1 @ Company 1 [From \"mm/yyy\" to \"mm/yyyy\"] :\n",
      "\n",
      "2. Designation 2 @ Company 2 [From \"mm/yyy\" to \"mm/yyyy\"] :\n",
      "\n",
      "Please follow this structure accurately and keep the response within the token limit.\" \n",
      "\n",
      "This is the resume text:\n",
      "Neeraj Mourya Professional Summary\n",
      "Software Engineer Analytical and Innovative Software Engineer with 1.5 years of experience in\n",
      " creating robust and efficient software solutions and deploying them on Linux\n",
      "Contact and Windows servers. I'm dedicated to creating clean, scalable, and user-\n",
      " centric solutions. Seeking opportunities to contribute my technical skills and\n",
      "Phone passion for software development to create cutting-edge solutions.\n",
      "+91 9673473826\n",
      "\n",
      "Email\n",
      " Experience [1.5 yrs]\n",
      "neerajmourya9165@gmail.com\n",
      " September 2022 - Present\n",
      "Address Nexgensis Technologies Private Limited l Viman Nagar, Pune\n",
      "Kharadi,Pune-411014 Software Engineer\n",
      " Working on the backend part of the applications in Django using Python and\n",
      "Education maintaining databases.\n",
      " Involved in direct client interaction and in the software development life\n",
      "BE - 2021 74.48% cycle(SDLC) of tracking the requirements gathering, analysis, detailed design,\n",
      "Computer Science and development.\n",
      "Savitribai Phule University Creating automated alerts, notifications, and APIs as per requirement.\n",
      " Working closely with cross-functional teams(DevOps, Frontend,QA,Integration)\n",
      " to improve the user interface and integrate the API’s.\n",
      "HSC - 2016 62.62%\n",
      " Writing scripts for data transformation and data generation using numpy and\n",
      "S V Union Jr. College\n",
      " pandas libraries.\n",
      " Handling day-to-day issues and fine-tuning the applications for enhanced\n",
      "SSC - 2014 71.71% performance.\n",
      "Stella Maris High School\n",
      " Projects\n",
      " 1-Raams(Rental and Asset Management Service)\n",
      "Skills Purpose: Providing a web and mobile application for PG property owners to\n",
      " streamline property management.\n",
      " Implemented the MVT Architecture for developing the web application using Django\n",
      " Framework(Backend), ReactJS (web app), and Flutter(Mobile app).\n",
      " C, C++\n",
      " Utilized Django rest Framework for creating REST APIs and collaborated with other\n",
      " Python\n",
      " teams to integrate these API’s.\n",
      " Django Framework and DRF\n",
      " Used SQL and Django ORM queries for interacting with the database and\n",
      " SQL, POSTGRESQL\n",
      " performing CRUD operations and providing various analytics.\n",
      " HTML,CSS\n",
      " GCP Dialogflow 2-Manufacturing Industry Plant Analysis\n",
      " GIT (Github)\n",
      " Purpose: Enhancing efficiency and reducing downtime by improving production\n",
      " AWS EC2,S3\n",
      " rates in the plant.\n",
      " Linux\n",
      " Implemented data visualization processes by storing data in databases and\n",
      " Postman\n",
      " creating REST APIs for visualization and comparison of this stored data.\n",
      "Personal Traits Designed and implemented a solution that monitors and analyzes production lines\n",
      " in real-time.\n",
      " Implemented a feature that detects and alerts relevant personnel in case of\n",
      " breakdowns.\n",
      " Continuous Learner Achieved a 20% increase in production efficiency through streamlined processes,\n",
      " Collaborative team player leading to cost savings and higher productivity.\n",
      " Strong problem solving skills Decreased breakdown time by 20-30% through proactive maintenance and\n",
      " Agile Mindset improved troubleshooting techniques.\n",
      "\n",
      " September 2020 - March 2021\n",
      "Language\n",
      " Cloudage l Kondwa, Pune\n",
      " Intern\n",
      " English Implemented a virtual assistant solution for the company that will be available\n",
      " Hindi 24*7 for customer queries resolution using GCP DialogFlow.\n",
      " Marathi Integrated the virtual assistant with the company's website, Google Assistant, and\n",
      " other platforms like Telegram, Whatsapp, etc.\n",
      " Creating Python scripts for data transformation and data cleaning in order to feed\n",
      " the data to the model.\n",
      "\n",
      "This is the output in the required_format:\n",
      "1. Software Engineer @ Nexgensis Technologies Private Limited FROM 09/2022 TO present\n",
      "2. Intern @ Cloudage FROM 09/2020 TO 03/2021\n",
      "\n",
      "\n",
      "time taken : 4.667935132980347\n"
     ]
    }
   ],
   "source": [
    "from transformers import TextStreamer\n",
    "\n",
    "streamer = TextStreamer(tokenizer)\n",
    "model_input = tokenizer(ep,return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "start_time = time.time()\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(tokenizer.decode(model.generate(**model_input, max_new_tokens=512,streamer=streamer)[0], skip_special_tokens=True))\n",
    "print(f'time taken : {time.time()-start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INST]You are an accurate agent working for a job platform. You will be given the raw \n",
      "unstructured text of a user's resume, and the task is to extract the education history of the \n",
      "user at the graduate and post graduate level only. The response should be broken into a numbered list with each item of the list \n",
      "containing the complete and accurate information about the education of the users. Here is an example structure:\n",
      "\n",
      "1. Degree/Program Name 1 @ Institute 1 [From \"mm/yyyy\" to \"mm/yyyy\"] :\n",
      "\n",
      "2. Degree/Program Name 2 @ Institute 2 [From \"mm/yyyy\" to \"mm/yyyy\"] :\n",
      "\n",
      "Please follow this structure closely and keep the response within the token limit[\\INST] \n",
      "\n",
      "This is the resume text:\n",
      "Neeraj Mourya Professional Summary\n",
      "Software Engineer Analytical and Innovative Software Engineer with 1.5 years of experience in\n",
      " creating robust and efficient software solutions and deploying them on Linux\n",
      "Contact and Windows servers. I'm dedicated to creating clean, scalable, and user-\n",
      " centric solutions. Seeking opportunities to contribute my technical skills and\n",
      "Phone passion for software development to create cutting-edge solutions.\n",
      "+91 9673473826\n",
      "\n",
      "Email\n",
      " Experience [1.5 yrs]\n",
      "neerajmourya9165@gmail.com\n",
      " September 2022 - Present\n",
      "Address Nexgensis Technologies Private Limited l Viman Nagar, Pune\n",
      "Kharadi,Pune-411014 Software Engineer\n",
      " Working on the backend part of the applications in Django using Python and\n",
      "Education maintaining databases.\n",
      " Involved in direct client interaction and in the software development life\n",
      "BE - 2021 74.48% cycle(SDLC) of tracking the requirements gathering, analysis, detailed design,\n",
      "Computer Science and development.\n",
      "Savitribai Phule University Creating automated alerts, notifications, and APIs as per requirement.\n",
      " Working closely with cross-functional teams(DevOps, Frontend,QA,Integration)\n",
      " to improve the user interface and integrate the API’s.\n",
      "HSC - 2016 62.62%\n",
      " Writing scripts for data transformation and data generation using numpy and\n",
      "S V Union Jr. College\n",
      " pandas libraries.\n",
      " Handling day-to-day issues and fine-tuning the applications for enhanced\n",
      "SSC - 2014 71.71% performance.\n",
      "Stella Maris High School\n",
      " Projects\n",
      " 1-Raams(Rental and Asset Management Service)\n",
      "Skills Purpose: Providing a web and mobile application for PG property owners to\n",
      " streamline property management.\n",
      " Implemented the MVT Architecture for developing the web application using Django\n",
      " Framework(Backend), ReactJS (web app), and Flutter(Mobile app).\n",
      " C, C++\n",
      " Utilized Django rest Framework for creating REST APIs and collaborated with other\n",
      " Python\n",
      " teams to integrate these API’s.\n",
      " Django Framework and DRF\n",
      " Used SQL and Django ORM queries for interacting with the database and\n",
      " SQL, POSTGRESQL\n",
      " performing CRUD operations and providing various analytics.\n",
      " HTML,CSS\n",
      " GCP Dialogflow 2-Manufacturing Industry Plant Analysis\n",
      " GIT (Github)\n",
      " Purpose: Enhancing efficiency and reducing downtime by improving production\n",
      " AWS EC2,S3\n",
      " rates in the plant.\n",
      " Linux\n",
      " Implemented data visualization processes by storing data in databases and\n",
      " Postman\n",
      " creating REST APIs for visualization and comparison of this stored data.\n",
      "Personal Traits Designed and implemented a solution that monitors and analyzes production lines\n",
      " in real-time.\n",
      " Implemented a feature that detects and alerts relevant personnel in case of\n",
      " breakdowns.\n",
      " Continuous Learner Achieved a 20% increase in production efficiency through streamlined processes,\n",
      " Collaborative team player leading to cost savings and higher productivity.\n",
      " Strong problem solving skills Decreased breakdown time by 20-30% through proactive maintenance and\n",
      " Agile Mindset improved troubleshooting techniques.\n",
      "\n",
      " September 2020 - March 2021\n",
      "Language\n",
      " Cloudage l Kondwa, Pune\n",
      " Intern\n",
      " English Implemented a virtual assistant solution for the company that will be available\n",
      " Hindi 24*7 for customer queries resolution using GCP DialogFlow.\n",
      " Marathi Integrated the virtual assistant with the company's website, Google Assistant, and\n",
      " other platforms like Telegram, Whatsapp, etc.\n",
      " Creating Python scripts for data transformation and data cleaning in order to feed\n",
      " the data to the model.\n",
      "\n",
      "This is the output in the required_format:\n",
      "\n",
      "1. BE - 2021 @ Savitribai Phule University FROM 05/2021 TO 05/2021\n",
      "2. HSC - 2016 @ S V Union Jr. College FROM 05/2016 TO 05/2016\n",
      "3. SSC - 2014 @ Stella Maris High School FROM 05/2014 TO 05/2014\n",
      "\n",
      "\n",
      "time taken : 8.430961608886719\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "model_input = tokenizer(edu_p,return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(tokenizer.decode(model.generate(**model_input, max_new_tokens=512)[0], skip_special_tokens=True))\n",
    "\n",
    "print(f'time taken : {time.time()-start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f3ccfd7ff4c443593a90d1d27291e88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/109M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/lakshay/mistral-combined/commit/c9d8cd36195bb5509a7bb8b258b06f8c3bd9d550', commit_message='Upload model', commit_description='', oid='c9d8cd36195bb5509a7bb8b258b06f8c3bd9d550', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub('lakshay/mistral-combined',token='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "2d58e898dde0263bc564c6968b04150abacfd33eed9b19aaa8e45c040360e146"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
