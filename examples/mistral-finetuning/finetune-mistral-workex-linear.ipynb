{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 1: Load the model\n",
    "\n",
    "Point model_id to model weight folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "train_data = load_from_disk(\"../custom_data/mistral/linear_work_data.hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon May  6 11:00:21 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.154.05             Driver Version: 535.154.05   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A10G                    Off | 00000000:00:1E.0 Off |                    0 |\n",
      "|  0%   29C    P0              52W / 300W |      0MiB / 23028MiB |      4%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/ubuntu/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login(token='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Important \n",
    "\n",
    "It is important to consider here which model we're using to parse the resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b92e3d2b2a034fb3ba996e2c335710ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_id=\"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, load_in_4bit=True, device_map='auto', torch_dtype=torch.float16, token='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.append('/home/ec2-user/SageMaker/llama_root/src')\n",
    "sys.path.append('../llama-recipes/src/llama_recipes/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Check base model\n",
    "\n",
    "Run the base model on an example input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "eval_prompt = f'''\n",
    "You are an accurate agent working for a job platform. You will be given the raw \n",
    "unstructured text of a user's resume, and the task is to extract the entire work experience of the \n",
    "user from the resume. The response should be broken into a numbered list with each item of the list \n",
    "containing the complete and accurate information about the work experience of the users.\n",
    "1. Designation 1 @ Company 1 [From \"mm/yyy\" to \"mm/yyyy\"] : \"complete job description as given in resume\"\\n\n",
    "2. Designation 2 @ Company 2 [From \"mm/yyy\" to \"mm/yyyy\"] :  \"complete job description as given in resume\"\\n\n",
    "Please follow this structure closely and keep the response within the token limit.\" \n",
    "\n",
    "This is the resume text:\\n{{resume_text}}\\n\n",
    "This is the output in the required_format:\\n'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "example_resume_text = '''\n",
    " S\\n EVANAND\\n\\n\\nEmail: sevaanand863@gmail.com\\nMobile: +919110416415\\n\\n\\nPROFESSIONAL SUMMARY:\\n Having 2+ years of technical experience in Analysis, Design, Development, Testing\\n and Implementation of Client Server Application and Data warehousing ETL (Extract,\\n Transform and Load) in Informatica Power Center 10.4 and INFORMATICA intelligent\\n cloud services.\\n Main areas of expertise are Developing and Testing the data warehousing\\n projects with data quality standards.\\n Extensive experience in Extraction, Transformation and Loading of data\\n directly from heterogeneous source systems like fat fles, Oracle by using\\n Informatica power center.\\n Tuned several mappings for the better performance and involved in Performance\\n Testing.\\n Implemented exceptional handling mechanism by using Exception transformation &amp;\\n Human Task.\\n Creating Informatica IICS mappings for the diferent plans using various\\n transformations.\\n Have working experience in Informatica Intelligent Cloud Services IICS components -\\n application integration, data integration, Informatica data quality and Informatica\\n power center and CRM application - Salesforce.\\n Worked on SCD Type1,SCD Type2 in IICS\\n Worked on Mapping, Mapping Task, Mapplet, Task Flows\\n Experience on all important General transformations.\\n Used informatica developer tool to develop the mapping with power center\\n transformations.\\n Customized SQL override queries where ever possible to minimize the use of Joiner,\\n Aggregator and Lookup Transformations.\\n Developed all the mappings according to the design document and mapping specs\\n provided and performed unit testing.\\n Used Parameterization for Mapping, Workfows and sessions.\\n Worked on running &amp; scheduling the Informatica jobs using Shell Scripts written on\\n the UNIX box.\\n Error handling &amp; issue analysis during the testing and maintenance.\\n Hands on dynamic parameter fle creation.\\n Identifying the bottlenecks and implement the Performance tuning &amp;\\n Optimization techniques in power center.\\n Review and initial approval for various Docs like IDS, IRS, PDI, KEDB, Mapping\\n sheets.\\n Good Knowledge on Data Warehousing concepts like Star Schema, Dimensions\\n and Fact tables.\\n Optimizing Informatica Mappings and Sessions to improve the performance.\\n Experience of handling slowly changing dimensions to maintain complete\\n history using Type I, Type II and Type III strategies.\\n Created UNIX Shell scripts to run the Informatica Workfows &amp; controlling the ETL\\n fow.\\n Hands on Admin activities.\\n Excellent problem-solving skills with strong technical background and good\\n interpersonal skills.\\n\\n\\n\\n\\nEXPERIENCE SUMMARY:\\n, Worked as a Programmer Analyst with COGNIZANT from Jan 2022 to April 2023.\\n\\n Worked as a Software Engineer with Birla Soft LTD from Jan 2021 to Jan 2022.\\n\\n\\n\\n\\n TECHNICAL ENVIRONMENT:\\nOperating System : Windows, Linux\\nTools : Informatica developer, IICS, PUTTY, SQL Developer and WinSCP\\nRDBMS : Oracle ,SQL, PostgreSQL\\nLanguages : Unix,\\nScheduling Tools : Autosys, Control-M\\n\\n\\n\\n PROJECT PROFILE:\\n\\n\\n #PROJECT 1\\n\\n Client : Verizon\\n Project Name : HR Union Recruit in\\n Domain : Telecom\\n Role : IICS Developer\\n Environment : IICS, Oracle 11g, PostgreSQL , Windows 10\\n\\nProject Description:\\n The Project HR Union involves the migration of severance&rsquo;s data in PeopleSoft to\\nPostgreSQL.\\n\\nInformatica Cloud&rsquo;s Data Integration Services consume the Data from Peoplesoft system\\nand perform the\\n\\nbusiness logic to load in Severance&rsquo;s database (PostgreSQL) and then provide the data to\\ndownstream\\n\\nvendors in the form of Files.\\n Responsibilities:\\n\\n Creating Informatica IICS mappings for the diferent plans using various\\n transformations.\\n Have working experience in Informatica Intelligent Cloud Services IICS\\n components - application integration, data integration, Informatica data quality\\n and Informatica power center and CRM application - Salesforce.\\n Analysis of the specifcations provided by the clients.\\n Used Various Transformations such as Sorted, Lookup, Joiner, Aggregator,\\n Sequence Generator. Lookup, Normalizer, Transaction Control Transformation.\\n Worked on Diferent tasks like Mapping Task Replication Task, Synchronization\\n Task, Power Center Task in IICS.\\n Designed, Developed and implemented ETL Processes using IICS Data\\n Integration\\n Created IICS connection using various cloud connectors in IICS Administrator\\n Extensively used informatica IICS&ndash; Mapping, Mapping Task, Task Flow.\\n, Developed complex mappings using transformations such as the Source\\n qualifer, Joiner, Aggregator, Update Strategy, Expression, Connected Lookup,\\n Unconnected Lookup and Router transformations.\\n Created informatica mappings for stage, Dimensions and Fact table loads.\\n Created SCD type-1 and type-2 mappings for loading the dimension tables.\\n Done extensive testing and wrote queries in SQL to ensure the loading of the\\n data.\\n Developed and implemented the coding of Informatica Mapping for the\\n diferent stages of ETL.\\n Involved in Unit testing\\n On-time Production migration without defects\\n Involved in Post production Support.\\n\\n\\n\\n\\n#Project 2\\n\\n Client : Discover Fin bank\\n Domain : Banking\\n Environment : Informatica power center 9.X, Oracle10g\\n Role : Informatica Support and Developer\\n\\n\\n\\nDISCRIPTIOIN:\\n\\n This application was designed to load member and subscriber eligibility information\\nas received from the customers in the form of fat fles and oracle database. The system\\nwas designed to store the eligibility information of the members belonging to the various\\ncontracts for the various vendor customer services being provided to them by the client.\\nIt was used to store the historical information pertaining to each and every member who\\nwas entitled to receive the customer services. The various other front-end applications\\nwould access this database to determine the authenticity of the members and the type of\\nservices they were entitled to the system.\\nResponsibilities:\\n\\n Understanding existing business model and customer requirements.\\n Understanding the mapping specifcations and requirements.\\n Managing priorities of tasks, scheduling and tracking progress.\\n Extraction of data from various sources using Informatica.\\n Designed various mappings for extracting data from various sources involving fat\\n fles and relational tables.\\n Used Source Analyzer and Warehouse Designer to import the source and target\\n database schemas and the mapping designer to map source to the target.\\n Used Transformation Developer to create the flters, joiner, update strategy, lookups\\n and\\n Aggregation transformations, which are used in mappings.\\n Created various tasks like sessions, worklets, and workfows in the workfow\\n manager to test the mapping during development.\\n To keep track of historical data slowly changing dimensions are implemented.\\n Created and Monitored Batches and Sessions using Informatica Power Centre.\\n Created and executed sessions and batches using Server Manager.\\n Worked with Mapping Variables and Mapping Parameters.\\n Developed all the mappings according to the design document and mapping specs\\n provided and performed unit testing.\\n, Created test plan, Test Design, Test scripts and responsible for implementation of\\n Test cases as Manual test scripts.\\n Developed mapping to load the data in slowly changing dimension.\\n Checked the output according to the specifcations.\\n Confgured and ran the Debugger from within the Mapping Designer to troubleshoot\\n the mapping before the normal run of the workfow.\\n Tuned several mappings for the better performance and involved in Performance\\n Testing.\\n Documenting test cases and Informatica mappings\\n Prepared documentation for business data fow from source to target and also for\\n the changes made to the mappings/sessions existing to eliminate the errors.\\n Provide weekly status report to the Project Manager and discuss issues related to\\n quality and deadlines.'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ep = eval_prompt.format(resume_text=example_resume_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "/home/ubuntu/infoedge/llama-recipes/env/lib/python3.10/site-packages/bitsandbytes/nn/modules.py:226: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_type=torch.float32 (default). This will lead to slow inference or training speed.\n",
      "  warnings.warn(f'Input type into Linear4bit is torch.float16, but bnb_4bit_compute_type=torch.float32 (default). This will lead to slow inference or training speed.')\n",
      "2024-05-06 11:00:39.411628: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-06 11:00:39.452184: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-06 11:00:40.119959: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are an accurate agent working for a job platform. You will be given the raw \n",
      "unstructured text of a user's resume, and the task is to extract the entire work experience of the \n",
      "user from the resume. The response should be broken into a numbered list with each item of the list \n",
      "containing the complete and accurate information about the work experience of the users.\n",
      "1. Designation 1 @ Company 1 [From \"mm/yyy\" to \"mm/yyyy\"] : \"complete job description as given in resume\"\n",
      "\n",
      "2. Designation 2 @ Company 2 [From \"mm/yyy\" to \"mm/yyyy\"] :  \"complete job description as given in resume\"\n",
      "\n",
      "Please follow this structure closely and keep the response within the token limit.\" \n",
      "\n",
      "This is the resume text:\n",
      "\n",
      " S\n",
      " EVANAND\n",
      "\n",
      "\n",
      "Email: sevaanand863@gmail.com\n",
      "Mobile: +919110416415\n",
      "\n",
      "\n",
      "PROFESSIONAL SUMMARY:\n",
      " Having 2+ years of technical experience in Analysis, Design, Development, Testing\n",
      " and Implementation of Client Server Application and Data warehousing ETL (Extract,\n",
      " Transform and Load) in Informatica Power Center 10.4 and INFORMATICA intelligent\n",
      " cloud services.\n",
      " Main areas of expertise are Developing and Testing the data warehousing\n",
      " projects with data quality standards.\n",
      " Extensive experience in Extraction, Transformation and Loading of data\n",
      " directly from heterogeneous source systems like fat fles, Oracle by using\n",
      " Informatica power center.\n",
      " Tuned several mappings for the better performance and involved in Performance\n",
      " Testing.\n",
      " Implemented exceptional handling mechanism by using Exception transformation &amp;\n",
      " Human Task.\n",
      " Creating Informatica IICS mappings for the diferent plans using various\n",
      " transformations.\n",
      " Have working experience in Informatica Intelligent Cloud Services IICS components -\n",
      " application integration, data integration, Informatica data quality and Informatica\n",
      " power center and CRM application - Salesforce.\n",
      " Worked on SCD Type1,SCD Type2 in IICS\n",
      " Worked on Mapping, Mapping Task, Mapplet, Task Flows\n",
      " Experience on all important General transformations.\n",
      " Used informatica developer tool to develop the mapping with power center\n",
      " transformations.\n",
      " Customized SQL override queries where ever possible to minimize the use of Joiner,\n",
      " Aggregator and Lookup Transformations.\n",
      " Developed all the mappings according to the design document and mapping specs\n",
      " provided and performed unit testing.\n",
      " Used Parameterization for Mapping, Workfows and sessions.\n",
      " Worked on running &amp; scheduling the Informatica jobs using Shell Scripts written on\n",
      " the UNIX box.\n",
      " Error handling &amp; issue analysis during the testing and maintenance.\n",
      " Hands on dynamic parameter fle creation.\n",
      " Identifying the bottlenecks and implement the Performance tuning &amp;\n",
      " Optimization techniques in power center.\n",
      " Review and initial approval for various Docs like IDS, IRS, PDI, KEDB, Mapping\n",
      " sheets.\n",
      " Good Knowledge on Data Warehousing concepts like Star Schema, Dimensions\n",
      " and Fact tables.\n",
      " Optimizing Informatica Mappings and Sessions to improve the performance.\n",
      " Experience of handling slowly changing dimensions to maintain complete\n",
      " history using Type I, Type II and Type III strategies.\n",
      " Created UNIX Shell scripts to run the Informatica Workfows &amp; controlling the ETL\n",
      " fow.\n",
      " Hands on Admin activities.\n",
      " Excellent problem-solving skills with strong technical background and good\n",
      " interpersonal skills.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "EXPERIENCE SUMMARY:\n",
      ", Worked as a Programmer Analyst with COGNIZANT from Jan 2022 to April 2023.\n",
      "\n",
      " Worked as a Software Engineer with Birla Soft LTD from Jan 2021 to Jan 2022.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " TECHNICAL ENVIRONMENT:\n",
      "Operating System : Windows, Linux\n",
      "Tools : Informatica developer, IICS, PUTTY, SQL Developer and WinSCP\n",
      "RDBMS : Oracle ,SQL, PostgreSQL\n",
      "Languages : Unix,\n",
      "Scheduling Tools : Autosys, Control-M\n",
      "\n",
      "\n",
      "\n",
      " PROJECT PROFILE:\n",
      "\n",
      "\n",
      " #PROJECT 1\n",
      "\n",
      " Client : Verizon\n",
      " Project Name : HR Union Recruit in\n",
      " Domain : Telecom\n",
      " Role : IICS Developer\n",
      " Environment : IICS, Oracle 11g, PostgreSQL , Windows 10\n",
      "\n",
      "Project Description:\n",
      " The Project HR Union involves the migration of severance&rsquo;s data in PeopleSoft to\n",
      "PostgreSQL.\n",
      "\n",
      "Informatica Cloud&rsquo;s Data Integration Services consume the Data from Peoplesoft system\n",
      "and perform the\n",
      "\n",
      "business logic to load in Severance&rsquo;s database (PostgreSQL) and then provide the data to\n",
      "downstream\n",
      "\n",
      "vendors in the form of Files.\n",
      " Responsibilities:\n",
      "\n",
      " Creating Informatica IICS mappings for the diferent plans using various\n",
      " transformations.\n",
      " Have working experience in Informatica Intelligent Cloud Services IICS\n",
      " components - application integration, data integration, Informatica data quality\n",
      " and Informatica power center and CRM application - Salesforce.\n",
      " Analysis of the specifcations provided by the clients.\n",
      " Used Various Transformations such as Sorted, Lookup, Joiner, Aggregator,\n",
      " Sequence Generator. Lookup, Normalizer, Transaction Control Transformation.\n",
      " Worked on Diferent tasks like Mapping Task Replication Task, Synchronization\n",
      " Task, Power Center Task in IICS.\n",
      " Designed, Developed and implemented ETL Processes using IICS Data\n",
      " Integration\n",
      " Created IICS connection using various cloud connectors in IICS Administrator\n",
      " Extensively used informatica IICS&ndash; Mapping, Mapping Task, Task Flow.\n",
      ", Developed complex mappings using transformations such as the Source\n",
      " qualifer, Joiner, Aggregator, Update Strategy, Expression, Connected Lookup,\n",
      " Unconnected Lookup and Router transformations.\n",
      " Created informatica mappings for stage, Dimensions and Fact table loads.\n",
      " Created SCD type-1 and type-2 mappings for loading the dimension tables.\n",
      " Done extensive testing and wrote queries in SQL to ensure the loading of the\n",
      " data.\n",
      " Developed and implemented the coding of Informatica Mapping for the\n",
      " diferent stages of ETL.\n",
      " Involved in Unit testing\n",
      " On-time Production migration without defects\n",
      " Involved in Post production Support.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#Project 2\n",
      "\n",
      " Client : Discover Fin bank\n",
      " Domain : Banking\n",
      " Environment : Informatica power center 9.X, Oracle10g\n",
      " Role : Informatica Support and Developer\n",
      "\n",
      "\n",
      "\n",
      "DISCRIPTIOIN:\n",
      "\n",
      " This application was designed to load member and subscriber eligibility information\n",
      "as received from the customers in the form of fat fles and oracle database. The system\n",
      "was designed to store the eligibility information of the members belonging to the various\n",
      "contracts for the various vendor customer services being provided to them by the client.\n",
      "It was used to store the historical information pertaining to each and every member who\n",
      "was entitled to receive the customer services. The various other front-end applications\n",
      "would access this database to determine the authenticity of the members and the type of\n",
      "services they were entitled to the system.\n",
      "Responsibilities:\n",
      "\n",
      " Understanding existing business model and customer requirements.\n",
      " Understanding the mapping specifcations and requirements.\n",
      " Managing priorities of tasks, scheduling and tracking progress.\n",
      " Extraction of data from various sources using Informatica.\n",
      " Designed various mappings for extracting data from various sources involving fat\n",
      " fles and relational tables.\n",
      " Used Source Analyzer and Warehouse Designer to import the source and target\n",
      " database schemas and the mapping designer to map source to the target.\n",
      " Used Transformation Developer to create the flters, joiner, update strategy, lookups\n",
      " and\n",
      " Aggregation transformations, which are used in mappings.\n",
      " Created various tasks like sessions, worklets, and workfows in the workfow\n",
      " manager to test the mapping during development.\n",
      " To keep track of historical data slowly changing dimensions are implemented.\n",
      " Created and Monitored Batches and Sessions using Informatica Power Centre.\n",
      " Created and executed sessions and batches using Server Manager.\n",
      " Worked with Mapping Variables and Mapping Parameters.\n",
      " Developed all the mappings according to the design document and mapping specs\n",
      " provided and performed unit testing.\n",
      ", Created test plan, Test Design, Test scripts and responsible for implementation of\n",
      " Test cases as Manual test scripts.\n",
      " Developed mapping to load the data in slowly changing dimension.\n",
      " Checked the output according to the specifcations.\n",
      " Confgured and ran the Debugger from within the Mapping Designer to troubleshoot\n",
      " the mapping before the normal run of the workfow.\n",
      " Tuned several mappings for the better performance and involved in Performance\n",
      " Testing.\n",
      " Documenting test cases and Informatica mappings\n",
      " Prepared documentation for business data fow from source to target and also for\n",
      " the changes made to the mappings/sessions existing to eliminate the errors.\n",
      " Provide weekly status report to the Project Manager and discuss issues related to\n",
      " quality and deadlines.'\n",
      "\n",
      "\n",
      "This is the output in the required_format:\n",
      "\n",
      "1. IICS Developer @ Verizon [Jan 2022 to April 2023] :\n",
      "   - Role: IICS Developer\n",
      "   - Environment: IICS, Oracle 11g, PostgreSQL, Windows 10\n",
      "   - Responsibilities:\n",
      "     - Creating Informatica IICS mappings for the different plans using various transformations.\n",
      "     - Working experience in Informatica Intelligent Cloud Services IICS components - application integration, data integration, Informatica data quality and Informatica power center and CRM application - Salesforce.\n",
      "     - Analysis of the specifications provided by the clients.\n",
      "     - Used various transformations such as Sorted, Lookup, Joiner, Aggregator, Sequence Generator, Lookup, Normalizer, Transaction Control Transformation.\n",
      "     - Worked on different tasks like Mapping Task Replication Task, Synchronization Task, Power Center Task in IICS.\n",
      "     - Developed complex mappings using transformations such as the Source qualifier, Joiner, Aggregator, Update Strategy, Expression, Connected Lookup, Unconnected Lookup and Router transformations.\n",
      "     - Created Informatica mappings for stage, Dimensions and Fact table loads.\n",
      "     - Created SCD type-1 and type-2 mappings for loading the dimension tables.\n",
      "     - Done extensive testing and wrote queries in SQL to ensure the loading of the data.\n",
      "     - Developed and implemented the coding of Informatica Mapping for the different stages of ETL.\n",
      "     - Involved in Unit testing.\n",
      "     - On-time Production migration without defects.\n",
      "     - Involved in Post production Support.\n",
      "\n",
      "2. Informatica Support and Developer @ Discover Fin Bank [Jan 2021 to Jan 2022] :\n",
      "   - Role: Informatica Support and Developer\n",
      "   - Environment: Informatica power center 9.X, Oracle10g\n",
      "   - Responsibilities:\n",
      "     - Understanding existing business model and customer requirements.\n",
      "     - Understanding the mapping specifications and requirements.\n",
      "     - Managing priorities of tasks, scheduling and tracking progress.\n",
      "     - Extraction of data from various sources using Informatica.\n",
      "     - Designed various mappings for extracting data from various sources involving fat files and relational tables.\n",
      "     - Used Source Analyzer and Warehouse Designer to import the source and target database schemas and the mapping designer to map source to the target.\n",
      "     - Used Transformation Developer to create the filters, joiner, update strategy, lookups and aggregation transformations, which are used in mappings.\n",
      "     - Created various tasks like sessions, worklets, and workflows in the workflow manager to test the mapping during development.\n",
      "     - To keep track of historical data, slowly changing dimensions are implemented.\n",
      "     - Created and monitored batches and sessions using Informatica Power Centre.\n",
      "     - Created and executed sessions and batches using Server Manager.\n",
      "     - Worked with Mapping Variables and Mapping Parameters.\n",
      "     - Developed all the mappings according to the design document and mapping specs provided and performed unit testing.\n",
      "     - Created test plan, Test Design, Test scripts and responsible for implementation of Test cases as Manual test scripts.\n",
      "     - Developed mapping to load the data in slowly changing dimension.\n",
      "     - Checked the output according to the specifications.\n",
      "     - Configured and ran the Debugger from within the Mapping Designer to troubleshoot the mapping before the normal run of the workflow.\n",
      "     - Tuned several mappings for better performance and involved in Performance Testing.\n",
      "     - Documented test cases and Informatica mappings.\n",
      "     - Prepared documentation for business data flow from source to target and also for the changes made to the mappings/sessions to eliminate errors.\n",
      "     - Provide weekly status report to the Project Manager and discuss issues related to quality and deadlines.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TextStreamer\n",
    "\n",
    "# streamer = TextStreamer(tokenizer)\n",
    "model_input = tokenizer(ep,return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(tokenizer.decode(model.generate(**model_input, max_new_tokens=1024)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "We can see that the base model only repeats the conversation.\n",
    "\n",
    "### Step 4: Prepare model for PEFT\n",
    "\n",
    "Let's prepare the model for Parameter Efficient Fine Tuning (PEFT):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/infoedge/llama-recipes/env/lib/python3.10/site-packages/peft/utils/other.py:141: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 27,262,976 || all params: 7,268,995,072 || trainable%: 0.3750583915652433\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "def create_peft_config(model):\n",
    "    from peft import (\n",
    "        get_peft_model,\n",
    "        LoraConfig,\n",
    "        TaskType,\n",
    "        prepare_model_for_int8_training,\n",
    "    )\n",
    "\n",
    "    peft_config = LoraConfig(\n",
    "        task_type=TaskType.CAUSAL_LM,\n",
    "        inference_mode=False,\n",
    "        r=64,\n",
    "        lora_alpha=32,\n",
    "        lora_dropout=0.05,\n",
    "        target_modules = [\"q_proj\", \"v_proj\"]\n",
    "    )\n",
    "    \n",
    "    # peft_config = LoraConfig(\n",
    "    #     task_type=TaskType.CAUSAL_LM,\n",
    "    #     inference_mode=False,\n",
    "    #     r=8,\n",
    "    #     lora_alpha=32,\n",
    "    #     lora_dropout=0.05,\n",
    "    #     target_modules = [\"q_proj\", \"v_proj\"]\n",
    "    # )\n",
    "\n",
    "    # prepare int-8 model for training\n",
    "    model = prepare_model_for_int8_training(model)\n",
    "    model = get_peft_model(model, peft_config)\n",
    "    model.print_trainable_parameters()\n",
    "    return model, peft_config\n",
    "\n",
    "# create peft config\n",
    "model, lora_config = create_peft_config(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Step 5: Define an optional profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import TrainerCallback\n",
    "from contextlib import nullcontext\n",
    "enable_profiler = False\n",
    "output_dir = \"tmp/linear_workex\"\n",
    "\n",
    "config = {\n",
    "    'lora_config': lora_config,\n",
    "    'learning_rate': 1e-4,\n",
    "    'num_train_epochs': 3,\n",
    "    'gradient_accumulation_steps': 2,\n",
    "    'per_device_train_batch_size': 2,\n",
    "    'gradient_checkpointing': False,\n",
    "}\n",
    "\n",
    "# Set up profiler\n",
    "if enable_profiler:\n",
    "    wait, warmup, active, repeat = 1, 1, 2, 1\n",
    "    total_steps = (wait + warmup + active) * (1 + repeat)\n",
    "    schedule =  torch.profiler.schedule(wait=wait, warmup=warmup, active=active, repeat=repeat)\n",
    "    profiler = torch.profiler.profile(\n",
    "        schedule=schedule,\n",
    "        on_trace_ready=torch.profiler.tensorboard_trace_handler(f\"{output_dir}/logs/tensorboard\"),\n",
    "        record_shapes=True,\n",
    "        profile_memory=True,\n",
    "        with_stack=True)\n",
    "    \n",
    "    class ProfilerCallback(TrainerCallback):\n",
    "        def __init__(self, profiler):\n",
    "            self.profiler = profiler\n",
    "            \n",
    "        def on_step_end(self, *args, **kwargs):\n",
    "            self.profiler.step()\n",
    "\n",
    "    profiler_callback = ProfilerCallback(profiler)\n",
    "else:\n",
    "    profiler = nullcontext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon May  6 11:01:26 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.154.05             Driver Version: 535.154.05   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A10G                    Off | 00000000:00:1E.0 Off |                    0 |\n",
      "|  0%   37C    P0              91W / 300W |   7246MiB / 23028MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      1523      C   ...oedge/llama-recipes/env/bin/python3     7238MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Fine tune the model\n",
    "\n",
    "Here, we fine tune the model for a single epoch which takes a bit more than an hour on a A100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "/home/ubuntu/infoedge/llama-recipes/env/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='192' max='192' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [192/192 45:25, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.070100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.858500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.807500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.845800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.783400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.740600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.695800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.632500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.855200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.740300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>1.853600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.547100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>1.774000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.596000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>1.564200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.579500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>1.693000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.543700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>1.596800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.707700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>1.639300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.633700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>1.649800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.701700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>1.694000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.686300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>1.718300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.611200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>1.631400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.595300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>1.558200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.683600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>1.602200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.539300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>1.473700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.541000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185</td>\n",
       "      <td>1.587900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.564200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import default_data_collator, Trainer, TrainingArguments\n",
    "\n",
    "# Define training args\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "    bf16=True,  # Use BF16 if available\n",
    "    # logging strategies\n",
    "    logging_dir=f\"{output_dir}/logs\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=5,\n",
    "    save_strategy=\"no\",\n",
    "    optim=\"adamw_torch_fused\",\n",
    "    max_steps=total_steps if enable_profiler else -1,\n",
    "    **{k:v for k,v in config.items() if k != 'lora_config'}\n",
    ")\n",
    "\n",
    "with profiler:\n",
    "    # Create Trainer instance\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_data,\n",
    "        data_collator=default_data_collator,\n",
    "        callbacks=[profiler_callback] if enable_profiler else [],\n",
    "    )\n",
    "\n",
    "    # Start training\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 7:\n",
    "Save model checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 8:\n",
    "Try the fine tuned model on the same example again to see the learning progress:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_df = pd.read_csv('../custom_data/model_eval_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(161, 5)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import html, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sabdharishi.L.N,\n",
      "Email:saptharishi_ln@yahoo.com\n",
      "Mobile: +91 9738688274.\n",
      "\n",
      "Work Experience:\n",
      " Having 19+ years of experience in embedded systems.\n",
      "\n",
      " 16+ years of working experience in Automotive domain across leading\n",
      " Tier-1’s / Tier-2’r and indirect working relationship with leading OEM’s\n",
      "\n",
      " Currently working for BlueBinaries Engineering and Solutions Pvt.\n",
      " Ltd., as a General Manager for Digital Cockpit practice in Automotive Domain\n",
      " from Mar 2023 till date\n",
      "\n",
      " Worked for Harman International as a Sr. Principal Engineer in\n",
      " Automotive Domain from May 2019 till Mar 2023\n",
      "\n",
      " Worked for Wipro Technologies as a Presales Manager in Automotive\n",
      " Domain from May 2015 to May 2019\n",
      "\n",
      " Worked for Intel Mobile Communications India Pvt. Ltd., Bangalore as\n",
      " a Senior Firmware Engineer from July 2012 to May 2015\n",
      "\n",
      " Worked for Smart Play Technologies, Bangalore as a Lead Engineer\n",
      " from April 2011 to Jun 2012.\n",
      "\n",
      " Worked for Aricent Technologies, Bangalore as a Technical Lead from\n",
      " Jul 2007 to April 2011.\n",
      "\n",
      " Worked for Visteon Technical Services Centre Chennai as a Software\n",
      " Design Engineer from Dec 2003 to Jun 2007.\n",
      "\n",
      "Strengths:\n",
      " Key Account management, Stakeholder Management, Team Management,\n",
      " Negotiation.\n",
      " Pre-sales / solution delivery to RFP / RFQ / RFI, SoW, WBS etc. in IVI\n",
      " domain\n",
      " Core Development Expertise in Bluetooth Firmware, AGPS, Automotive\n",
      " infotainment, Multimedia and Consumer Electronics domains\n",
      " Product and Platform Requirement management\n",
      " Beginner Level Profciency in German Language\n",
      " AUTOSAR and ASPICE, EE Architecture, SDV expertise\n",
      "\n",
      "Achievements:\n",
      ", Successfully bid and won many business deals including a 3-year\n",
      " production program with a leading automotive OEM with more than 25\n",
      " million USD revenue.\n",
      " As a team lead, ensured “zero defect count” for a customer project.\n",
      " Filed 2 patents in the Automotive domain.\n",
      " Nominated for “Leading the Way” award in Visteon Corporation for\n",
      " successful product delivery of GAP radios which resulted in new business\n",
      " wins.\n",
      "\n",
      "Academics\n",
      "\n",
      " B.E (Electronics and Communications) from Govt. College of Engg.,\n",
      " Bargur Periyar University (Tamil Nadu) from 1999-2003 with 75%\n",
      " Passed High School with 94%\n",
      " Passed AISSE(CBSE) with 75%\n",
      "\n",
      "Technical Skills:\n",
      "\n",
      "Development Environments : Lauterbach, CCS, Metrowerks Code\n",
      " Warrior, VC++, Qt\n",
      "Hardware Environments : ARC and ARM processor (Atmel AT91RM9200),\n",
      " Microcontrollers (HCS12,\n",
      "TMS470), DM510\n",
      "Operating Systems : THREADX, MMOS, Linux\n",
      "Communication Protocols : SPI, I2C, UART, I2S, CAN, MOST, WiFi, BLE\n",
      "Hardware Debuggers : Bluetooth Air snifer Signal Monitor, Spectrum\n",
      "Analyzer.\n",
      "Version Control : Gerrit, Clear Case\n",
      "Programming Languages : C\n",
      "Tools : RTRT, CANalyzer, CANoe, QAC\n",
      "Process : ASPICE\n",
      "\n",
      "Projects:\n",
      "\n",
      " 1. Practice Head for Digital Cockpit Domain\n",
      "Descriptio Account Management, Platform Solution Development, RFQ/RFI\n",
      "n response solutions, Team Management\n",
      "Role General Manager\n",
      "Company BlueBinaries Engineering & Solutions Pvt. Ltd.\n",
      "Skill Digital Cockpit\n",
      "Contributi 1. Successfully managed accounts with Tier-1’s from digital\n",
      "on cockpit practice. Proposed and deployed resources asper plan\n",
      " with EBIDTA > 30%\n",
      " 2. Successfully managed to onboard ~40 resources in 2 months\n",
      " across 2 Tier-1’s.\n",
      " 3. At least 1 RFQ / RFI was responded to per week on average.\n",
      " 4. Proposed solutions in new areas like AR-HUD / Integrated\n",
      ", cockpit etc.\n",
      " 5. Creating assets like Test Automation Framework, System\n",
      " requirement library as part of platform building.\n",
      " 6. Hosted customer visits / demonstrated digital cockpit practice\n",
      " capability to customers including top tier OEM’s.\n",
      " 7. Collaboration with Talent Acquisition team / other practice\n",
      " teams, taking interviews with candidates for the identifed\n",
      " positions.\n",
      " 8. Learning newer areas like E/E architecture, SDV and its impact\n",
      " of digital cockpit\n",
      "Duration Mar 2023 till Date\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 2. System Requirements Engineering\n",
      "Descriptio\n",
      " System Requirement Management, Team management\n",
      "n\n",
      "Role System Requirement Manager\n",
      "Company Harman International\n",
      "Skill RTC, Doors\n",
      " 1. Managed a team of 6 including performance reviews, training\n",
      " needs, goal setting.\n",
      " 2. Built re-usable platform requirements in IVI connectivity\n",
      " domains, to be used by various products, thereby saving efort\n",
      " and time of productization.\n",
      " 3. Planning/executing road-map features which delivers business\n",
      " value to customers.\n",
      " 4. Identifed the in-efciencies in the system and proposed ways to\n",
      "Contributi improve operational efciency by ~35%\n",
      "on 5. Spearheading an AI/ML based solution for doing “Gap analysis”\n",
      " of requirements which will yield savings of at least 150K\n",
      " USD / year.\n",
      " 6. Awarded “Exceeded Expectations” rating within 2 years of\n",
      " current experience.\n",
      " 7. Collaboration with stakeholders such as product management,\n",
      " domain teams, validation teams, Architecture teams to realize\n",
      " features on time.\n",
      "\n",
      "Duration May 2019 till Mar 2023\n",
      "\n",
      " 3. Presales Manager – IVI Domain\n",
      "Descriptio Solution Proposal to RFP, RFQ, SOW preparation, cost estimation,\n",
      "n WBS, Resource Loading etc.\n",
      "Role Presales Manager\n",
      "Company Wipro Technologies\n",
      ",Skill IVI Domain\n",
      " 1. Complete ownership of proposals in IVI domains across\n",
      " geographies for all major OEM’s and Tier-1’s\n",
      " 2. Customer Interaction with all leading OEM’s across all\n",
      " geographies.\n",
      " 3. Won businesses with leading OEM and Tier-1’s including a\n",
      " multimillion-dollar (~$30 Million USD) deal win with an OEM\n",
      " for their Android based platform for production\n",
      " 4. Handled a portfolio of ~ $17 Million per quarter average\n",
      "Contributi revenue\n",
      "on 5. Negotiating proposals with fnance, sales team after\n",
      " transforming engineering efort to cost\n",
      " 6. Achieved 100% delivery of all proposals on time while working\n",
      " on parallel deals\n",
      " 7. Hosted multiple customer visits including direct interaction\n",
      " with OEM’s.\n",
      " 8. Identifying customer pain points and developing / proposing\n",
      " solutions with a proactive pitch for new business wins including\n",
      " stafng, new solution deployment\n",
      "Duration Aug 2017 till May 2019\n",
      "\n",
      " 4. WiFi Middleware for Car Infotainment\n",
      " Systems\n",
      "Descriptio The project involves fxing issues and implementing Change\n",
      "n Requests for Diferent Customer programs\n",
      "Role Architect/Program Manager\n",
      "Company Wipro Technologies\n",
      "Skill C, Wif\n",
      "Environme\n",
      " Windows\n",
      "nt\n",
      "Hardware TI Micro Controller\n",
      " 1. As a scrum master, successfully met the deliverables in\n",
      " resolving defects and implementing DCR’s for SYNC GEN3\n",
      " project.\n",
      " 2. As an architect, gave solutions to the team in solving technical\n",
      "Contributi\n",
      " issues.\n",
      "on\n",
      " 3. Co-ordinated with all stake holders to communicate and follow\n",
      " up so that customer issues are addressed on time.\n",
      " 4. Managed the program as program manager ensuring quality\n",
      " deliverables on time\n",
      "Duration May 2015 till July 2017\n",
      "\n",
      "\n",
      " 5. Bluetooth Firmware\n",
      "Descriptio The project involves fxing issues on the BT Firmware controller\n",
      ",n\n",
      "Role Firmware Engineer\n",
      "Company Intel Mobile Communications\n",
      "Skill C, JTAG, Power Trace, signal monitor, protocol analyzer\n",
      "Environme\n",
      " Windows\n",
      "nt\n",
      "Hardware AG610 ARM based processor\n",
      " 1. As a lead, successfully resolved all issues (in AG610 platform)\n",
      " that resulted in product launch to OEM’s.\n",
      " 2. Achieved ‘zero defect count’ for AG610 based platform.\n",
      "Contributi 3. Optimized the existing code by more than 78% for Low Energy\n",
      "on Only Solution.\n",
      " 4. Co-ordinated with all stake holders to communicate and follow\n",
      " up so that customer issues are addressed on time for Samsung\n",
      " and Nokia.\n",
      "Duration August 2012 till May2015\n",
      "\n",
      " 6. AGPS (Assisted GPS) Development for\n",
      " SUPLV2.0\n",
      " The project involves developing features for SUPL2.0 (Secured\n",
      "Descriptio\n",
      " User Plane Location) protocol using which a user can identify his\n",
      "n\n",
      " position or other person’s position with the help of GPS server.\n",
      "Role Lead Engineer\n",
      "Company ST-Ericsson (worked at the client site)\n",
      "Skill C, Linux\n",
      "Environme\n",
      " Linux, windows\n",
      "nt\n",
      "Hardware CG900\n",
      " 1. Developing SUPL2.0 features like SUPL over WLAN, Third\n",
      " party location transfer/retrieval, Application ID, Session Info\n",
      " query etc.\n",
      " 2. Applied for patent for implementing MAC ID based reference\n",
      "Contributi location positioning in the android framework layer with the\n",
      "on google developers forum.\n",
      " 3. Lead the development team, coordinate with the necessary\n",
      " stake holders to resolve the issue to meet customer deadlines\n",
      " 4. Resolve/debug memory issues/crashes\n",
      " 5. Worked as an onsite coordinator for STE\n",
      "Duration April 2011 till July 2012\n",
      "\n",
      " 7. GPS (Global Positioning System) Driver\n",
      "Descriptio This project involves porting of Global Positioning System drivers\n",
      "n across various mobile platforms.\n",
      "Role Technical Lead\n",
      ",Company Intel Mobile Communications (worked at the client site)\n",
      "Skill C, ThreadX, Trace32\n",
      "Environme\n",
      " Lauterbach, RVCT compiler.\n",
      "nt\n",
      "Hardware XMM2130/XMM2230 ARM based processor\n",
      " 1. Porting of AGPS driver (I2C based) across diferent platforms\n",
      " 2. Board bring up on new software/hardware platform\n",
      "Contributi\n",
      " 3. Debugging issues while porting for new platform\n",
      "on\n",
      " 4. Hardware level debugging with oscilloscope/spectrum analyzer\n",
      " 5. Ported drivers in 33% time compared to average time\n",
      "Duration July 2010 to April 2011\n",
      "\n",
      " 8. MDI (Media Device Interface)\n",
      "\n",
      " The Media Device Interface (MDI) is a device developed for\n",
      "Descriptio Volkswagen (VW) by S1nn and Aricent. This Device would connect\n",
      "n and play Apple iPods and Mass Storage Devices in an “in-car\n",
      " entertainment system”.\n",
      "Role Sr. Software Engineer\n",
      "Customer S1nn, Germany\n",
      " Volkswagen, Bentley (Car Manufacturing companies)\n",
      "Client\n",
      "Skill C, ThreadX\n",
      "Environme\n",
      " Keil Uvision 3.\n",
      "nt\n",
      "Hardware Atmel AT91RM9200 processor\n",
      " 1. Implementation of DAI (Digital Audio Interface) module.\n",
      "Contributi 2. Involved as an individual contributor.\n",
      "on 3. Mentored and ramped up junior members of the team\n",
      " successfully\n",
      "Duration Jul 2007 to Aug 2008\n",
      "\n",
      " 9. MP3 CODEC Based Car Radios\n",
      " The Project involves playback of various audio fle formats such\n",
      "Description as MP3, WMA, AAC etc in single CD and six CD based radios for\n",
      " Ford and Hyundai cars\n",
      "Role Software Design Engineer\n",
      "Customer Ford, Hyundai\n",
      "Skill C\n",
      "Environme\n",
      " CCS\n",
      "nt\n",
      "Hardware TMS320C5410, TMS470\n",
      "Contributio 1. Bug fxes, application development for the TMS320C5410 DSP\n",
      "n based MP3 decoder subsystem.\n",
      ", 2. Lead the team successfully throughout the project duration.\n",
      " Mentored junior members into the project.\n",
      " 3. Successfully interacted with product development groups in\n",
      " US and Mexico which resulted in production releases.\n",
      " 4. Created technical proposals that resolved system issues and\n",
      " improved the quality of the Visteon radios.\n",
      "\n",
      "Duration Jan 2006 to June 2007\n",
      "\n",
      " 10. Tuner Component for SDARS (Satellite\n",
      " Digital Audio Radio Service) radios\n",
      "Descripti This project involves development of tuner component of Sirius and\n",
      "on XM car radios which provides satellite digital radio services to\n",
      " North America.\n",
      "Role Software Engineer\n",
      "Customer BMW, PAG, Ford\n",
      "Skill C, Clear case, MMOS\n",
      "Hardware MC9S12DP256 Motorola controller,\n",
      "Contribut 1. Involved in tuner component.\n",
      "ion 2. Actively involved in full software development life cycle\n",
      " 3. Successfully implemented new features which resulted in new\n",
      " business wins\n",
      " 4. On time delivery of quality work product\n",
      "Duration Jan 2004 to Dec 2005\n"
     ]
    }
   ],
   "source": [
    "rt = eval_df.sample(random_state=random.randint(0,10000))['resume'].values[0]\n",
    "rt = html.unescape(rt)\n",
    "\n",
    "print(rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "eval_prompt = f'''\n",
    "You are an accurate agent working for a job platform. You will be given the raw \n",
    "unstructured text of a user's resume, and the task is to extract the entire work experience of the \n",
    "user from the resume. The response should be presented into a numbered list with each item of the list \n",
    "being an unbroken line of text containing the complete and accurate information about the work experience of the users. \n",
    "Here is an example structure:\\n\n",
    "1. Designation 1 @ Company 1 [From \"mm/yyy\" to \"mm/yyyy\"] : \"complete job description as given in resume\"\\n\n",
    "2. Designation 2 @ Company 2 [From \"mm/yyy\" to \"mm/yyyy\"] :  \"complete job description as given in resume\"\\n\n",
    "Please follow this structure accurately and keep the response within the token limit.\" \n",
    "\n",
    "This is the resume text:\\n{{resume_text}}\\n\n",
    "This is the output in the required_format:\\n'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ep = eval_prompt.format(resume_text=rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are an accurate agent working for a job platform. You will be given the raw \n",
      "unstructured text of a user's resume, and the task is to extract the entire work experience of the \n",
      "user from the resume. The response should be presented into a numbered list with each item of the list \n",
      "being an unbroken line of text containing the complete and accurate information about the work experience of the users. \n",
      "Here is an example structure:\n",
      "\n",
      "1. Designation 1 @ Company 1 [From \"mm/yyy\" to \"mm/yyyy\"] : \"complete job description as given in resume\"\n",
      "\n",
      "2. Designation 2 @ Company 2 [From \"mm/yyy\" to \"mm/yyyy\"] :  \"complete job description as given in resume\"\n",
      "\n",
      "Please follow this structure accurately and keep the response within the token limit.\" \n",
      "\n",
      "This is the resume text:\n",
      "Sabdharishi.L.N,\n",
      "Email:saptharishi_ln@yahoo.com\n",
      "Mobile: +91 9738688274.\n",
      "\n",
      "Work Experience:\n",
      " Having 19+ years of experience in embedded systems.\n",
      "\n",
      " 16+ years of working experience in Automotive domain across leading\n",
      " Tier-1’s / Tier-2’r and indirect working relationship with leading OEM’s\n",
      "\n",
      " Currently working for BlueBinaries Engineering and Solutions Pvt.\n",
      " Ltd., as a General Manager for Digital Cockpit practice in Automotive Domain\n",
      " from Mar 2023 till date\n",
      "\n",
      " Worked for Harman International as a Sr. Principal Engineer in\n",
      " Automotive Domain from May 2019 till Mar 2023\n",
      "\n",
      " Worked for Wipro Technologies as a Presales Manager in Automotive\n",
      " Domain from May 2015 to May 2019\n",
      "\n",
      " Worked for Intel Mobile Communications India Pvt. Ltd., Bangalore as\n",
      " a Senior Firmware Engineer from July 2012 to May 2015\n",
      "\n",
      " Worked for Smart Play Technologies, Bangalore as a Lead Engineer\n",
      " from April 2011 to Jun 2012.\n",
      "\n",
      " Worked for Aricent Technologies, Bangalore as a Technical Lead from\n",
      " Jul 2007 to April 2011.\n",
      "\n",
      " Worked for Visteon Technical Services Centre Chennai as a Software\n",
      " Design Engineer from Dec 2003 to Jun 2007.\n",
      "\n",
      "Strengths:\n",
      " Key Account management, Stakeholder Management, Team Management,\n",
      " Negotiation.\n",
      " Pre-sales / solution delivery to RFP / RFQ / RFI, SoW, WBS etc. in IVI\n",
      " domain\n",
      " Core Development Expertise in Bluetooth Firmware, AGPS, Automotive\n",
      " infotainment, Multimedia and Consumer Electronics domains\n",
      " Product and Platform Requirement management\n",
      " Beginner Level Profciency in German Language\n",
      " AUTOSAR and ASPICE, EE Architecture, SDV expertise\n",
      "\n",
      "Achievements:\n",
      ", Successfully bid and won many business deals including a 3-year\n",
      " production program with a leading automotive OEM with more than 25\n",
      " million USD revenue.\n",
      " As a team lead, ensured “zero defect count” for a customer project.\n",
      " Filed 2 patents in the Automotive domain.\n",
      " Nominated for “Leading the Way” award in Visteon Corporation for\n",
      " successful product delivery of GAP radios which resulted in new business\n",
      " wins.\n",
      "\n",
      "Academics\n",
      "\n",
      " B.E (Electronics and Communications) from Govt. College of Engg.,\n",
      " Bargur Periyar University (Tamil Nadu) from 1999-2003 with 75%\n",
      " Passed High School with 94%\n",
      " Passed AISSE(CBSE) with 75%\n",
      "\n",
      "Technical Skills:\n",
      "\n",
      "Development Environments : Lauterbach, CCS, Metrowerks Code\n",
      " Warrior, VC++, Qt\n",
      "Hardware Environments : ARC and ARM processor (Atmel AT91RM9200),\n",
      " Microcontrollers (HCS12,\n",
      "TMS470), DM510\n",
      "Operating Systems : THREADX, MMOS, Linux\n",
      "Communication Protocols : SPI, I2C, UART, I2S, CAN, MOST, WiFi, BLE\n",
      "Hardware Debuggers : Bluetooth Air snifer Signal Monitor, Spectrum\n",
      "Analyzer.\n",
      "Version Control : Gerrit, Clear Case\n",
      "Programming Languages : C\n",
      "Tools : RTRT, CANalyzer, CANoe, QAC\n",
      "Process : ASPICE\n",
      "\n",
      "Projects:\n",
      "\n",
      " 1. Practice Head for Digital Cockpit Domain\n",
      "Descriptio Account Management, Platform Solution Development, RFQ/RFI\n",
      "n response solutions, Team Management\n",
      "Role General Manager\n",
      "Company BlueBinaries Engineering & Solutions Pvt. Ltd.\n",
      "Skill Digital Cockpit\n",
      "Contributi 1. Successfully managed accounts with Tier-1’s from digital\n",
      "on cockpit practice. Proposed and deployed resources asper plan\n",
      " with EBIDTA > 30%\n",
      " 2. Successfully managed to onboard ~40 resources in 2 months\n",
      " across 2 Tier-1’s.\n",
      " 3. At least 1 RFQ / RFI was responded to per week on average.\n",
      " 4. Proposed solutions in new areas like AR-HUD / Integrated\n",
      ", cockpit etc.\n",
      " 5. Creating assets like Test Automation Framework, System\n",
      " requirement library as part of platform building.\n",
      " 6. Hosted customer visits / demonstrated digital cockpit practice\n",
      " capability to customers including top tier OEM’s.\n",
      " 7. Collaboration with Talent Acquisition team / other practice\n",
      " teams, taking interviews with candidates for the identifed\n",
      " positions.\n",
      " 8. Learning newer areas like E/E architecture, SDV and its impact\n",
      " of digital cockpit\n",
      "Duration Mar 2023 till Date\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 2. System Requirements Engineering\n",
      "Descriptio\n",
      " System Requirement Management, Team management\n",
      "n\n",
      "Role System Requirement Manager\n",
      "Company Harman International\n",
      "Skill RTC, Doors\n",
      " 1. Managed a team of 6 including performance reviews, training\n",
      " needs, goal setting.\n",
      " 2. Built re-usable platform requirements in IVI connectivity\n",
      " domains, to be used by various products, thereby saving efort\n",
      " and time of productization.\n",
      " 3. Planning/executing road-map features which delivers business\n",
      " value to customers.\n",
      " 4. Identifed the in-efciencies in the system and proposed ways to\n",
      "Contributi improve operational efciency by ~35%\n",
      "on 5. Spearheading an AI/ML based solution for doing “Gap analysis”\n",
      " of requirements which will yield savings of at least 150K\n",
      " USD / year.\n",
      " 6. Awarded “Exceeded Expectations” rating within 2 years of\n",
      " current experience.\n",
      " 7. Collaboration with stakeholders such as product management,\n",
      " domain teams, validation teams, Architecture teams to realize\n",
      " features on time.\n",
      "\n",
      "Duration May 2019 till Mar 2023\n",
      "\n",
      " 3. Presales Manager – IVI Domain\n",
      "Descriptio Solution Proposal to RFP, RFQ, SOW preparation, cost estimation,\n",
      "n WBS, Resource Loading etc.\n",
      "Role Presales Manager\n",
      "Company Wipro Technologies\n",
      ",Skill IVI Domain\n",
      " 1. Complete ownership of proposals in IVI domains across\n",
      " geographies for all major OEM’s and Tier-1’s\n",
      " 2. Customer Interaction with all leading OEM’s across all\n",
      " geographies.\n",
      " 3. Won businesses with leading OEM and Tier-1’s including a\n",
      " multimillion-dollar (~$30 Million USD) deal win with an OEM\n",
      " for their Android based platform for production\n",
      " 4. Handled a portfolio of ~ $17 Million per quarter average\n",
      "Contributi revenue\n",
      "on 5. Negotiating proposals with fnance, sales team after\n",
      " transforming engineering efort to cost\n",
      " 6. Achieved 100% delivery of all proposals on time while working\n",
      " on parallel deals\n",
      " 7. Hosted multiple customer visits including direct interaction\n",
      " with OEM’s.\n",
      " 8. Identifying customer pain points and developing / proposing\n",
      " solutions with a proactive pitch for new business wins including\n",
      " stafng, new solution deployment\n",
      "Duration Aug 2017 till May 2019\n",
      "\n",
      " 4. WiFi Middleware for Car Infotainment\n",
      " Systems\n",
      "Descriptio The project involves fxing issues and implementing Change\n",
      "n Requests for Diferent Customer programs\n",
      "Role Architect/Program Manager\n",
      "Company Wipro Technologies\n",
      "Skill C, Wif\n",
      "Environme\n",
      " Windows\n",
      "nt\n",
      "Hardware TI Micro Controller\n",
      " 1. As a scrum master, successfully met the deliverables in\n",
      " resolving defects and implementing DCR’s for SYNC GEN3\n",
      " project.\n",
      " 2. As an architect, gave solutions to the team in solving technical\n",
      "Contributi\n",
      " issues.\n",
      "on\n",
      " 3. Co-ordinated with all stake holders to communicate and follow\n",
      " up so that customer issues are addressed on time.\n",
      " 4. Managed the program as program manager ensuring quality\n",
      " deliverables on time\n",
      "Duration May 2015 till July 2017\n",
      "\n",
      "\n",
      " 5. Bluetooth Firmware\n",
      "Descriptio The project involves fxing issues on the BT Firmware controller\n",
      ",n\n",
      "Role Firmware Engineer\n",
      "Company Intel Mobile Communications\n",
      "Skill C, JTAG, Power Trace, signal monitor, protocol analyzer\n",
      "Environme\n",
      " Windows\n",
      "nt\n",
      "Hardware AG610 ARM based processor\n",
      " 1. As a lead, successfully resolved all issues (in AG610 platform)\n",
      " that resulted in product launch to OEM’s.\n",
      " 2. Achieved ‘zero defect count’ for AG610 based platform.\n",
      "Contributi 3. Optimized the existing code by more than 78% for Low Energy\n",
      "on Only Solution.\n",
      " 4. Co-ordinated with all stake holders to communicate and follow\n",
      " up so that customer issues are addressed on time for Samsung\n",
      " and Nokia.\n",
      "Duration August 2012 till May2015\n",
      "\n",
      " 6. AGPS (Assisted GPS) Development for\n",
      " SUPLV2.0\n",
      " The project involves developing features for SUPL2.0 (Secured\n",
      "Descriptio\n",
      " User Plane Location) protocol using which a user can identify his\n",
      "n\n",
      " position or other person’s position with the help of GPS server.\n",
      "Role Lead Engineer\n",
      "Company ST-Ericsson (worked at the client site)\n",
      "Skill C, Linux\n",
      "Environme\n",
      " Linux, windows\n",
      "nt\n",
      "Hardware CG900\n",
      " 1. Developing SUPL2.0 features like SUPL over WLAN, Third\n",
      " party location transfer/retrieval, Application ID, Session Info\n",
      " query etc.\n",
      " 2. Applied for patent for implementing MAC ID based reference\n",
      "Contributi location positioning in the android framework layer with the\n",
      "on google developers forum.\n",
      " 3. Lead the development team, coordinate with the necessary\n",
      " stake holders to resolve the issue to meet customer deadlines\n",
      " 4. Resolve/debug memory issues/crashes\n",
      " 5. Worked as an onsite coordinator for STE\n",
      "Duration April 2011 till July 2012\n",
      "\n",
      " 7. GPS (Global Positioning System) Driver\n",
      "Descriptio This project involves porting of Global Positioning System drivers\n",
      "n across various mobile platforms.\n",
      "Role Technical Lead\n",
      ",Company Intel Mobile Communications (worked at the client site)\n",
      "Skill C, ThreadX, Trace32\n",
      "Environme\n",
      " Lauterbach, RVCT compiler.\n",
      "nt\n",
      "Hardware XMM2130/XMM2230 ARM based processor\n",
      " 1. Porting of AGPS driver (I2C based) across diferent platforms\n",
      " 2. Board bring up on new software/hardware platform\n",
      "Contributi\n",
      " 3. Debugging issues while porting for new platform\n",
      "on\n",
      " 4. Hardware level debugging with oscilloscope/spectrum analyzer\n",
      " 5. Ported drivers in 33% time compared to average time\n",
      "Duration July 2010 to April 2011\n",
      "\n",
      " 8. MDI (Media Device Interface)\n",
      "\n",
      " The Media Device Interface (MDI) is a device developed for\n",
      "Descriptio Volkswagen (VW) by S1nn and Aricent. This Device would connect\n",
      "n and play Apple iPods and Mass Storage Devices in an “in-car\n",
      " entertainment system”.\n",
      "Role Sr. Software Engineer\n",
      "Customer S1nn, Germany\n",
      " Volkswagen, Bentley (Car Manufacturing companies)\n",
      "Client\n",
      "Skill C, ThreadX\n",
      "Environme\n",
      " Keil Uvision 3.\n",
      "nt\n",
      "Hardware Atmel AT91RM9200 processor\n",
      " 1. Implementation of DAI (Digital Audio Interface) module.\n",
      "Contributi 2. Involved as an individual contributor.\n",
      "on 3. Mentored and ramped up junior members of the team\n",
      " successfully\n",
      "Duration Jul 2007 to Aug 2008\n",
      "\n",
      " 9. MP3 CODEC Based Car Radios\n",
      " The Project involves playback of various audio fle formats such\n",
      "Description as MP3, WMA, AAC etc in single CD and six CD based radios for\n",
      " Ford and Hyundai cars\n",
      "Role Software Design Engineer\n",
      "Customer Ford, Hyundai\n",
      "Skill C\n",
      "Environme\n",
      " CCS\n",
      "nt\n",
      "Hardware TMS320C5410, TMS470\n",
      "Contributio 1. Bug fxes, application development for the TMS320C5410 DSP\n",
      "n based MP3 decoder subsystem.\n",
      ", 2. Lead the team successfully throughout the project duration.\n",
      " Mentored junior members into the project.\n",
      " 3. Successfully interacted with product development groups in\n",
      " US and Mexico which resulted in production releases.\n",
      " 4. Created technical proposals that resolved system issues and\n",
      " improved the quality of the Visteon radios.\n",
      "\n",
      "Duration Jan 2006 to June 2007\n",
      "\n",
      " 10. Tuner Component for SDARS (Satellite\n",
      " Digital Audio Radio Service) radios\n",
      "Descripti This project involves development of tuner component of Sirius and\n",
      "on XM car radios which provides satellite digital radio services to\n",
      " North America.\n",
      "Role Software Engineer\n",
      "Customer BMW, PAG, Ford\n",
      "Skill C, Clear case, MMOS\n",
      "Hardware MC9S12DP256 Motorola controller,\n",
      "Contribut 1. Involved in tuner component.\n",
      "ion 2. Actively involved in full software development life cycle\n",
      " 3. Successfully implemented new features which resulted in new\n",
      " business wins\n",
      " 4. On time delivery of quality work product\n",
      "Duration Jan 2004 to Dec 2005\n",
      "\n",
      "This is the output in the required_format:\n",
      "1. General Manager for Digital Cockpit practice in Automotive Domain @ BlueBinaries Engineering & Solutions Pvt. Ltd. FROM 03/2023 TO present : Successfully managed accounts with Tier-1’s from digital cockpit practice. Proposed and deployed resources asper plan with EBIDTA > 30%. Successfully managed to onboard ~40 resources in 2 months across 2 Tier-1’s. At least 1 RFQ / RFI was responded to per week on average. Spearheading an AI/ML based solution for doing “Gap analysis” of requirements which will yield savings of at least 150K USD / year.\n",
      "2. System Requirement Manager @ Harman International FROM 05/2019 TO 03/2023 : Managed a team of 6 including performance reviews, training needs, goal setting. Built re-usable platform requirements in IVI connectivity domains, to be used by various products, thereby saving efort and time of productization. Planning/executing road-map features which delivers business value to customers. Identifed the in-efciencies in the system and proposed ways to improve operational efciency by ~35%. Spearheading an AI/ML based solution for doing “Gap analysis” of requirements which will yield savings of at least 150K USD / year. Awarded “Exceeded Expectations” rating within 2 years of current experience.\n",
      "3. Presales Manager – IVI Domain @ Wipro Technologies FROM 08/2017 TO 05/2019 : Complete ownership of proposals in IVI domains across geographies for all major OEM’s and Tier-1’s. Customer Interaction with all leading OEM’s across all geographies. Won businesses with leading OEM and Tier-1’s including a multimillion-dollar (~$30 Million USD) deal win with an OEM for their Android based platform for production. Handled a portfolio of ~ $17 Million per quarter average revenue. Negotiating proposals with fnance, sales team after transforming engineering efort to cost. Achieved 100% delivery of all proposals on time while working on parallel deals. Hosted multiple customer visits including direct interaction with OEM’s. Identifying customer pain points and developing / proposing solutions with a proactive pitch for new business wins including stafng, new solution deployment.\n",
      "4. WiFi Middleware for Car Infotainment Systems @ Intel Mobile Communications FROM 08/2012 TO 05/2015 : As a lead, successfully resolved all issues (in AG610 platform) that resulted in product launch to OEM’s. Achieved ‘zero defect count’ for AG610 based platform. Lead the development team, coordinate with the necessary stake holders to resolve the issue to meet customer deadlines. Resolve/debug memory issues/crashes. Worked as an onsite coordinator for STE.\n",
      "5. Bluetooth Firmware @ Intel Mobile Communications FROM 07/2010 TO 04/2011 : As a lead, successfully resolved all issues (in AG610 platform) that resulted in product launch to OEM’s. Achieved ‘zero defect count’ for AG610 based platform. Lead the development team, coordinate with the necessary stake holders to resolve the issue to meet customer deadlines. Resolve/debug memory issues/crashes. Worked as an onsite coordinator for STE.\n",
      "6. AGPS (Assisted GPS) Development for SUPLV2.0 @ ST-Ericsson FROM 04/2011 TO 07/2012 : Developing SUPL2.0 features like SUPL over WLAN, Third party location transfer/retrieval, Application ID, Session Info query etc. Lead the development team, coordinate with the necessary stake holders to resolve the issue to meet customer deadlines. Resolve/debug memory issues/crashes. Worked as an onsite coordinator for STE.\n",
      "7. MDI (Media Device Interface) @ Intel Mobile Communications FROM 07/2007 TO 08/2008 : Implementation of DAI (Digital Audio Interface) module. Involved as an individual contributor. Mentored and ramped up junior members of the team successfully. Successfully interacted with product development groups in US and Mexico which resulted in production releases. Created technical proposals that resolved system issues and improved the quality of the Visteon radios.\n",
      "8. MP3 CODEC Based Car Radios @ Visteon FROM\n"
     ]
    }
   ],
   "source": [
    "from transformers import TextStreamer\n",
    "\n",
    "streamer = TextStreamer(tokenizer)\n",
    "model_input = tokenizer(ep,return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(tokenizer.decode(model.generate(**model_input, max_new_tokens=1024)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8886c1f1b906430793002ba50dd97486",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/109M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.push_to_hub('lakshay/linear-work-peft',token='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "2d58e898dde0263bc564c6968b04150abacfd33eed9b19aaa8e45c040360e146"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
