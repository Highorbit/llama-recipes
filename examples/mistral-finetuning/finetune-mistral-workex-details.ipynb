{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%bash\n",
    "# pip install transformers datasets accelerate sentencepiece protobuf==3.20 py7zr scipy peft bitsandbytes fire torch_tb_profiler ipywidgets tqdm vllm\n",
    "# TRANSFORM=`python -c \"import transformers;print('/'.join(transformers.__file__.split('/')[:-1])+'/models/llama/convert_llama_weighjts_to_hf.py')\"`\n",
    "# python ${TRANSFORM} --input_dir models --model_size 7B --output_dir models_hf/7B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# llama-recipes/src/llama_recipes/utils/dataset_utils.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work Experience (Shell Details)\n",
    "This notebook is meant to fine-tune Llama2 on Work Experience Details (all work experience minus the job description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 1: Load the model\n",
    "\n",
    "Point model_id to model weight folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "train_data = load_from_disk(\"../custom_data/mistral/work_details.hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Mar  4 12:52:13 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.154.05             Driver Version: 535.154.05   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A10G                    Off | 00000000:00:1E.0 Off |                    0 |\n",
      "|  0%   29C    P0              55W / 300W |      0MiB / 23028MiB |      4%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/ubuntu/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login(token='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Important \n",
    "\n",
    "It is important to consider here which model we're using to parse the resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a44f4378e80f460b88dbcf6183cffcf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a530adac9b6442c58fa95470c261aae2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_id=\"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, load_in_4bit=True, device_map='auto', torch_dtype=torch.float16, token='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MistralForCausalLM(\n",
       "  (model): MistralModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x MistralDecoderLayer(\n",
       "        (self_attn): MistralAttention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): MistralRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Mar  4 12:53:24 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.154.05             Driver Version: 535.154.05   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A10G                    Off | 00000000:00:1E.0 Off |                    0 |\n",
      "|  0%   31C    P0              59W / 300W |   5244MiB / 23028MiB |     22%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      6218      C   ...oedge/llama-recipes/env/bin/python3     5236MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.append('/home/ec2-user/SageMaker/llama_root/src')\n",
    "sys.path.append('../llama-recipes/src/llama_recipes/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Check base model\n",
    "\n",
    "Run the base model on an example input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "work_prompt = f'''\n",
    "You are an accurate agent working for a job platform. You will be given the raw \n",
    "unstructured text of a user's resume, and the task is to extract specific details about the work experience of the \n",
    "user from the resume. The JSON should include a \"work_experience\" key with an array of objects. \n",
    "Each object represents a job and should contain keys for \"company\", \"role\", \"start_date\", \"end_date\".\n",
    "Dates should be in \"mm/yyyy\" format. Please provide the data in a concise JSON format\n",
    "Ensure the JSON syntax is correct, with proper use of quotes, commas, and braces. Here is an example structure::\n",
    "\n",
    "Please follow this structure closely and keep the response within the token limit.\" \\n{{query_format}}\\n\n",
    "\n",
    "This is the resume text:\\n{{resume_text}}\\n\n",
    "This is the output in the required_format:\\n\n",
    "'''\n",
    "\n",
    "work_format = '''\n",
    "[\n",
    "    {\"company\":\"Example Company 1\",\n",
    "    \"role\":\"Example Role 1\",\n",
    "    \"start_date\":\"mm/yyyy\",\n",
    "    \"end_date\":\"mm/yyyy\"},\n",
    "    {\"company\":\"Example Company 2\",\n",
    "    \"role\":\"Example Role 2\",\"\n",
    "    start_date\":\"mm/yyyy\",\n",
    "    \"end_date\":\"mm/yyyy\"}\n",
    "]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import html\n",
    "\n",
    "df = pd.read_csv('../custom_data/latest_work_exp_28dec.csv')\n",
    "base_model_test_rt = html.unescape(df['resume'].sample().values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_prompt = work_prompt.format(resume_text=base_model_test_rt,\n",
    "                          query_format=work_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "2024-02-22 15:38:49.859990: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-22 15:38:49.907490: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-22 15:38:50.600863: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are an accurate agent working for a job platform. You will be given the raw \n",
      "unstructured text of a user's resume, and the task is to extract specific details about the work experience of the \n",
      "user from the resume. The JSON should include a \"work_experience\" key with an array of objects. \n",
      "Each object represents a job and should contain keys for \"company\", \"role\", \"start_date\", \"end_date\".\n",
      "Dates should be in \"mm/yyyy\" format. Please provide the data in a concise JSON format\n",
      "Ensure the JSON syntax is correct, with proper use of quotes, commas, and braces. Here is an example structure::\n",
      "\n",
      "Please follow this structure closely and keep the response within the token limit.\" \n",
      "\n",
      "[\n",
      "    {\"company\":\"Example Company 1\",\n",
      "    \"role\":\"Example Role 1\",\n",
      "    \"start_date\":\"mm/yyyy\",\n",
      "    \"end_date\":\"mm/yyyy\"},\n",
      "    {\"company\":\"Example Company 2\",\n",
      "    \"role\":\"Example Role 2\",\"\n",
      "    start_date\":\"mm/yyyy\",\n",
      "    \"end_date\":\"mm/yyyy\"}\n",
      "]\n",
      "\n",
      "\n",
      "\n",
      "This is the resume text:\n",
      " PARTH PRADIP SAWAI\n",
      " +91 9503183475 linkedin.com/in/parth-sawai-b39193236/\n",
      "\n",
      " Gadge Nagar, Poonam Photo Studio Line,\n",
      " parthsawai68@gmail.com\n",
      " Amravati, Maharashtra, 444604\n",
      "\n",
      "CAREER OBJECTIVE CERTIFICATION\n",
      "Dedicated individual with a strong foundation in Java programming Young Professional Course\n",
      "and a passion for software development. Aiming to contribute at TCS iON Career Edge\n",
      "effectively to a collaborative team environment and grow as a Duration: May 28, 2023 -\n",
      "valuable Java developer. June 12, 2023\n",
      " Hosted by TCS\n",
      "EDUCATION SKILLS\n",
      "Bachelor of Engineering in Information Technology at Sipna College Functional Skills\n",
      "of Engineering and Technology, Amravati Problem solving\n",
      "SGBAU, AMRAVATI (June 2020 - Present) Time Management\n",
      " Currently pursuing with a 77.95% grade percentage Communication\n",
      " CGPA of 8.61 Negotiation\n",
      "Higher Secondary School (HSC) (June 2019 - July 2020) Adaptability\n",
      " Collge: Vinayaka Vidya Mandir, Amravati, Maharashtra Decision Making\n",
      " Board: Maharashtra State Board Risk Management\n",
      " Percentage: 65.54%\n",
      " Technical Skills\n",
      "Secondary School Certificate (SSC) (June 2017 - July 2018)\n",
      " JAVA\n",
      " School: Podar International School, Amravati, Maharashtra\n",
      " Excel\n",
      " Board: Central Board of Secondary Education\n",
      " HTML\n",
      " Percentage: 70.8%\n",
      " CSS\n",
      " PROJECTS Microsoft word\n",
      "\n",
      " Vrinda Store Data Analysis (June 2023) LANGUAGES\n",
      " Employed fundamental Excel concepts to clean, process,\n",
      " Marathi (Native)\n",
      " analyze, and generate dashboards for data\n",
      " Hindi (Fluent)\n",
      " Utilized online resources for guidance and support\n",
      " English (Fluent)\n",
      " Amazon Clone Website (July 2023)\n",
      " Developed a fully functional Amazon clone website using HTML EXTRA-CURRICULAR\n",
      " and CSS. Master of the Codorithm\n",
      " Replicated essential e-commerce features, including product University Level Coding\n",
      " listings, a shopping cart, and user authentication. Competition (2022)\n",
      " Demonstrated strong front-end web development skills in HTML\n",
      " and CSS, delivering a visually appealing and responsive user PERSONAL INFORMATION\n",
      " interface.\n",
      " Date of Birth: 31/10/2002\n",
      " EXPERIENCE Hobbies: listening music ,\n",
      " Web Developer Intern at LAKSH IT SOLUTION Gardening\n",
      " Employed since OCT 2023 and currently working Sports: Badminton , Cricket\n",
      " Specializing in full stack web development with a focus on Java\n",
      "\n",
      "This is the output in the required_format:\n",
      "\n",
      "[\n",
      "    {\"company\":\"LAKSH IT SOLUTIONS\",\n",
      "    \"role\":\"Web Developer Intern\",\n",
      "    \"start_date\":\"OCT/2023\",\n",
      "    \"end_date\":\"Present\"}\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "model_input = tokenizer(eval_prompt,return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(tokenizer.decode(model.generate(**model_input, max_new_tokens=1024)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "We can see that the base model only repeats the conversation.\n",
    "\n",
    "### Step 4: Prepare model for PEFT\n",
    "\n",
    "Let's prepare the model for Parameter Efficient Fine Tuning (PEFT):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 3,407,872 || all params: 7,245,139,968 || trainable%: 0.04703666202518836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/infoedge/llama-recipes/env/lib/python3.10/site-packages/peft/utils/other.py:141: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "def create_peft_config(model):\n",
    "    from peft import (\n",
    "        get_peft_model,\n",
    "        LoraConfig,\n",
    "        TaskType,\n",
    "        prepare_model_for_int8_training,\n",
    "    )\n",
    "\n",
    "    peft_config = LoraConfig(\n",
    "        task_type=TaskType.CAUSAL_LM,\n",
    "        inference_mode=False,\n",
    "        r=8,\n",
    "        lora_alpha=16,\n",
    "        lora_dropout=0.05,\n",
    "        target_modules = [\"q_proj\", \"v_proj\"]\n",
    "    )\n",
    "    \n",
    "    # peft_config = LoraConfig(\n",
    "    #     task_type=TaskType.CAUSAL_LM,\n",
    "    #     inference_mode=False,\n",
    "    #     r=8,\n",
    "    #     lora_alpha=32,\n",
    "    #     lora_dropout=0.05,\n",
    "    #     target_modules = [\"q_proj\", \"v_proj\"]\n",
    "    # )\n",
    "\n",
    "    # prepare int-8 model for training\n",
    "    model = prepare_model_for_int8_training(model)\n",
    "    model = get_peft_model(model, peft_config)\n",
    "    model.print_trainable_parameters()\n",
    "    return model, peft_config\n",
    "\n",
    "# create peft config\n",
    "model, lora_config = create_peft_config(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Step 5: Define an optional profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import TrainerCallback\n",
    "from contextlib import nullcontext\n",
    "enable_profiler = False\n",
    "output_dir = \"tmp/mistral-output\"\n",
    "\n",
    "config = {\n",
    "    'lora_config': lora_config,\n",
    "    'learning_rate': 1e-4,\n",
    "    'num_train_epochs': 5,\n",
    "    'gradient_accumulation_steps': 2,\n",
    "    'per_device_train_batch_size': 2,\n",
    "    'gradient_checkpointing': True,\n",
    "}\n",
    "\n",
    "# Set up profiler\n",
    "if enable_profiler:\n",
    "    wait, warmup, active, repeat = 1, 1, 2, 1\n",
    "    total_steps = (wait + warmup + active) * (1 + repeat)\n",
    "    schedule =  torch.profiler.schedule(wait=wait, warmup=warmup, active=active, repeat=repeat)\n",
    "    profiler = torch.profiler.profile(\n",
    "        schedule=schedule,\n",
    "        on_trace_ready=torch.profiler.tensorboard_trace_handler(f\"{output_dir}/logs/tensorboard\"),\n",
    "        record_shapes=True,\n",
    "        profile_memory=True,\n",
    "        with_stack=True)\n",
    "    \n",
    "    class ProfilerCallback(TrainerCallback):\n",
    "        def __init__(self, profiler):\n",
    "            self.profiler = profiler\n",
    "            \n",
    "        def on_step_end(self, *args, **kwargs):\n",
    "            self.profiler.step()\n",
    "\n",
    "    profiler_callback = ProfilerCallback(profiler)\n",
    "else:\n",
    "    profiler = nullcontext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Mar  4 13:01:59 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.154.05             Driver Version: 535.154.05   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A10G                    Off | 00000000:00:1E.0 Off |                    0 |\n",
      "|  0%   31C    P0              59W / 300W |   6258MiB / 23028MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      6218      C   ...oedge/llama-recipes/env/bin/python3     6250MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Fine tune the model\n",
    "\n",
    "Here, we fine tune the model for a single epoch which takes a bit more than an hour on a A100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-04 13:02:01.505418: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 13:02:01.551593: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-04 13:02:02.231889: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "/home/ubuntu/infoedge/llama-recipes/env/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='310' max='310' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [310/310 1:12:45, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.980600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.962500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.775700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.747600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.714400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.760900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.727700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.702000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.595500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.655400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>1.646700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.749400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>1.660600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.610700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>1.470500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.688800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>1.599800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.562200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>1.593900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.612200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>1.543000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.672100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>1.503900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.443500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>1.474400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.561900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>1.573500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.573700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>1.535600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.588700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>1.477100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.502600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>1.511100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.702500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>1.538100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.496800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185</td>\n",
       "      <td>1.434300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.417600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>1.472100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.586700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>205</td>\n",
       "      <td>1.590900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.594900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>215</td>\n",
       "      <td>1.544600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.508700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>1.472300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1.522800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>235</td>\n",
       "      <td>1.510800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.395700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>245</td>\n",
       "      <td>1.610800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.509300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>255</td>\n",
       "      <td>1.473300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1.648800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>265</td>\n",
       "      <td>1.483400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1.516300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>1.408600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1.468100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>285</td>\n",
       "      <td>1.435200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1.495400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>295</td>\n",
       "      <td>1.477200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.549600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>305</td>\n",
       "      <td>1.538700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1.443600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import default_data_collator, Trainer, TrainingArguments\n",
    "\n",
    "# Define training args\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "    bf16=True,  # Use BF16 if available\n",
    "    # logging strategies\n",
    "    logging_dir=f\"{output_dir}/logs\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=5,\n",
    "    save_strategy=\"no\",\n",
    "    optim=\"adamw_torch_fused\",\n",
    "    max_steps=total_steps if enable_profiler else -1,\n",
    "    **{k:v for k,v in config.items() if k != 'lora_config'}\n",
    ")\n",
    "\n",
    "with profiler:\n",
    "    # Create Trainer instance\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_data,\n",
    "        data_collator=default_data_collator,\n",
    "        callbacks=[profiler_callback] if enable_profiler else [],\n",
    "    )\n",
    "\n",
    "    # Start training\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Mar  4 15:15:53 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.154.05             Driver Version: 535.154.05   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A10G                    Off | 00000000:00:1E.0 Off |                    0 |\n",
      "|  0%   31C    P0              60W / 300W |  15624MiB / 23028MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      6218      C   ...oedge/llama-recipes/env/bin/python3    15616MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 7:\n",
    "Save model checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.save_pretrained('tmp/llama2/work-details')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 8:\n",
    "Try the fine tuned model on the same example again to see the learning progress:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_df = pd.read_csv('../custom_data/iimjobs_eval_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(449, 5)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume\n",
      "VIJAY KUMAR\n",
      "Add. V.P.O. Khoh\n",
      "Jhunjhunu, Rajasthan (333053)\n",
      "Contact no-917357654164 /9650260083\n",
      "Email: - Vijaysain505@gmail.com\n",
      "Career Objective:-\n",
      " To work with the best Industry where I can utilize my skills, potential and\n",
      "functional expertise to the maximum and to add value to the organization in\n",
      "turn to elevate my personal capabilities.\n",
      "Work Experience:-\n",
      " Total 4 Years above work experience in Warehouse Inbound -\n",
      "out bound &Logistics.\n",
      " Currently working in VARUNA INTERGRATED L OGISTICS PVT\n",
      "LTD (GGN.)  as a CONTROL-TOWER EXECUTIVE from Dec -2018 to\n",
      "till now.\n",
      " 1 years worked experience with M/s. LAVA mobile company Noida as a\n",
      "Data entry Operator & associate from nov -2017 to dec-2018..\n",
      "Key Responsibilities & Performance Indicators:-\n",
      "CONTROL-TOWER executive VARUNA INTERGRATED L OGISTICS PVT LTD\n",
      "Dec-2018 to till nov.\n",
      " Prepare & Maintain Daily MIS Report.\n",
      " Prepare the other Reports review reports for Management.\n",
      " Responsible to make coordination with warehouse team.\n",
      " Handling Transport activity including E way bill, LR update, vehicle\n",
      "tracking, pod upload and trip closed.\n",
      " Responsible for Invoice matching in the system and to create invoice\n",
      "according to inbound material.\n",
      " Follows up with warehouse team to dispatch the shipments as per TAT.\n",
      " Working Control-Tower department for Secondary Transportation.\n",
      " Escalate DEPS (Damage Excess Pilferage Shortage) cases for all\n",
      "projects (Tares, Battery, and VMM).\n",
      " Managing transportation for dispatch time to time & loading\n",
      "activities.\n",
      " Processing the Orders as per FIFO Basis.\n",
      " Follow up with customer (Regarding order).\n",
      " Vehicle controlling and planning vehicle on time.\n",
      "\",\" Escalate delivery & unloading challenge with client.\n",
      " Filling of documents systematically as per 5S.\n",
      " We have Working Inward dispatch and billing team Transport\n",
      "Tracking for Vehicles\n",
      "1 year LAVA mobile company Noida as a Data entry Operator &\n",
      "associate :-\n",
      " Receiving material from diferent vendors, physical quantity\n",
      "verification, and entry of material as per the receipt quantity.\n",
      " Looking after GRN related to DC Inward and vendor follow up daily\n",
      "basis Responsible for all incoming shipments.\n",
      " Responsible to coordinate with diferent Courier parteners & making\n",
      "coordinate with the ground team for Diferent type Dispatch.\n",
      " Track courier packages. Responsible to take daily reports from the courier\n",
      "partners to manage the transportation facility smoothly.\n",
      " Put away of goods in respective location\n",
      " Making the Pick list for the order to be processed list.\n",
      " Making Challan Copy after Picking done (Qty Change & Batch\n",
      "Change).\n",
      " Physically and Quality Checking the items as per Challan Copy.\n",
      " Generating the Final Invoices after physically and Quality Checking\n",
      "done.\n",
      " Dispatch the material from warehouse to retail & distributors.\n",
      " Inventory management of warehouse stock.\n",
      " Daily Data entry process regarding stock out to diferent retails &\n",
      "distributors.\n",
      " Making Inventory Transactions in SAP.\n",
      " Maintain the 5S in Outward Dispatches.\n",
      " Able to handle the Multitask Operations of Dispatches.\n",
      " Very good knowledge of SAP.\n",
      "Educational Qualifcation\n",
      " B.A. Honors from Rajasthan University in 2013.\n",
      " Senior Secondary from RBSE in Year 2010.\n",
      " Secondary from RBSE in Year 2008.\n",
      "Computer Knowledge\n",
      "Having knowledge of MS Ofce & internet surfing\n",
      "Excel level skills , VLOOKUP, MS word , Pivot Table etc.\n",
      "Knowledge of E-mailing system and Internet.\n",
      "SAP - Confident to any other package ,Oracle retail Invoice\n",
      "matching ,RWMS & ,WAY BILL,ERP .\n",
      "\",\"Personal Profciency:\n",
      "5S, 3R, FIFO,4M & SOP.\n",
      "Personal Details\n",
      "Fathers Name- Mr. Sharwan Kumar Sain\n",
      "Date of Birth- 02.06. 1993\n",
      "Address - AS Above\n",
      "Marital Status - Unmarried\n",
      "Sex - Male\n",
      "Strengths- Self Motivated, Hard worker ,Team Worker.\n",
      "Hobbies- Traveling, playing Cricket.\n",
      "Language know- Hindi & English\n",
      "Nationality - Indian\n",
      "Religion - Hindu\n",
      "I certified that the information stated above is true and correct to the best of\n",
      "my knowledge.\n",
      "Date.\n",
      "Placegurgaon Vijay kumar\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import html \n",
    "rt = eval_df.sample()['resume'].values[0]\n",
    "rt = html.unescape(rt)\n",
    "print(rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "work_prompt = f'''\n",
    "You are an accurate agent working for a job platform. You will be given the raw \n",
    "unstructured text of a user's resume, and the task is to extract the entire work experience of the \n",
    "user from the resume. Please provide the data in a concise JSON format. The JSON should include a \n",
    "\"work_experience\" key with an array of objects. Each object represents a job and should contain keys for \n",
    "\"company\", \"role\", \"start_date\", \"end_date\". Dates should be in \"mm/yyyy\" format. \n",
    "Ensure the JSON syntax is correct, with proper use of quotes, commas, and braces.\n",
    "\n",
    "Please follow this structure closely and keep the response within the token limit.\" \\n{{query_format}}\\n\n",
    "\n",
    "This is the resume text:\\n{{resume_text}}\\n\n",
    "This is the output in the required_format\\n\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "work_format = '''\n",
    "[\n",
    "    {\"company\":\"Example Company 1\",\n",
    "    \"role\":\"Example Role 1\",\n",
    "    \"start_date\":\"mm/yyyy\",\n",
    "    \"end_date\":\"mm/yyyy\",\n",
    "    \"description\":\"Example Description 1\"},\n",
    "    {\"company\":\"Example Company 2\",\n",
    "    \"role\":\"Example Role 2\",\"\n",
    "    start_date\":\"mm/yyyy\",\n",
    "    \"end_date\":\"mm/yyyy\",\n",
    "    \"description\":\"Example Description 2\"}\n",
    "]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "eval_prompt = work_prompt.format(\n",
    "            query_format=work_format,\n",
    "            resume_text=rt)\n",
    "\n",
    "sample_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1431"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_input['input_ids'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken :7.73288369178772\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    full_document = tokenizer.decode(model.generate(**sample_input, max_new_tokens=1000)[0], skip_special_tokens=True)\n",
    "print(f'Time taken :{time.time()-start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are an accurate agent working for a job platform. You will be given the raw \n",
      "unstructured text of a user's resume, and the task is to extract the entire work experience of the \n",
      "user from the resume. Please provide the data in a concise JSON format. The JSON should include a \n",
      "\"work_experience\" key with an array of objects. Each object represents a job and should contain keys for \n",
      "\"company\", \"role\", \"start_date\", \"end_date\". Dates should be in \"mm/yyyy\" format. \n",
      "Ensure the JSON syntax is correct, with proper use of quotes, commas, and braces.\n",
      "\n",
      "Please follow this structure closely and keep the response within the token limit.\" \n",
      "\n",
      "[\n",
      "    {\"company\":\"Example Company 1\",\n",
      "    \"role\":\"Example Role 1\",\n",
      "    \"start_date\":\"mm/yyyy\",\n",
      "    \"end_date\":\"mm/yyyy\",\n",
      "    \"description\":\"Example Description 1\"},\n",
      "    {\"company\":\"Example Company 2\",\n",
      "    \"role\":\"Example Role 2\",\"\n",
      "    start_date\":\"mm/yyyy\",\n",
      "    \"end_date\":\"mm/yyyy\",\n",
      "    \"description\":\"Example Description 2\"}\n",
      "]\n",
      "\n",
      "\n",
      "\n",
      "This is the resume text:\n",
      "Resume\n",
      "VIJAY KUMAR\n",
      "Add. V.P.O. Khoh\n",
      "Jhunjhunu, Rajasthan (333053)\n",
      "Contact no-917357654164 /9650260083\n",
      "Email: - Vijaysain505@gmail.com\n",
      "Career Objective:-\n",
      " To work with the best Industry where I can utilize my skills, potential and\n",
      "functional expertise to the maximum and to add value to the organization in\n",
      "turn to elevate my personal capabilities.\n",
      "Work Experience:-\n",
      " Total 4 Years above work experience in Warehouse Inbound -\n",
      "out bound &Logistics.\n",
      " Currently working in VARUNA INTERGRATED L OGISTICS PVT\n",
      "LTD (GGN.)  as a CONTROL-TOWER EXECUTIVE from Dec -2018 to\n",
      "till now.\n",
      " 1 years worked experience with M/s. LAVA mobile company Noida as a\n",
      "Data entry Operator & associate from nov -2017 to dec-2018..\n",
      "Key Responsibilities & Performance Indicators:-\n",
      "CONTROL-TOWER executive VARUNA INTERGRATED L OGISTICS PVT LTD\n",
      "Dec-2018 to till nov.\n",
      " Prepare & Maintain Daily MIS Report.\n",
      " Prepare the other Reports review reports for Management.\n",
      " Responsible to make coordination with warehouse team.\n",
      " Handling Transport activity including E way bill, LR update, vehicle\n",
      "tracking, pod upload and trip closed.\n",
      " Responsible for Invoice matching in the system and to create invoice\n",
      "according to inbound material.\n",
      " Follows up with warehouse team to dispatch the shipments as per TAT.\n",
      " Working Control-Tower department for Secondary Transportation.\n",
      " Escalate DEPS (Damage Excess Pilferage Shortage) cases for all\n",
      "projects (Tares, Battery, and VMM).\n",
      " Managing transportation for dispatch time to time & loading\n",
      "activities.\n",
      " Processing the Orders as per FIFO Basis.\n",
      " Follow up with customer (Regarding order).\n",
      " Vehicle controlling and planning vehicle on time.\n",
      "\",\" Escalate delivery & unloading challenge with client.\n",
      " Filling of documents systematically as per 5S.\n",
      " We have Working Inward dispatch and billing team Transport\n",
      "Tracking for Vehicles\n",
      "1 year LAVA mobile company Noida as a Data entry Operator &\n",
      "associate :-\n",
      " Receiving material from diferent vendors, physical quantity\n",
      "verification, and entry of material as per the receipt quantity.\n",
      " Looking after GRN related to DC Inward and vendor follow up daily\n",
      "basis Responsible for all incoming shipments.\n",
      " Responsible to coordinate with diferent Courier parteners & making\n",
      "coordinate with the ground team for Diferent type Dispatch.\n",
      " Track courier packages. Responsible to take daily reports from the courier\n",
      "partners to manage the transportation facility smoothly.\n",
      " Put away of goods in respective location\n",
      " Making the Pick list for the order to be processed list.\n",
      " Making Challan Copy after Picking done (Qty Change & Batch\n",
      "Change).\n",
      " Physically and Quality Checking the items as per Challan Copy.\n",
      " Generating the Final Invoices after physically and Quality Checking\n",
      "done.\n",
      " Dispatch the material from warehouse to retail & distributors.\n",
      " Inventory management of warehouse stock.\n",
      " Daily Data entry process regarding stock out to diferent retails &\n",
      "distributors.\n",
      " Making Inventory Transactions in SAP.\n",
      " Maintain the 5S in Outward Dispatches.\n",
      " Able to handle the Multitask Operations of Dispatches.\n",
      " Very good knowledge of SAP.\n",
      "Educational Qualifcation\n",
      " B.A. Honors from Rajasthan University in 2013.\n",
      " Senior Secondary from RBSE in Year 2010.\n",
      " Secondary from RBSE in Year 2008.\n",
      "Computer Knowledge\n",
      "Having knowledge of MS Ofce & internet surfing\n",
      "Excel level skills , VLOOKUP, MS word , Pivot Table etc.\n",
      "Knowledge of E-mailing system and Internet.\n",
      "SAP - Confident to any other package ,Oracle retail Invoice\n",
      "matching ,RWMS & ,WAY BILL,ERP .\n",
      "\",\"Personal Profciency:\n",
      "5S, 3R, FIFO,4M & SOP.\n",
      "Personal Details\n",
      "Fathers Name- Mr. Sharwan Kumar Sain\n",
      "Date of Birth- 02.06. 1993\n",
      "Address - AS Above\n",
      "Marital Status - Unmarried\n",
      "Sex - Male\n",
      "Strengths- Self Motivated, Hard worker ,Team Worker.\n",
      "Hobbies- Traveling, playing Cricket.\n",
      "Language know- Hindi & English\n",
      "Nationality - Indian\n",
      "Religion - Hindu\n",
      "I certified that the information stated above is true and correct to the best of\n",
      "my knowledge.\n",
      "Date.\n",
      "Placegurgaon Vijay kumar\n",
      "\n",
      "\n",
      "This is the output in the required_format\n",
      "\n",
      "[{'company': 'VARUNA INTERGRATED L OGISTICS PVT LTD', 'role': 'CONTROL-TOWER EXECUTIVE', 'start_date': '12/2018', 'end_date': 'present'}, {'company': 'LAVA mobile company Noida', 'role': 'Data entry Operator & associate', 'start_date': '11/2017', 'end_date': '12/2018'}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(full_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "out_str = full_document.replace(eval_prompt,\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'company': 'VARUNA INTERGRATED L OGISTICS PVT LTD',\n",
       "  'role': 'CONTROL-TOWER EXECUTIVE',\n",
       "  'start_date': '12/2018',\n",
       "  'end_date': 'present'},\n",
       " {'company': 'LAVA mobile company Noida',\n",
       "  'role': 'Data entry Operator & associate',\n",
       "  'start_date': '11/2017',\n",
       "  'end_date': '12/2018'}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ast.literal_eval(out_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bed54eeaa71c457caf5369d223f18563",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/13.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/lakshay/mistral-work-peft/commit/d60925978db009605be10bc5126006c66fd80905', commit_message='Upload model', commit_description='', oid='d60925978db009605be10bc5126006c66fd80905', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub('lakshay/mistral-work-peft',token='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "2d58e898dde0263bc564c6968b04150abacfd33eed9b19aaa8e45c040360e146"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
