{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Meta Platforms, Inc. and affiliates.\n",
    "This software may be used and distributed according to the terms of the Llama 2 Community License Agreement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "This notebook shows how to train a Llama 2 model on a single GPU (e.g. A10 with 24GB) using int8 quantization and LoRA.\n",
    "\n",
    "### Step 0: Install pre-requirements and convert checkpoint\n",
    "\n",
    "We use the Hugging Face trainer and model which means that the checkpoint has to be converted from its original format into the dedicated Hugging Face format.\n",
    "The conversion can be achieved by running the `convert_llama_weights_to_hf.py` script provided with the transformer package.\n",
    "Given that the original checkpoint resides under `models/7B` we can install all requirements and convert the checkpoint with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%bash\n",
    "# pip install transformers datasets accelerate sentencepiece protobuf==3.20 py7zr scipy peft bitsandbytes fire torch_tb_profiler ipywidgets tqdm vllm\n",
    "# TRANSFORM=`python -c \"import transformers;print('/'.join(transformers.__file__.split('/')[:-1])+'/models/llama/convert_llama_weighjts_to_hf.py')\"`\n",
    "# python ${TRANSFORM} --input_dir models --model_size 7B --output_dir models_hf/7B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# llama-recipes/src/llama_recipes/utils/dataset_utils.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 1: Load the model\n",
    "\n",
    "Point model_id to model weight folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "train_data = load_from_disk(\"custom_data/train_data.hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pi_data = load_from_disk('custom_data/pi_data.hf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/ubuntu/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login(token='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Important \n",
    "\n",
    "It is important to consider here which model we're using to parse the resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab054053c947408da44664abc288f8c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer\n",
    "\n",
    "model_id=\"meta-llama/Llama-2-7b-chat-hf\"\n",
    "\n",
    "tokenizer = LlamaTokenizer.from_pretrained(model_id)\n",
    "\n",
    "model = LlamaForCausalLM.from_pretrained(model_id, load_in_8bit=True, device_map='auto', torch_dtype=torch.float16, token='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.append('/home/ec2-user/SageMaker/llama_root/src')\n",
    "sys.path.append('../llama-recipes/src/llama_recipes/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Check base model\n",
    "\n",
    "Run the base model on an example input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summarize this dialog:\n",
      "A: Hi Tom, are you busy tomorrow’s afternoon?\n",
      "B: I’m pretty sure I am. What’s up?\n",
      "A: Can you go with me to the animal shelter?.\n",
      "B: What do you want to do?\n",
      "A: I want to get a puppy for my son.\n",
      "B: That will make him so happy.\n",
      "A: Yeah, we’ve discussed it many times. I think he’s ready now.\n",
      "B: That’s good. Raising a dog is a tough issue. Like having a baby ;-) \n",
      "A: I'll get him one of those little dogs.\n",
      "B: One that won't grow up too big;-)\n",
      "A: And eat too much;-))\n",
      "B: Do you know which one he would like?\n",
      "A: Oh, yes, I took him there last Monday. He showed me one that he really liked.\n",
      "B: I bet you had to drag him away.\n",
      "A: He wanted to take it home right away ;-).\n",
      "B: I wonder what he'll name it.\n",
      "A: He said he’d name it after his dead hamster – Lemmy  - he's  a great Motorhead fan :-)))\n",
      "---\n",
      "Summary:\n",
      "A is asking B if they are free the next afternoon to go to the animal shelter together to get a puppy for A's son. B agrees and mentions that raising a dog is a lot of work, like having a baby. A says they will get a small dog that won't grow too big and eat too much. B wonders which dog A's son will like and A mentions that their son wants to name the dog after his dead hamster, Lemmy.\n"
     ]
    }
   ],
   "source": [
    "eval_prompt = \"\"\"\n",
    "Summarize this dialog:\n",
    "A: Hi Tom, are you busy tomorrow’s afternoon?\n",
    "B: I’m pretty sure I am. What’s up?\n",
    "A: Can you go with me to the animal shelter?.\n",
    "B: What do you want to do?\n",
    "A: I want to get a puppy for my son.\n",
    "B: That will make him so happy.\n",
    "A: Yeah, we’ve discussed it many times. I think he’s ready now.\n",
    "B: That’s good. Raising a dog is a tough issue. Like having a baby ;-) \n",
    "A: I'll get him one of those little dogs.\n",
    "B: One that won't grow up too big;-)\n",
    "A: And eat too much;-))\n",
    "B: Do you know which one he would like?\n",
    "A: Oh, yes, I took him there last Monday. He showed me one that he really liked.\n",
    "B: I bet you had to drag him away.\n",
    "A: He wanted to take it home right away ;-).\n",
    "B: I wonder what he'll name it.\n",
    "A: He said he’d name it after his dead hamster – Lemmy  - he's  a great Motorhead fan :-)))\n",
    "---\n",
    "Summary:\n",
    "\"\"\"\n",
    "\n",
    "model_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(tokenizer.decode(model.generate(**model_input, max_new_tokens=100)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "resume_text = f'''\n",
    "Manuj Jagga 767, Dashmesh colony, Street No 4, Ward No 4, Malout, Punjab, 152107 8130909979 | manujjagga421@gmail.com | manujjagga421 \n",
    "Summary Current Android Developer at Highorbit Careers Pvt. Ltd. (iimjobs.com | hirist.com). Been working at Highorbit Careers Pvt. Ltd. for more than a year now. Former Android Developer at Kisan Network (Y Combinator and Theil fellowship funded startup), Interned at Carebuddy and Edward Ganj Public Welfare Association. \n",
    "Work Experience Highorbit Careers Pvt. Ltd. (iimjobs.com | hirist.com) Delhi ANDROID DEVELOPER Jan 2019 - PRESENT &bull; Built hirist app with latest android jetpack and architecture components &bull; Built end to end Android side for inhouse text, audio and video chat using webRTC \n",
    "Kisan Network Gurgaon ANDROID ENGINEER June 2017 - Jan 2019 &bull; Worked on operations apps for feild executives of Kisan Network &bull; Built customised camera using Android Camera2 API with realtime focus detection &bull; Developed most of the required backed APIs using node.js Carebuddy Noida \n",
    "ANDROID DEVELOPER INTERN May 2016 - Aug. 2016 &bull; Developed the promotional FirstAid info and blood donation network app Edward Ganj Public Welfare Association Malout ANDROID DEVELOPER INTERN March 2016 - April 2016 &bull; Developed an Android app for operations of their public Library. \n",
    "Education Shiv Nadar University Greater Noida, Uttar Pradesh B.TECH(COMPUTER SCIENCE AND ENGINEERING) Aug. 2013 - Aug. 2017 &bull; CGPA- 7.98/10 D.A.V. Edward Ganj Public School Malout, Punjab HIGH SCHOOL-12TH 2013 &bull; Passed with 89.6 % marks D.A.V. Edward Ganj Public School Malout, Punjab MATRICULATION-10TH 2011 &bull; Passed with 8.8/10 CGPA Projects Video Conferencing using WebRTC Highorbit Careers Pvt. Ltd. APP DEVELOPER Android, Java, Kotlin &bull; One to One video conferencing using WebRTC. WebRTC allows direct peer-to-peer communication, eliminating the need to install plugins or download native apps. Custom camera using Camera2 API with real time focus detection Kisan Network APP DEVELOPER Android, Java &bull; Camera that allows you to click image only when it is focused as those images were later processed to determine the quality of the crops. Spatial Querying for e-travel portal \n",
    "Final Year Research Project APP DEVELOPER Android, Java &bull; Travel portal that segregates ratings of the hotels based on you demographics and also lets you process mCk queries i.e. finding which are k places closest to a particular hotel. ,Skills JAVA, Android, Kotlin, MVVM, Dagger, Room, Navigation Architecture component, Retrofit, Room Database, LiveData, Node.js, Programming SQL, Arduino, LaTex Languages English, Hindi, Punjabi Extracurriculars HP Summer Training Program Chandigarh TRAINEE May 2015 - June 2015 &bull; Gained expertise in JAVA which further helped me in stepping into Android Development. &bull; \n",
    "Made a complaint management and hostel room allocation system as a part of their final project using JAVA\n",
    "\n",
    "'''\n",
    "\n",
    "r_format = '''{\n",
    "    'work_experience': [{'company': 'company Name 1',\n",
    "                         'role': 'job designation 1',\n",
    "                         'start_date': 'starting date as given in resume (mm/yy)',\n",
    "                         'end_date': 'ending date as given in resume (mm/yy)',\n",
    "                         'description': 'Job description taken from resume'},\n",
    "                        {'company': 'company name 2',\n",
    "                         'role': 'job designation 1',\n",
    "                         'start_date': 'starting date as given in resume (mm/yy)',\n",
    "                         'end_date': 'ending date as given in resume (mm/yy)',\n",
    "                         'description': 'Job description taken from resume'}]\n",
    "}'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "r_format = '''{\n",
    "    'work_experience': [{'company': 'company Name 1',\n",
    "                         'role': 'job designation 1',\n",
    "                         'start_date': 'starting date as given in resume (mm/yy)',\n",
    "                         'end_date': 'ending date as given in resume (mm/yy)',\n",
    "                         'description': 'Job description taken from resume'},\n",
    "                        {'company': 'company name 2',\n",
    "                         'role': 'job designation 1',\n",
    "                         'start_date': 'starting date as given in resume (mm/yy)',\n",
    "                         'end_date': 'ending date as given in resume (mm/yy)',\n",
    "                         'description': 'Job description taken from resume'}]\n",
    "}'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_prompt = f'''Given a user's resume text\n",
    "                extract the user's work experience from the resume in this format :\\n\\n{r_format}\\n\\n\n",
    "                Resume Text : \\n\\n{resume_text}\\n\\n\n",
    "                \n",
    "                Output : \\n\\n\n",
    "                '''\n",
    "sample_input = tokenizer(sample_prompt, return_tensors=\"pt\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given a user's resume text\n",
      "                extract the user's work experience from the resume in this format :\n",
      "\n",
      "{\n",
      "    'work_experience': [{'company': 'company Name 1',\n",
      "                         'role': 'job designation 1',\n",
      "                         'start_date': 'starting date as given in resume (mm/yy)',\n",
      "                         'end_date': 'ending date as given in resume (mm/yy)',\n",
      "                         'description': 'Job description taken from resume'},\n",
      "                        {'company': 'company name 2',\n",
      "                         'role': 'job designation 1',\n",
      "                         'start_date': 'starting date as given in resume (mm/yy)',\n",
      "                         'end_date': 'ending date as given in resume (mm/yy)',\n",
      "                         'description': 'Job description taken from resume'}]\n",
      "}\n",
      "\n",
      "\n",
      "                Resume Text : \n",
      "\n",
      "\n",
      "Manuj Jagga 767, Dashmesh colony, Street No 4, Ward No 4, Malout, Punjab, 152107 8130909979 | manujjagga421@gmail.com | manujjagga421 \n",
      "Summary Current Android Developer at Highorbit Careers Pvt. Ltd. (iimjobs.com | hirist.com). Been working at Highorbit Careers Pvt. Ltd. for more than a year now. Former Android Developer at Kisan Network (Y Combinator and Theil fellowship funded startup), Interned at Carebuddy and Edward Ganj Public Welfare Association. \n",
      "Work Experience Highorbit Careers Pvt. Ltd. (iimjobs.com | hirist.com) Delhi ANDROID DEVELOPER Jan 2019 - PRESENT &bull; Built hirist app with latest android jetpack and architecture components &bull; Built end to end Android side for inhouse text, audio and video chat using webRTC \n",
      "Kisan Network Gurgaon ANDROID ENGINEER June 2017 - Jan 2019 &bull; Worked on operations apps for feild executives of Kisan Network &bull; Built customised camera using Android Camera2 API with realtime focus detection &bull; Developed most of the required backed APIs using node.js Carebuddy Noida \n",
      "ANDROID DEVELOPER INTERN May 2016 - Aug. 2016 &bull; Developed the promotional FirstAid info and blood donation network app Edward Ganj Public Welfare Association Malout ANDROID DEVELOPER INTERN March 2016 - April 2016 &bull; Developed an Android app for operations of their public Library. \n",
      "Education Shiv Nadar University Greater Noida, Uttar Pradesh B.TECH(COMPUTER SCIENCE AND ENGINEERING) Aug. 2013 - Aug. 2017 &bull; CGPA- 7.98/10 D.A.V. Edward Ganj Public School Malout, Punjab HIGH SCHOOL-12TH 2013 &bull; Passed with 89.6 % marks D.A.V. Edward Ganj Public School Malout, Punjab MATRICULATION-10TH 2011 &bull; Passed with 8.8/10 CGPA Projects Video Conferencing using WebRTC Highorbit Careers Pvt. Ltd. APP DEVELOPER Android, Java, Kotlin &bull; One to One video conferencing using WebRTC. WebRTC allows direct peer-to-peer communication, eliminating the need to install plugins or download native apps. Custom camera using Camera2 API with real time focus detection Kisan Network APP DEVELOPER Android, Java &bull; Camera that allows you to click image only when it is focused as those images were later processed to determine the quality of the crops. Spatial Querying for e-travel portal \n",
      "Final Year Research Project APP DEVELOPER Android, Java &bull; Travel portal that segregates ratings of the hotels based on you demographics and also lets you process mCk queries i.e. finding which are k places closest to a particular hotel. ,Skills JAVA, Android, Kotlin, MVVM, Dagger, Room, Navigation Architecture component, Retrofit, Room Database, LiveData, Node.js, Programming SQL, Arduino, LaTex Languages English, Hindi, Punjabi Extracurriculars HP Summer Training Program Chandigarh TRAINEE May 2015 - June 2015 &bull; Gained expertise in JAVA which further helped me in stepping into Android Development. &bull; \n",
      "Made a complaint management and hostel room allocation system as a part of their final project using JAVA\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                \n",
      "                Output : \n",
      "\n",
      "\n",
      "                  This is the output in the required_format:\n",
      "$[{'company': 'Highorbit Careers Pvt. Ltd. (iimjobs.com | hirist.com)', 'role': 'Android Developer', 'start_date': 'Jan 2019', 'end_date': 'Present', 'description': 'Built hirist app with latest android jetpack and architecture components. Built end to end Android side for inhouse text, audio and video chat using webRTC.'}, {'company': 'Kisan Network', 'role': 'Android Engineer', 'start_date': 'June 2017', 'end_date': 'Jan 2019', 'description': 'Worked on operations apps for feild executives of Kisan Network. Built customised camera using Android Camera2 API with realtime focus detection. Developed most of the required backed APIs using node.js.'}, {'company': 'Carebuddy', 'role': 'Intern', 'start_date': 'May 2016', 'end_date': 'Aug. 2016', 'description': 'Developed the promotional FirstAid info and blood donation network app.'}, {'company': 'Edward Ganj Public Welfare Association', 'role': 'Intern', 'start_date': 'March 2016', 'end_date': 'April 2016', 'description': 'Developed an Android app for operations of their public Library.'}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(tokenizer.decode(model.generate(**sample_input, max_new_tokens=1000)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'company': 'Highorbit Careers Pvt. Ltd. (iimjobs.com | hirist.com)',\n",
       "  'role': 'Android Developer',\n",
       "  'start_date': 'Jan 2019',\n",
       "  'end_date': 'Present',\n",
       "  'description': 'Built hirist app with latest android jetpack and architecture components. Built end to end Android side for inhouse text, audio and video chat using webRTC.'},\n",
       " {'company': 'Kisan Network',\n",
       "  'role': 'Android Engineer',\n",
       "  'start_date': 'June 2017',\n",
       "  'end_date': 'Jan 2019',\n",
       "  'description': 'Worked on operations apps for feild executives of Kisan Network. Built customised camera using Android Camera2 API with realtime focus detection. Developed most of the required backed APIs using node.js.'},\n",
       " {'company': 'Carebuddy',\n",
       "  'role': 'Intern',\n",
       "  'start_date': 'May 2016',\n",
       "  'end_date': 'Aug. 2016',\n",
       "  'description': 'Developed the promotional FirstAid info and blood donation network app.'},\n",
       " {'company': 'Edward Ganj Public Welfare Association',\n",
       "  'role': 'Intern',\n",
       "  'start_date': 'March 2016',\n",
       "  'end_date': 'April 2016',\n",
       "  'description': 'Developed an Android app for operations of their public Library.'}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[{'company': 'Highorbit Careers Pvt. Ltd. (iimjobs.com | hirist.com)', 'role': 'Android Developer', 'start_date': 'Jan 2019', 'end_date': 'Present', 'description': 'Built hirist app with latest android jetpack and architecture components. Built end to end Android side for inhouse text, audio and video chat using webRTC.'}, {'company': 'Kisan Network', 'role': 'Android Engineer', 'start_date': 'June 2017', 'end_date': 'Jan 2019', 'description': 'Worked on operations apps for feild executives of Kisan Network. Built customised camera using Android Camera2 API with realtime focus detection. Developed most of the required backed APIs using node.js.'}, {'company': 'Carebuddy', 'role': 'Intern', 'start_date': 'May 2016', 'end_date': 'Aug. 2016', 'description': 'Developed the promotional FirstAid info and blood donation network app.'}, {'company': 'Edward Ganj Public Welfare Association', 'role': 'Intern', 'start_date': 'March 2016', 'end_date': 'April 2016', 'description': 'Developed an Android app for operations of their public Library.'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "We can see that the base model only repeats the conversation.\n",
    "\n",
    "### Step 4: Prepare model for PEFT\n",
    "\n",
    "Let's prepare the model for Parameter Efficient Fine Tuning (PEFT):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/infoedge/llama-recipes/env/lib/python3.10/site-packages/peft/utils/other.py:141: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 33,554,432 || all params: 6,771,970,048 || trainable%: 0.49548996469513035\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "def create_peft_config(model):\n",
    "    from peft import (\n",
    "        get_peft_model,\n",
    "        LoraConfig,\n",
    "        TaskType,\n",
    "        prepare_model_for_int8_training,\n",
    "    )\n",
    "\n",
    "    peft_config = LoraConfig(\n",
    "        task_type=TaskType.CAUSAL_LM,\n",
    "        inference_mode=False,\n",
    "        r=64,\n",
    "        lora_alpha=32,\n",
    "        lora_dropout=0.05,\n",
    "        target_modules = [\"q_proj\", \"v_proj\"]\n",
    "    )\n",
    "    \n",
    "    # peft_config = LoraConfig(\n",
    "    #     task_type=TaskType.CAUSAL_LM,\n",
    "    #     inference_mode=False,\n",
    "    #     r=8,\n",
    "    #     lora_alpha=32,\n",
    "    #     lora_dropout=0.05,\n",
    "    #     target_modules = [\"q_proj\", \"v_proj\"]\n",
    "    # )\n",
    "\n",
    "    # prepare int-8 model for training\n",
    "    model = prepare_model_for_int8_training(model)\n",
    "    model = get_peft_model(model, peft_config)\n",
    "    model.print_trainable_parameters()\n",
    "    return model, peft_config\n",
    "\n",
    "# create peft config\n",
    "model, lora_config = create_peft_config(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Step 5: Define an optional profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import TrainerCallback\n",
    "from contextlib import nullcontext\n",
    "enable_profiler = False\n",
    "output_dir = \"tmp/llama-output\"\n",
    "\n",
    "config = {\n",
    "    'lora_config': lora_config,\n",
    "    'learning_rate': 1e-4,\n",
    "    'num_train_epochs': 3,\n",
    "    'gradient_accumulation_steps': 2,\n",
    "    'per_device_train_batch_size': 2,\n",
    "    'gradient_checkpointing': False,\n",
    "}\n",
    "\n",
    "# Set up profiler\n",
    "if enable_profiler:\n",
    "    wait, warmup, active, repeat = 1, 1, 2, 1\n",
    "    total_steps = (wait + warmup + active) * (1 + repeat)\n",
    "    schedule =  torch.profiler.schedule(wait=wait, warmup=warmup, active=active, repeat=repeat)\n",
    "    profiler = torch.profiler.profile(\n",
    "        schedule=schedule,\n",
    "        on_trace_ready=torch.profiler.tensorboard_trace_handler(f\"{output_dir}/logs/tensorboard\"),\n",
    "        record_shapes=True,\n",
    "        profile_memory=True,\n",
    "        with_stack=True)\n",
    "    \n",
    "    class ProfilerCallback(TrainerCallback):\n",
    "        def __init__(self, profiler):\n",
    "            self.profiler = profiler\n",
    "            \n",
    "        def on_step_end(self, *args, **kwargs):\n",
    "            self.profiler.step()\n",
    "\n",
    "    profiler_callback = ProfilerCallback(profiler)\n",
    "else:\n",
    "    profiler = nullcontext()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Fine tune the model\n",
    "\n",
    "Here, we fine tune the model for a single epoch which takes a bit more than an hour on a A100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "/home/ubuntu/infoedge/llama-recipes/env/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/infoedge/llama-recipes/env/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/ubuntu/infoedge/llama-recipes/env/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='261' max='261' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [261/261 1:02:17, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.380400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.166600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.112900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.047900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.974100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.986800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.926400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.972300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.086200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>1.838800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.936800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>1.855500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.895200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>1.810600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.810000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>1.729900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.792200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>1.857800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.705100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>1.654200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.736600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>1.764100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.594500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>1.800800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.779000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>1.734100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.911900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>1.748200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.673300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>1.816200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.833300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>1.687000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.710800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>1.708700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.642300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185</td>\n",
       "      <td>1.734700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.664200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>1.695500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.820300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>205</td>\n",
       "      <td>1.698500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.698100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>215</td>\n",
       "      <td>1.668700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.777500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>1.713800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1.687300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>235</td>\n",
       "      <td>1.724900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.688600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>245</td>\n",
       "      <td>1.678600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.505100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>255</td>\n",
       "      <td>1.648400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1.842800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import default_data_collator, Trainer, TrainingArguments\n",
    "\n",
    "# Define training args\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "    bf16=True,  # Use BF16 if available\n",
    "    # logging strategies\n",
    "    logging_dir=f\"{output_dir}/logs\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=5,\n",
    "    save_strategy=\"no\",\n",
    "    optim=\"adamw_torch_fused\",\n",
    "    max_steps=total_steps if enable_profiler else -1,\n",
    "    **{k:v for k,v in config.items() if k != 'lora_config'}\n",
    ")\n",
    "\n",
    "with profiler:\n",
    "    # Create Trainer instance\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_data,\n",
    "        data_collator=default_data_collator,\n",
    "        callbacks=[profiler_callback] if enable_profiler else [],\n",
    "    )\n",
    "\n",
    "    # Start training\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('done, on the 22nd of December, the year of our lord 2023')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 7:\n",
    "Save model checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 8:\n",
    "Try the fine tuned model on the same example again to see the learning progress:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_df = pd.read_csv('custom_data/model_eval_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(161, 5)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAMPALA VENKATASAI\n",
      "Backend Developer\n",
      "E 9666704364 jampalavenkatasai99@gmail.com\n",
      "q https://www.linkedin.com/in/jampala-venkatasai-314954218 e Hyderabad\n",
      "\n",
      "SUMMARY EDUCATION\n",
      "\n",
      "Highly skilled and experienced Backend Developer specializing in Golang, with a proven B.Tech\n",
      "track record of designing, building, and maintaining robust server-side applications.\n",
      "Proficient in database management, containerization, and API development. Adept at\n",
      " Jayamukhi institute of technology and\n",
      " sciences\n",
      "collaborating with cross-functional teams to deliver efficient and scalable solutions\n",
      " 05/2019 - 06/2022\n",
      "\n",
      " GPA 8.8&nbsp;/&nbsp;10.0\n",
      "EXPERIENCE\n",
      " Diploma\n",
      "Backend Developer 08/2022\n",
      " Laqshya institute of technological\n",
      "Jukshio Hyd\n",
      " sciences\n",
      "Company Description 05/2016 - 06/2019\n",
      "&bull; Experienced Backend Developer proficient in Golang, PostgresSQL, Docker, Postman,\n",
      " Ubuntu, GCP, and Azure, with a skill set that includes: GPA 9.1&nbsp;/&nbsp;10\n",
      "&bull; Developing and maintaining server-side applications using Golang.\n",
      "&bull; Designing and implementing database schemas with PostgresSQL. SSC\n",
      "&bull; Managing containerization with Docker for deployment and scalability.\n",
      "&bull; Collaborating closely with frontend developers and product owners to define and Zphs\n",
      " implement APIs. 05/2015 - 06/2016\n",
      "&bull; Writing efficient, reliable code capable of handling high data volumes and concurrent\n",
      " requests. GPA 9.0&nbsp;/&nbsp;10.0\n",
      "&bull; Conducting thorough code reviews and offering constructive feedback to enhance code\n",
      " quality.\n",
      "&bull; Beyond technical expertise, I bring strong problem-solving abilities, excellent\n",
      " communication skills, and a collaborative team-oriented approach to my work.\n",
      " PROJECTS\n",
      "\n",
      "Internship 05/2022 - 08/2022 Automatic Side Stand Removal\n",
      " Mechanism\n",
      "SukShi Academy Hyd\n",
      " 01/2021 - 04/2021 warngal\n",
      " Innovative sidestand removal mechanism\n",
      "&bull; ASO project, I utilized Golang to develop efficient SQL database interactions and create\n",
      " for enhanced motorcycle stability and\n",
      " robust APIs, ensuring seamless data management and smooth communication between\n",
      " convenience\n",
      " various system components\n",
      " &bull;\n",
      "\n",
      "\n",
      "ACHIEVEMENTS\n",
      " Prosthetic Leg Using 3D\n",
      " Inspire Award\n",
      " Achieved a National Level Best Project Award for my outstanding project work.\n",
      " Printing\n",
      " Recognized with the prestigious Inspire Award for contributions to the field. Proud 2021 - 03/2022 warangal\n",
      " member of IEEE, actively participating in the global engineering community.\n",
      " Revolutionizing prosthetic limb\n",
      " Dedicated member of SAE, contributing to advancements in the automotives.\n",
      " production with cutting-edge 3D printing\n",
      " technology for personalized, accessible,\n",
      " and efficient solutions\n",
      "SKILLS &bull;\n",
      "\n",
      "Golang\n",
      "\n",
      "\n",
      "GitHub\n",
      "\n",
      "\n",
      "Docker, PostgresSql\n",
      "\n",
      "\n",
      "Database management\n",
      "\n",
      "\n",
      "Python ,Postman\n",
      "\n",
      "\n",
      "Linux, Windows\n"
     ]
    }
   ],
   "source": [
    "rt = eval_df.sample()['resume'].values[0]\n",
    "print(rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# eval_prompt = f'''\n",
    "# You are a helpful language model working for a job platform. You will be given the raw \n",
    "#  unstructured text of a user's resume, and the task is to extract the work experience of the \n",
    "#  user from the raw text in the following format: \\n{{work_format}}\\n\n",
    "\n",
    "#  This is the resume text:\\n{{resume_text}}\\n\n",
    "#  This is the output in the required format:\\n\n",
    "# '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# work_format = '''{\n",
    "#     'work_experience': [{'company': 'company Name 1',\n",
    "#                          'role': 'job designation 1',\n",
    "#                          'start_date': 'mm/yyyy',\n",
    "#                          'end_date': 'mm/yyyy',\n",
    "#                          'description': 'complete Job description taken from resume'},\n",
    "#                         {'company': 'company name 2',\n",
    "#                          'role': 'job designation 2',\n",
    "#                          'start_date': mm/yyyy',\n",
    "#                          'end_date': 'mm/yyyy',\n",
    "#                          'description': 'complete Job description taken from resume'}]\n",
    "# }'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from string import Template\n",
    "edu_eval_prompt = Template('''\n",
    "You are a helpful language model working for a job platform. You will be given the raw \n",
    " unstructured text of a user's resume, and the task is to extract the \n",
    " educational details (undergraduate/postgraduate degrees, name of programs, certifications) of the \n",
    " user from the raw text in the following format: \\n ${edu_format}\\n\n",
    " If the information for a certain field is not available, return 'NA'\n",
    " This is the resume text:\\n${resume_text}\\n\n",
    " This is the output in the required_format:\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "edu_format = '''[\n",
    "    {\n",
    "        \"institution\": \"put name of educational institution here\"\n",
    "        \"program\" : \"name of degree/certification/diploma as given in the resume\"\n",
    "        \"start_date\" : \"start date in dd/mm/yyyy format\"\n",
    "        \"end_date\" : \"end date in dd/mm/yyyy format\"\n",
    "        \n",
    "    },\n",
    "    {\n",
    "        \"institution\": \"put name of educational institution here\"\n",
    "        \"program\" : \"name of degree/certification/diploma as given in the resume\"\n",
    "        \"start_date\" : \"start date in dd/mm/yyyy format\"\n",
    "        \"end_date\" : \"end date in dd/mm/yyyy format\"\n",
    "        \n",
    "    }\n",
    "]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# eval_prompt = edu_prompt.substitute(\n",
    "#         edu_format=edu_format,\n",
    "#         resume_text=rt\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "eval_prompt = edu_eval_prompt.substitute(\n",
    "            edu_format=edu_format,\n",
    "            resume_text=rt)\n",
    "\n",
    "sample_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1144"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_input['input_ids'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/infoedge/llama-recipes/env/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    full_document = tokenizer.decode(model.generate(**sample_input, max_new_tokens=1000)[0], skip_special_tokens=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are a helpful language model working for a job platform. You will be given the raw \n",
      " unstructured text of a user's resume, and the task is to extract the \n",
      " educational details (undergraduate/postgraduate degrees, name of programs, certifications) of the \n",
      " user from the raw text in the following format: \n",
      " [\n",
      "    {\n",
      "        \"institution\": \"put name of educational institution here\"\n",
      "        \"program\" : \"name of degree/certification/diploma as given in the resume\"\n",
      "        \"start_date\" : \"start date in dd/mm/yyyy format\"\n",
      "        \"end_date\" : \"end date in dd/mm/yyyy format\"\n",
      "        \n",
      "    },\n",
      "    {\n",
      "        \"institution\": \"put name of educational institution here\"\n",
      "        \"program\" : \"name of degree/certification/diploma as given in the resume\"\n",
      "        \"start_date\" : \"start date in dd/mm/yyyy format\"\n",
      "        \"end_date\" : \"end date in dd/mm/yyyy format\"\n",
      "        \n",
      "    }\n",
      "]\n",
      "\n",
      " If the information for a certain field is not available, return 'NA'\n",
      " This is the resume text:\n",
      "JAMPALA VENKATASAI\n",
      "Backend Developer\n",
      "E 9666704364 jampalavenkatasai99@gmail.com\n",
      "q https://www.linkedin.com/in/jampala-venkatasai-314954218 e Hyderabad\n",
      "\n",
      "SUMMARY EDUCATION\n",
      "\n",
      "Highly skilled and experienced Backend Developer specializing in Golang, with a proven B.Tech\n",
      "track record of designing, building, and maintaining robust server-side applications.\n",
      "Proficient in database management, containerization, and API development. Adept at\n",
      " Jayamukhi institute of technology and\n",
      " sciences\n",
      "collaborating with cross-functional teams to deliver efficient and scalable solutions\n",
      " 05/2019 - 06/2022\n",
      "\n",
      " GPA 8.8&nbsp;/&nbsp;10.0\n",
      "EXPERIENCE\n",
      " Diploma\n",
      "Backend Developer 08/2022\n",
      " Laqshya institute of technological\n",
      "Jukshio Hyd\n",
      " sciences\n",
      "Company Description 05/2016 - 06/2019\n",
      "&bull; Experienced Backend Developer proficient in Golang, PostgresSQL, Docker, Postman,\n",
      " Ubuntu, GCP, and Azure, with a skill set that includes: GPA 9.1&nbsp;/&nbsp;10\n",
      "&bull; Developing and maintaining server-side applications using Golang.\n",
      "&bull; Designing and implementing database schemas with PostgresSQL. SSC\n",
      "&bull; Managing containerization with Docker for deployment and scalability.\n",
      "&bull; Collaborating closely with frontend developers and product owners to define and Zphs\n",
      " implement APIs. 05/2015 - 06/2016\n",
      "&bull; Writing efficient, reliable code capable of handling high data volumes and concurrent\n",
      " requests. GPA 9.0&nbsp;/&nbsp;10.0\n",
      "&bull; Conducting thorough code reviews and offering constructive feedback to enhance code\n",
      " quality.\n",
      "&bull; Beyond technical expertise, I bring strong problem-solving abilities, excellent\n",
      " communication skills, and a collaborative team-oriented approach to my work.\n",
      " PROJECTS\n",
      "\n",
      "Internship 05/2022 - 08/2022 Automatic Side Stand Removal\n",
      " Mechanism\n",
      "SukShi Academy Hyd\n",
      " 01/2021 - 04/2021 warngal\n",
      " Innovative sidestand removal mechanism\n",
      "&bull; ASO project, I utilized Golang to develop efficient SQL database interactions and create\n",
      " for enhanced motorcycle stability and\n",
      " robust APIs, ensuring seamless data management and smooth communication between\n",
      " convenience\n",
      " various system components\n",
      " &bull;\n",
      "\n",
      "\n",
      "ACHIEVEMENTS\n",
      " Prosthetic Leg Using 3D\n",
      " Inspire Award\n",
      " Achieved a National Level Best Project Award for my outstanding project work.\n",
      " Printing\n",
      " Recognized with the prestigious Inspire Award for contributions to the field. Proud 2021 - 03/2022 warangal\n",
      " member of IEEE, actively participating in the global engineering community.\n",
      " Revolutionizing prosthetic limb\n",
      " Dedicated member of SAE, contributing to advancements in the automotives.\n",
      " production with cutting-edge 3D printing\n",
      " technology for personalized, accessible,\n",
      " and efficient solutions\n",
      "SKILLS &bull;\n",
      "\n",
      "Golang\n",
      "\n",
      "\n",
      "GitHub\n",
      "\n",
      "\n",
      "Docker, PostgresSql\n",
      "\n",
      "\n",
      "Database management\n",
      "\n",
      "\n",
      "Python ,Postman\n",
      "\n",
      "\n",
      "Linux, Windows\n",
      "\n",
      " This is the output in the required_format:\n",
      "$[{'institution': 'Jayamukhi institute of technology and sciences', 'program': 'B.Tech', 'start_date': '05/2019', 'end_date': '06/2022'}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(full_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken :10.088245153427124\n"
     ]
    }
   ],
   "source": [
    "out_str = full_document.replace(eval_prompt,\"\")\n",
    "print(f'Time taken :{time.time()-start_time}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Personal Information Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from string import Template\n",
    "pi_eval_prompt = Template('''You are a helpful language model working for a job platform. You will be given the raw \n",
    " unstructured text of a user's resume, and the task is to extract the personal information (name, phone number, email ID and the location) of the \n",
    " user from the raw text in the following format: \\n${pi_format}\\n\n",
    " If the information is not available, return 'NA'\n",
    " This is the resume text:\\n${resume_text}\\n\n",
    " This is the output in the required_format:\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pi_format = '''{\n",
    "    'personal_information': {'name': \"Name\",\n",
    "                         'email_id': \"Valid Email ID\",\n",
    "                         'phone_number': \"10 Digit phone number\",\n",
    "                         'location': \"User's current location\"}\n",
    "}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Darshana Patil\n",
      "System Engineer\n",
      "I have an experience of 4 years in Infosys designated currently as System Engineer which carries the Tag\n",
      "as CTFL-PT Certied || AWS certied || 3 * Azure certied || Certied in IOT professional || Full stack\n",
      "infrastructure professional || Public Cloud Professional\n",
      "\n",
      "\n",
      "\n",
      " darshanapatil0123@gmail.com 9049695920 Virar, India linkedin.com/in/darshana-patil-3a4665188\n",
      "\n",
      "\n",
      "\n",
      "WORK EXPERIENCE SKILLS\n",
      "System Engineer Apache Jmeter App Dynamic LRE Splunk\n",
      "Infosys\n",
      "09/2019 - Present, Oracle AWR Oracle SQL Developer Tectia\n",
      "Currently involved in testing for a corporate banking platform for one of\n",
      "America's leading banks.Also worked as Network Engineer and AWS EC2 IBM MQ AWS Lambda MongoDB\n",
      "Engineer as well.\n",
      "Achievements/Tasks Microfocus performance Center AWS S3 IAM\n",
      " Insta Award - Awarded for the upskilling journey and\n",
      " completed 5 certicates in a Quarter VPC\n",
      " Rise Insta award - Grasped the new proccess and lowered the\n",
      " total volume to 14% of huge volume as well talking care of\n",
      " green dl emails\n",
      " RESPONSIBILITIES\n",
      " Quality Assurance\n",
      "EDUCATION Involved in Performance Testing, includes testing application for volumes\n",
      " and loads which can trigger failures and analyzing throughput, response\n",
      " timings, and susceptible to failure queries. Interacted with client to\n",
      "Bachelors of Science in Information determine their requirements and expectations. Coordinated with TEM\n",
      "Technology and DEV teams to resolve the issue related to DB Cleanup, mq cleanup ,\n",
      " schema analysis. Creating EOD and AWR, ASH reports, gathering stats\n",
      "Mumbai University performing validation on database and tectia then performing the sanity\n",
      "08/2016 - 05/2019, 8.43 test.\n",
      "\n",
      " AWS Engineer\n",
      "Higher Secondary School Certicate Create S3 buckets and also managing policies for S3 bucket. Creating\n",
      "New English School and jr College and managing DNS records on Amazon route S3. Manage Amazon Web\n",
      "06/2014 - 02/2016, 70% Services - ELB, EC2, S3, ROUTE53, RDS, CloudWatch, and VPC.\n",
      "\n",
      " System Engineer\n",
      " Worked as Cloud network infrastructure professional with Lumen\n",
      " technology, Century link.\n",
      "\n",
      "\n",
      "\n",
      " LANGUAGES\n",
      " English Marathi\n",
      " Full Professional Prociency Full Professional Prociency\n",
      "\n",
      " Hindi\n",
      " Full Professional Prociency\n",
      "\n",
      "\n",
      "\n",
      " CERTIFICATES\n",
      "\n",
      " ISTQB CERTIFIED Aws solution architect\n",
      "\n",
      " Az900 Az104, Az700 AWS IOT\n",
      "\n",
      " Cloud Practitioner\n",
      "\n",
      " ITIL Infosys Certied Java SE8 Developer\n",
      "\n",
      " Infosys Global Agile Developer Certication\n",
      "\n",
      " Infosys Certied AppDynamics Associate\n",
      "\n",
      " SPEL100 Software Performance Engineering\n"
     ]
    }
   ],
   "source": [
    "rt = eval_df.sample()['resume'].values[0]\n",
    "print(rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "eval_prompt = pi_eval_prompt.substitute(\n",
    "            pi_format=pi_format,\n",
    "            resume_text=rt)\n",
    "\n",
    "sample_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    full_document = tokenizer.decode(model.generate(**sample_input, max_new_tokens=200)[0], skip_special_tokens=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful language model working for a job platform. You will be given the raw \n",
      " unstructured text of a user's resume, and the task is to extract the personal information (name, phone number, email ID and the location) of the \n",
      " user from the raw text in the following format: \n",
      "{\n",
      "    'personal_information': {'name': \"Name\",\n",
      "                         'email_id': \"Valid Email ID\",\n",
      "                         'phone_number': \"10 Digit phone number\",\n",
      "                         'location': \"User's current location\"}\n",
      "}\n",
      "\n",
      " If the information is not available, return 'NA'\n",
      " This is the resume text:\n",
      "Darshana Patil\n",
      "System Engineer\n",
      "I have an experience of 4 years in Infosys designated currently as System Engineer which carries the Tag\n",
      "as CTFL-PT Certied || AWS certied || 3 * Azure certied || Certied in IOT professional || Full stack\n",
      "infrastructure professional || Public Cloud Professional\n",
      "\n",
      "\n",
      "\n",
      " darshanapatil0123@gmail.com 9049695920 Virar, India linkedin.com/in/darshana-patil-3a4665188\n",
      "\n",
      "\n",
      "\n",
      "WORK EXPERIENCE SKILLS\n",
      "System Engineer Apache Jmeter App Dynamic LRE Splunk\n",
      "Infosys\n",
      "09/2019 - Present, Oracle AWR Oracle SQL Developer Tectia\n",
      "Currently involved in testing for a corporate banking platform for one of\n",
      "America's leading banks.Also worked as Network Engineer and AWS EC2 IBM MQ AWS Lambda MongoDB\n",
      "Engineer as well.\n",
      "Achievements/Tasks Microfocus performance Center AWS S3 IAM\n",
      " Insta Award - Awarded for the upskilling journey and\n",
      " completed 5 certicates in a Quarter VPC\n",
      " Rise Insta award - Grasped the new proccess and lowered the\n",
      " total volume to 14% of huge volume as well talking care of\n",
      " green dl emails\n",
      " RESPONSIBILITIES\n",
      " Quality Assurance\n",
      "EDUCATION Involved in Performance Testing, includes testing application for volumes\n",
      " and loads which can trigger failures and analyzing throughput, response\n",
      " timings, and susceptible to failure queries. Interacted with client to\n",
      "Bachelors of Science in Information determine their requirements and expectations. Coordinated with TEM\n",
      "Technology and DEV teams to resolve the issue related to DB Cleanup, mq cleanup ,\n",
      " schema analysis. Creating EOD and AWR, ASH reports, gathering stats\n",
      "Mumbai University performing validation on database and tectia then performing the sanity\n",
      "08/2016 - 05/2019, 8.43 test.\n",
      "\n",
      " AWS Engineer\n",
      "Higher Secondary School Certicate Create S3 buckets and also managing policies for S3 bucket. Creating\n",
      "New English School and jr College and managing DNS records on Amazon route S3. Manage Amazon Web\n",
      "06/2014 - 02/2016, 70% Services - ELB, EC2, S3, ROUTE53, RDS, CloudWatch, and VPC.\n",
      "\n",
      " System Engineer\n",
      " Worked as Cloud network infrastructure professional with Lumen\n",
      " technology, Century link.\n",
      "\n",
      "\n",
      "\n",
      " LANGUAGES\n",
      " English Marathi\n",
      " Full Professional Prociency Full Professional Prociency\n",
      "\n",
      " Hindi\n",
      " Full Professional Prociency\n",
      "\n",
      "\n",
      "\n",
      " CERTIFICATES\n",
      "\n",
      " ISTQB CERTIFIED Aws solution architect\n",
      "\n",
      " Az900 Az104, Az700 AWS IOT\n",
      "\n",
      " Cloud Practitioner\n",
      "\n",
      " ITIL Infosys Certied Java SE8 Developer\n",
      "\n",
      " Infosys Global Agile Developer Certication\n",
      "\n",
      " Infosys Certied AppDynamics Associate\n",
      "\n",
      " SPEL100 Software Performance Engineering\n",
      "\n",
      " This is the output in the required_format:\n",
      "{'name': 'Darshana Patil', 'location': 'Virar, India', 'email': 'darshanapatil0123@gmail.com', 'phone': '9049695920'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(full_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3c3902aec854d6cbb28ce11f68205b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/lakshay/llama2-test/commit/2b0cc408d9fc73d2220bf356e47d7501c4c86743', commit_message='Upload model', commit_description='', oid='2b0cc408d9fc73d2220bf356e47d7501c4c86743', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub('lakshay/llama2-test',token='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PI validation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_data = pd.read_csv('custom_data/validation_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>designation</th>\n",
       "      <th>keywords</th>\n",
       "      <th>user_experience</th>\n",
       "      <th>resume</th>\n",
       "      <th>name</th>\n",
       "      <th>email</th>\n",
       "      <th>phone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>2748218</td>\n",
       "      <td>Data engineering consultant</td>\n",
       "      <td>['Oracle', 'SQL', 'SQL Queries', 'Reconciliati...</td>\n",
       "      <td>8</td>\n",
       "      <td>Ajith Akarapu HyderabadTelangana\\n\\n +91 91778...</td>\n",
       "      <td>Ajith Akarapu</td>\n",
       "      <td>ajith.db18@gmail.com</td>\n",
       "      <td>9.177842e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                  designation  \\\n",
       "363  2748218  Data engineering consultant   \n",
       "\n",
       "                                              keywords  user_experience  \\\n",
       "363  ['Oracle', 'SQL', 'SQL Queries', 'Reconciliati...                8   \n",
       "\n",
       "                                                resume           name  \\\n",
       "363  Ajith Akarapu HyderabadTelangana\\n\\n +91 91778...  Ajith Akarapu   \n",
       "\n",
       "                    email         phone  \n",
       "363  ajith.db18@gmail.com  9.177842e+09  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' RAJANI\\n KANTA\\n ROUTH\\n GET IN CONTACT\\n\\n rajnikantrouth93042@gmail.com\\n Phone number: 6297814393\\n Diesel Colony ,Siliguri Junction\\n\\n\\n\\nCARRIER OBJECTIVE\\n PROJECTS\\n\\n &ldquo;To work in an organisation\\n Audio player - A simple functional featured audio player web application\\n which provides me with ample\\n implemented with html ,css and javascript. You play all device stored songs\\n opportunities to enhance my\\n with ease.\\n skills and knowledge along with\\n contributing to the growth of\\n Garage on internet wheels - Garage on internet wheels is an eventual online\\n the organisation.&rdquo;\\n platform that allows users to order garage mechanic online from an ample\\n range of option near their local region. To solve their car or any vehicle issues\\n with ease. I create this project using html, css and javascript.\\nAREAS OF EXPERTISE\\n Advocate appointment website - A simple website where users check the\\n Advocate profile and surety that the advocate which hire for their legal issues\\n C++ , C and Java ,Python, C# is suitable or not for them and Advocate fee also. I create this project using\\n Data Structure and Algorithm html, css and javascript.\\n Html, Css ,Javascript,React.js\\n Database : DBMS\\n Database Language : SQL\\n Quality Analyst\\n Networking,Operating System\\n\\n EDUCATION HISTORY\\n\\n OTHER SKILLS B.TECH IN INFORMATION TECHNOLOGY, 2021\\n SILIGURI INSTITUTE OF TECHNOLOGY\\n\\n 12TH FROM BHARATI HINDI VIDYALAYA (H.S), 2016\\n The ability to analyze complex\\n and technical information 10TH FROM BHARATI HINDI VIDYALAYA (H S), 2014\\n Detailed Oriented\\n Excellent problem solver\\n Modifies code to fix errors'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data.resume.values[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c0045a417194cd5969086fba78e0771",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feck\n",
      "feck\n",
      "feck\n",
      "feck\n",
      "feck\n",
      "feck\n",
      "feck\n",
      "feck\n",
      "feck\n",
      "feck\n",
      "feck\n",
      "feck\n",
      "feck\n",
      "feck\n",
      "feck\n",
      "feck\n",
      "feck\n",
      "feck\n",
      "feck\n",
      "feck\n",
      "feck\n",
      "feck\n",
      "feck\n",
      "feck\n",
      "feck\n",
      "feck\n",
      "feck\n",
      "feck\n",
      "feck\n",
      "feck\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "error_list = list()\n",
    "correct_list = list()\n",
    "\n",
    "for uid,rt in tqdm(validation_data[['id','resume']].sample(frac=1).values[:200]):\n",
    "\n",
    "    eval_prompt = pi_eval_prompt.substitute(\n",
    "                pi_format=pi_format,\n",
    "                resume_text=rt)\n",
    "\n",
    "    sample_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    try:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            full_document = tokenizer.decode(model.generate(**sample_input, max_new_tokens=200)[0], skip_special_tokens=True)\n",
    "    except:\n",
    "        print('feck')\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        out_str = full_document.replace(eval_prompt,'').replace('$','')\n",
    "        out_json = ast.literal_eval(out_str)\n",
    "        u_info = {}\n",
    "        u_info[uid] = out_json\n",
    "        correct_list.append(u_info)\n",
    "    except:\n",
    "        error_list.append(full_document)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# correct_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello  , yes'"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'hello there, $, yes'.replace('there,','').replace('$','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(correct_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct_list\n",
    "\n",
    "with open('custom_data/validation_output.pkl','wb') as f:\n",
    "    pickle.dump(correct_list,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "2d58e898dde0263bc564c6968b04150abacfd33eed9b19aaa8e45c040360e146"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
