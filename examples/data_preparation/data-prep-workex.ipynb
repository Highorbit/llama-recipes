{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df4de648-5266-4812-b886-f3369fbfa86b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from datasets import Dataset\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bce07c6d-fae6-4d63-828d-bec1e78e438e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "import sys\n",
    "sys.path.append('/home/ec2-user/SageMaker/llama_root/src')\n",
    "sys.path.append('../llama-recipes/src/llama_recipes/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8291ada-d832-4da8-a606-784fe3966079",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/ubuntu/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login(token='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcf8fbe9-cfde-4e07-afdc-358385113136",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import LlamaForCausalLM, LlamaTokenizer\n",
    "\n",
    "model_id=\"meta-llama/Llama-2-7b-chat-hf\"\n",
    "\n",
    "tokenizer = LlamaTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39f90510-1c51-48cf-ab0b-07be150dafd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d = pd.read_csv('../custom_data/gpt4_parsed_resumes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e36acaa4-f7e4-47e0-a464-f6c200325b3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# d['work_experience'].sample(1).values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91b43a8-0579-4c95-8df9-f43c1db45fc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9605db0-b6c9-4668-bc6f-9e2cd295f4b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560d0cfd-4389-4285-aab4-12e51f896e48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70a82b43-c058-4b6a-85f5-232a9c156778",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../custom_data/latest_work_exp_28dec.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b07bca94-2591-4224-ae4f-fd406d22c6e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.columns = ['id', 'designation', 'keywords', 'user_experience', 'resume','work_experience']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2992d2ab-9985-4b0d-b4b5-caaaf853ecdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbfe4e61-21dc-4537-b67b-6457d1907b7e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'company': 'HCL Technologies',\n",
       "  'role': 'Associate Consultant',\n",
       "  'start_date': 'Nov 2021',\n",
       "  'end_date': 'Present',\n",
       "  'description': 'Installation, configuration and maintenance of servers. Provision New server AWS, Azure and On-prem. Planning and execution of patching. Create file systems and Extending size as per the requirement. Handling Linux Level 2 tickets using Helix Tool. Controlling access to files and Folder with the Permissions. Installation of and upgrading software packages using YUM and RPM. Interact with customers to gather user requirements relevant to deployment and integration, Architecture Implementation. Tuning up of systems/components in case of performance issues. Creating Document. Attending CRC meeting and represent all CRQ from Unix Team. Perform server patching every month. Knowledge On Various DevOps Tools and Technologies (Git, Ansible, Docker and Container). Create support case with Red Hat. Add EBS Volume and extend file system as per requirement. Change Instance type as per requirement. Create snapshot of AWS and Azure servers. Restore from snapshot. Monitor Health check from AWS and Azure Console. Create support case with AWS and Microsoft Azure. Create new server with Image. Create Golden Image patching for AWS, Azure and On-prem. Check backup failed issue on Azure servers. Check server status from AWS/Azure console management. Used to write script whenever required to optimize my task.'},\n",
       " {'company': 'Megthink Solutions',\n",
       "  'role': 'OS Admin',\n",
       "  'start_date': 'Sep 2020',\n",
       "  'end_date': 'Nov 2021',\n",
       "  'description': 'Installation, configuration and maintenance of servers. VMware Management for virtualization. VCS Management. Planning and execution of patching and VCS cluster switching of machines. Restore/Refresh of servers/VGs using NetBackup and/or ISM. Create file systems and Extending size as per the requirement. Monitor system performance using HPOVO and OM Monitoring Tools. Managing User and Groups in Linux. Installation of and upgrading software packages using YUM and RPM. Scheduling Future Linux task Using CRON. Basic troubleshooting of DB level issues (Oracle / MySql). Installation and management of MySQL for a couple of in-house application. Interact with customers to gather user requirements relevant to deployment and integration, Architecture Implementation. Analyzing the integration/deployment Requirements and underling business logic/purpose. Document and review processes to help in the smooth roll out of a release in production. Installation, customization and Administration of purchased Software products e.g Modeln, Peoplesoft ,Sharepoint Server, Remedy, E2open, tuxedo, IWS etc. Maintenance of Application servers (Weblogic/Jboss/Tomcat) on distributed clusters. Application components deployment in Production, Quality Assurance and Test Environments. Scheduling and managing scripts using IBM Tivoli Workload Scheduler (Maestro). Installation and management of Hermes and a couple of in-house application. Installation and configuration of Commvault tools. Wrote simple and complex shell(bash) script for automation the repeated task.'},\n",
       " {'company': 'ST Microelectronics',\n",
       "  'role': 'System Engineer',\n",
       "  'start_date': 'Jul 2016',\n",
       "  'end_date': 'Sep 2020',\n",
       "  'description': 'No job description provided'},\n",
       " {'company': 'SI Microelectronics',\n",
       "  'role': 'Automation and Backup Operation',\n",
       "  'start_date': 'Jul 2015',\n",
       "  'end_date': 'Jun 2016',\n",
       "  'description': 'Checking the status of all the Admin schedules on daily basis and if necessary manually executing those commands (ex. Backing up client data, backing up primary, tape and copy storage pools, Database Backup, Expiration, DB utilization, Log utilization, Reclamation & Migration ). Working on bad tapes such as auditing volumes, fixing errors, restoring volumes, deleting volumes if necessary. Constantly monitoring Storage Libraries for Drive issues, scratch volume counts, tape mount issues, tape volume errors to ensure the integrity of the backup environment. Installing and configuring new TSM client nodes for automatic scheduled backups. Handling Incidents of Troubleshooting of Missed/Failed backups which includes OS level and Network related issues across all Platforms. Handling restores of windows/Unix servers as per client requests.'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_str = df['work_experience'].sample(1).values[0]\n",
    "job_obj = ast.literal_eval(json_str)\n",
    "job_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e87641a2-9248-44cf-8163-443e2b20bec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11c4ebe9cbce40999bc09e368c64dad5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/365 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wex = []\n",
    "for work_string in tqdm(df['work_experience'].values):\n",
    "    work_json = ast.literal_eval(work_string)\n",
    "    \n",
    "    for work_ex in work_json:\n",
    "        work_ex.pop('description', None)\n",
    "    wex.append(work_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ecb7c51-5926-4235-99c9-43ac1d030ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['work_data'] = wex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59335d34-039a-4706-9753-b8fe14f1f48e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Work Experience Training Data\n",
    "We try and define a decent text prompt here for the base untrained model to understand the general task of extracting work experience from a resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d0ce362-a960-4740-b5f2-a69d0015380b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3bfdf1c9-78a0-445a-8599-400c3b55e3a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "work_prompt = f'''\n",
    "You are an accurate agent working for a job platform. You will be given the raw \n",
    "unstructured text of a user's resume, and the task is to extract the entire work experience of the \n",
    "user from the resume. Please provide the data in a concise JSON format. The JSON should include a \n",
    "\"work_experience\" key with an array of objects. Each object represents a job and should contain keys for \n",
    "\"company\", \"role\", \"start_date\", \"end_date\", and \"description\". Dates should be in \"mm/yyyy\" format. \n",
    "Ensure the JSON syntax is correct, with proper use of quotes, commas, and braces. Here is an example structure::\n",
    "\n",
    "Please follow this structure closely and keep the response within the token limit.\" \\n{{query_format}}\\n\n",
    "\n",
    "This is the resume text:\\n{{resume_text}}\\n\n",
    "This is the output in the required_format:\\n{{output}}\\n{{eos_token}}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c6ab1b-4a91-4399-a81b-5e20efe058f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6173f9b3-f0f3-4e4b-ab88-80e70612b0d4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Output Format \n",
    "We're telling the model how to format the output and give us a repsonse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d01f1a2-f7ce-4513-9a93-304fff0595cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "work_format = '''\n",
    "[\n",
    "    {\"company\":\"Example Company 1\",\n",
    "    \"role\":\"Example Role 1\",\n",
    "    \"start_date\":\"mm/yyyy\",\n",
    "    \"end_date\":\"mm/yyyy\",\n",
    "    \"description\":\"Example Description 1\"},\n",
    "    {\"company\":\"Example Company 2\",\n",
    "    \"role\":\"Example Role 2\",\"\n",
    "    start_date\":\"mm/yyyy\",\n",
    "    \"end_date\":\"mm/yyyy\",\n",
    "    \"description\":\"Example Description 2\"}\n",
    "]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d4ab092-8db8-4ec0-8c0b-3e19e80dabfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "work_df = df[['resume','work_experience']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e443bf8-b7e3-45ba-88ed-9722d69a8327",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resume</th>\n",
       "      <th>work_experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>Kevin Patel [Quality Analyst]\\n kevinpatel8832...</td>\n",
       "      <td>[{'company': 'Tech Mahindra', 'role': 'Quality...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>Bushra Khan Professional Experience\\n\\n Senior...</td>\n",
       "      <td>[{'company': 'Paytm', 'role': 'Senior Software...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>+91 7709938677 Vineet Kolate\\n Java Developer...</td>\n",
       "      <td>[{'company': 'Broadridge Trading and Connectiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>ALOK CHAUDHARY\\nLaxmi Vihar, Burari, Delhi - 1...</td>\n",
       "      <td>[{'company': 'Indian Computer Emergency Respon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>SANGEETHA S XAMARIN FORMS &amp;amp; .NET DEVELOPE...</td>\n",
       "      <td>[{'company': 'Ouris Health Pvt. Ltd.', 'role':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>AQSA KHAN\\n +91 9811998472\\n Aqsa1221@gmail.c...</td>\n",
       "      <td>[{'company': 'JLL India Pvt Ltd', 'role': 'Sub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>TEAM LEAD\\n\\n Noida, Uttar Pradesh - 201318, ...</td>\n",
       "      <td>[{'company': 'Qualitest', 'role': 'Team Lead',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>suneethaworkday15@gmail.com\\n Mobile:99645486...</td>\n",
       "      <td>[{'company': 'Forcepoint', 'role': 'Workday Te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>ayushsj17@gmail.com\\n\\nAYUSH KUMAR SONE +91 8...</td>\n",
       "      <td>[{'company': 'Envision Enterprises Solution Pv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>Sumit Dasharath Phadake\\n Career Objective: T...</td>\n",
       "      <td>[{'company': 'Icon Facility Service Company', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>365 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                resume  \\\n",
       "241  Kevin Patel [Quality Analyst]\\n kevinpatel8832...   \n",
       "260  Bushra Khan Professional Experience\\n\\n Senior...   \n",
       "191   +91 7709938677 Vineet Kolate\\n Java Developer...   \n",
       "177  ALOK CHAUDHARY\\nLaxmi Vihar, Burari, Delhi - 1...   \n",
       "233   SANGEETHA S XAMARIN FORMS &amp; .NET DEVELOPE...   \n",
       "..                                                 ...   \n",
       "237   AQSA KHAN\\n +91 9811998472\\n Aqsa1221@gmail.c...   \n",
       "226   TEAM LEAD\\n\\n Noida, Uttar Pradesh - 201318, ...   \n",
       "127   suneethaworkday15@gmail.com\\n Mobile:99645486...   \n",
       "239   ayushsj17@gmail.com\\n\\nAYUSH KUMAR SONE +91 8...   \n",
       "339   Sumit Dasharath Phadake\\n Career Objective: T...   \n",
       "\n",
       "                                       work_experience  \n",
       "241  [{'company': 'Tech Mahindra', 'role': 'Quality...  \n",
       "260  [{'company': 'Paytm', 'role': 'Senior Software...  \n",
       "191  [{'company': 'Broadridge Trading and Connectiv...  \n",
       "177  [{'company': 'Indian Computer Emergency Respon...  \n",
       "233  [{'company': 'Ouris Health Pvt. Ltd.', 'role':...  \n",
       "..                                                 ...  \n",
       "237  [{'company': 'JLL India Pvt Ltd', 'role': 'Sub...  \n",
       "226  [{'company': 'Qualitest', 'role': 'Team Lead',...  \n",
       "127  [{'company': 'Forcepoint', 'role': 'Workday Te...  \n",
       "239  [{'company': 'Envision Enterprises Solution Pv...  \n",
       "339  [{'company': 'Icon Facility Service Company', ...  \n",
       "\n",
       "[365 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "work_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d421fa5e-b3ab-45fb-9657-79f237afd5ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "work_df.columns = ['resume','output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d79c7946-6496-4cdf-ba24-7dd3d9f2cc30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10441/1997307274.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  work_df['format'] = work_format\n",
      "/tmp/ipykernel_10441/1997307274.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  work_df['prompt'] = work_prompt\n"
     ]
    }
   ],
   "source": [
    "work_df['format'] = work_format\n",
    "work_df['prompt'] = work_prompt\n",
    "work_data = Dataset.from_pandas(work_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59420ff2-853a-45da-80b9-9822c8a0e780",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2232e1a-a2a8-4a8e-8bae-05119ea85336",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_recipes.utils.dataset_utils import get_preprocessed_dataset\n",
    "from llama_recipes.datasets.utils import Concatenator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6a4976-b464-40b4-938c-1d9d106e759c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d186af96-d722-4bf9-ab31-88e90f80da6e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['resume', 'output', 'format', 'prompt', '__index_level_0__'],\n",
       "    num_rows: 365\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "work_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f724dc89-579a-4725-84b9-f858e5230553",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[\n",
      "    {\"company\":\"Example Company 1\",\n",
      "    \"role\":\"Example Role 1\",\n",
      "    \"start_date\":\"mm/yyyy\",\n",
      "    \"end_date\":\"mm/yyyy\",\n",
      "    \"description\":\"Example Description 1\"},\n",
      "    {\"company\":\"Example Company 2\",\n",
      "    \"role\":\"Example Role 2\",\"\n",
      "    start_date\":\"mm/yyyy\",\n",
      "    \"end_date\":\"mm/yyyy\",\n",
      "    \"description\":\"Example Description 2\"}\n",
      "]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(work_data[4]['format'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca13d7e-f76e-4af7-a1e5-329cde4f3d45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d226e7c9-d38a-4334-948e-8e07f927902e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are an accurate agent working for a job platform. You will be given the raw \n",
      "unstructured text of a user's resume, and the task is to extract the entire work experience of the \n",
      "user from the resume. Please provide the data in a concise JSON format. The JSON should include a \n",
      "\"work_experience\" key with an array of objects. Each object represents a job and should contain keys for \n",
      "\"company\", \"role\", \"start_date\", \"end_date\", and \"description\". Dates should be in \"mm/yyyy\" format. \n",
      "Ensure the JSON syntax is correct, with proper use of quotes, commas, and braces. Here is an example structure::\n",
      "\n",
      "Please follow this structure closely and keep the response within the token limit.\" \n",
      "{query_format}\n",
      "\n",
      "\n",
      "This is the resume text:\n",
      "{resume_text}\n",
      "\n",
      "This is the output in the required_format:\n",
      "{output}\n",
      "{eos_token}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(work_data[4]['prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207b948c-174c-49d4-8972-f2a5425c0fd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c5f91ba5-c09e-4375-8863-143512404713",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_list = []\n",
    "for row in work_df.itertuples():\n",
    "    text = row.prompt.format(\n",
    "            query_format=row.format,\n",
    "            resume_text=row.resume,\n",
    "            output=row.output,\n",
    "            eos_token=tokenizer.eos_token)\n",
    "    data_list.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb71fe6-b0a1-4266-9449-f590137860f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86249f3a-b5e8-4d97-b28b-514e40545ff1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c61f28-e89b-4d54-8618-390d711c0599",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0650eae6-572d-4b9d-8342-0b954ce0953f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dl = {\n",
    "    'text': data_list\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5ea18e54-67d8-4f88-be2e-d92aab71d3fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "work_data_hf = Dataset.from_dict(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68853fbd-d5a4-4613-bd4b-ef941356a849",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dc3c31-9600-42fc-a8a7-ff17e089b93a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7d80eae4-4de6-49dc-b1b6-5d4cc51acf18",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1f9abab3d9c464f9c8a54ec083fa294",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/365 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2e3e1cf88d144d78cd9f0951215ce90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/365 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "work_data_hf = work_data_hf.map(\n",
    "    lambda sample: tokenizer(sample[\"text\"]),\n",
    "    batched=True,\n",
    "    remove_columns=list(work_data_hf.features),\n",
    ").map(Concatenator(), batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ee8828-f805-4992-a6d0-052419fcaed0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "737e669e-ce5c-45b9-a907-51387b0425cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 344\n",
       "})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "work_data_hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "acc90de9-56c2-4b9b-97f0-d1fb25787d6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "297ae49101494e589fdd9f6b80efe9b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/344 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "work_data_hf.save_to_disk('../custom_data/llama2/work_details.hf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da3cbef-63c3-4951-98b5-59a5bb827324",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8332f7-d3b4-46aa-b2db-5f445e8aa6e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "faffbbd3-a11f-4f3a-87be-de3026e6e142",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# work_ds.save_to_disk('custom_data/work_data.hf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a84862c8-ed37-4bb2-9811-729382d9d66e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# edu_ds.save_to_disk('custom_data/education_data.hf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5fa3a0ea-4961-4f51-afd2-e9e28011f4be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pi_ds.save_to_disk('custom_data/pi_data.hf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e85d59-dab0-48d2-afdb-b982615aa34b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
