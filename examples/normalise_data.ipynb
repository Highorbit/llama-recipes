{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from datasets import load_from_disk\n",
    "# train_data = load_from_disk(\"custom_data/llama2/work-ex-details.hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Feb  6 17:29:17 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.154.05             Driver Version: 535.154.05   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A10G                    Off | 00000000:00:1E.0 Off |                    0 |\n",
      "|  0%   30C    P0              56W / 300W |      0MiB / 23028MiB |      4%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/ubuntu/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login(token='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Important \n",
    "\n",
    "It is important to consider here which model we're using to parse the resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27923aadcc6446a495d024e7b16f9efe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer\n",
    "\n",
    "model_id=\"meta-llama/Llama-2-7b-chat-hf\"\n",
    "\n",
    "tokenizer = LlamaTokenizer.from_pretrained(model_id)\n",
    "\n",
    "model = LlamaForCausalLM.from_pretrained(model_id, load_in_8bit=True, device_map='auto', torch_dtype=torch.float16, token='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.append('/home/ec2-user/SageMaker/llama_root/src')\n",
    "sys.path.append('../llama-recipes/src/llama_recipes/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Check base model\n",
    "\n",
    "Run the base model on an example input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# eval_prompt = \"\"\"\n",
    "# Summarize this dialog:\n",
    "# A: Hi Tom, are you busy tomorrow’s afternoon?\n",
    "# B: I’m pretty sure I am. What’s up?\n",
    "# A: Can you go with me to the animal shelter?.\n",
    "# B: What do you want to do?\n",
    "# A: I want to get a puppy for my son.\n",
    "# B: That will make him so happy.\n",
    "# A: Yeah, we’ve discussed it many times. I think he’s ready now.\n",
    "# B: That’s good. Raising a dog is a tough issue. Like having a baby ;-) \n",
    "# A: I'll get him one of those little dogs.\n",
    "# B: One that won't grow up too big;-)\n",
    "# A: And eat too much;-))\n",
    "# B: Do you know which one he would like?\n",
    "# A: Oh, yes, I took him there last Monday. He showed me one that he really liked.\n",
    "# B: I bet you had to drag him away.\n",
    "# A: He wanted to take it home right away ;-).\n",
    "# B: I wonder what he'll name it.\n",
    "# A: He said he’d name it after his dead hamster – Lemmy  - he's  a great Motorhead fan :-)))\n",
    "# ---\n",
    "# Summary:\n",
    "# \"\"\"\n",
    "\n",
    "# model_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     print(tokenizer.decode(model.generate(**model_input, max_new_tokens=100)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_date = 'jul 2016'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_prompt = f\"\"\"\n",
    "[INST]Convert the following dates to mm/yyy format:\n",
    "Input: apr-2017\n",
    "output :  04/2017\n",
    "\n",
    "Input : November 2023 \n",
    "Output :  11/2023\n",
    "\n",
    "Input : {input_date}\n",
    "Output :  \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep2 = f'''\n",
    "Convert this date : apr-2017 to mm/yyyy format\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Convert this date : apr-2017 to mm/yyyy format\n",
      "\n",
      "Answer: 04/2017\n",
      "\n",
      "Explanation:\n",
      "\n",
      "In the mm/yyyy format, the month is represented by two digits, and the year is represented by four digits.\n",
      "\n",
      "So, in the case of \"apr-2017\", we can see that the month is \"apr\" which corresponds to the month of April, and the year is \"2017\".\n",
      "\n",
      "Therefore, the date in mm/yyyy\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_input = tokenizer(ep2, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(tokenizer.decode(model.generate(**model_input, max_new_tokens=100)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "We can see that the base model only repeats the conversation.\n",
    "\n",
    "### Step 4: Prepare model for PEFT\n",
    "\n",
    "Let's prepare the model for Parameter Efficient Fine Tuning (PEFT):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/peft/utils/other.py:141: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 33,554,432 || all params: 6,771,970,048 || trainable%: 0.49548996469513035\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "def create_peft_config(model):\n",
    "    from peft import (\n",
    "        get_peft_model,\n",
    "        LoraConfig,\n",
    "        TaskType,\n",
    "        prepare_model_for_int8_training,\n",
    "    )\n",
    "\n",
    "    peft_config = LoraConfig(\n",
    "        task_type=TaskType.CAUSAL_LM,\n",
    "        inference_mode=False,\n",
    "        r=64,\n",
    "        lora_alpha=32,\n",
    "        lora_dropout=0.05,\n",
    "        target_modules = [\"q_proj\", \"v_proj\"]\n",
    "    )\n",
    "    \n",
    "    # peft_config = LoraConfig(\n",
    "    #     task_type=TaskType.CAUSAL_LM,\n",
    "    #     inference_mode=False,\n",
    "    #     r=8,\n",
    "    #     lora_alpha=32,\n",
    "    #     lora_dropout=0.05,\n",
    "    #     target_modules = [\"q_proj\", \"v_proj\"]\n",
    "    # )\n",
    "\n",
    "    # prepare int-8 model for training\n",
    "    model = prepare_model_for_int8_training(model)\n",
    "    model = get_peft_model(model, peft_config)\n",
    "    model.print_trainable_parameters()\n",
    "    return model, peft_config\n",
    "\n",
    "# create peft config\n",
    "model, lora_config = create_peft_config(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Step 5: Define an optional profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import TrainerCallback\n",
    "from contextlib import nullcontext\n",
    "enable_profiler = False\n",
    "output_dir = \"tmp/llama-output\"\n",
    "\n",
    "config = {\n",
    "    'lora_config': lora_config,\n",
    "    'learning_rate': 1e-4,\n",
    "    'num_train_epochs': 2,\n",
    "    'gradient_accumulation_steps': 2,\n",
    "    'per_device_train_batch_size': 2,\n",
    "    'gradient_checkpointing': False,\n",
    "}\n",
    "\n",
    "# Set up profiler\n",
    "if enable_profiler:\n",
    "    wait, warmup, active, repeat = 1, 1, 2, 1\n",
    "    total_steps = (wait + warmup + active) * (1 + repeat)\n",
    "    schedule =  torch.profiler.schedule(wait=wait, warmup=warmup, active=active, repeat=repeat)\n",
    "    profiler = torch.profiler.profile(\n",
    "        schedule=schedule,\n",
    "        on_trace_ready=torch.profiler.tensorboard_trace_handler(f\"{output_dir}/logs/tensorboard\"),\n",
    "        record_shapes=True,\n",
    "        profile_memory=True,\n",
    "        with_stack=True)\n",
    "    \n",
    "    class ProfilerCallback(TrainerCallback):\n",
    "        def __init__(self, profiler):\n",
    "            self.profiler = profiler\n",
    "            \n",
    "        def on_step_end(self, *args, **kwargs):\n",
    "            self.profiler.step()\n",
    "\n",
    "    profiler_callback = ProfilerCallback(profiler)\n",
    "else:\n",
    "    profiler = nullcontext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jan 18 15:13:37 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.12             Driver Version: 535.104.12   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A10G                    On  | 00000000:00:1E.0 Off |                    0 |\n",
      "|  0%   23C    P0              59W / 300W |   8642MiB / 23028MiB |      3%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A     21812      C   ...r/anaconda3/envs/python3/bin/python     8634MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Fine tune the model\n",
    "\n",
    "Here, we fine tune the model for a single epoch which takes a bit more than an hour on a A100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='115' max='146' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [115/146 26:59 < 07:24, 0.07 it/s, Epoch 1.55/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.193300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.070200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.072200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.983600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.936900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.944400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.819200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.750900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.734000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.743100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>1.831600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.672600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>1.853900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.658700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>1.682000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.588900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>1.668500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.575000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>1.736100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.671800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>1.724100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.767000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import default_data_collator, Trainer, TrainingArguments\n",
    "\n",
    "# Define training args\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "    bf16=True,  # Use BF16 if available\n",
    "    # logging strategies\n",
    "    logging_dir=f\"{output_dir}/logs\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=5,\n",
    "    save_strategy=\"no\",\n",
    "    optim=\"adamw_torch_fused\",\n",
    "    max_steps=total_steps if enable_profiler else -1,\n",
    "    **{k:v for k,v in config.items() if k != 'lora_config'}\n",
    ")\n",
    "\n",
    "with profiler:\n",
    "    # Create Trainer instance\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_data,\n",
    "        data_collator=default_data_collator,\n",
    "        callbacks=[profiler_callback] if enable_profiler else [],\n",
    "    )\n",
    "\n",
    "    # Start training\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 7:\n",
    "Save model checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 8:\n",
    "Try the fine tuned model on the same example again to see the learning progress:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_df = pd.read_csv('custom_data/model_eval_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(161, 5)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head Digital Solutions/Digital Transformation Leader\n",
      "Vijayasree Patnaik\n",
      "Email: vijayasreepatnaik1@gmail.com; Phone: +91 7410569056\n",
      "\n",
      "\n",
      "Career Highlights & Summary\n",
      "\n",
      " Overall 23+ years of experience in Solution Architecture, Presales, Product Management\n",
      " and Engineering delivery management for Enterprise solutions\n",
      " In depth experience in driving Digital transformation journey for Utilities, Oil&Gas and\n",
      " Telecom industries\n",
      " Digital transformation presales, solutioning and Program deliveries (cloud and analytics)\n",
      " Digital transformation presales, solutioning and project deliveries (ServiceNow and\n",
      " Salesforce enterprise platforms)\n",
      " Experience in Managed Services Delivery Platform for global customers (more than 200+\n",
      " customers). Managing global stakeholders\n",
      " Strategic product management experience working with business teams to develop IT\n",
      " strategy for new and existing services and automation opportunities\n",
      " Product lifecycle management experience (product roadmap, strategy, vendor\n",
      " management, delivery management, capacity planning and solution ownership)\n",
      " End-to-End experience in application lifecycle management, working closely with\n",
      " customers doing requirement analysis, use case development, solution architecture and\n",
      " project delivery\n",
      "\n",
      "Technical Skills\n",
      "\n",
      " Digital Transformation solutioning (Cloud, IIOT, analytics, Digital Utilities)\n",
      " Microsoft Azure Platform, GCP\n",
      " Domains – Oil&Gas, Manufacturing, Energy & Utilities, Telecom\n",
      " ServiceNow, Salesforce Platform experience\n",
      " AI & ML, Python\n",
      " Enterprise mobility solutions, Telecom OSS, NFV/SDN, Industry 4.0\n",
      "\n",
      "Professional Summary\n",
      "\n",
      "Current: Cyient Limited Dec’2021 – Till Date\n",
      "Role: Sr Director/Head Digital Aftermarket Services\n",
      "\n",
      "Technical Skills – Salesforce, ServiceNow, Analytics, Cloud Migration, FSM, Energy&Utilities, Python\n",
      "\n",
      " Industry 4.0 solutioning\n",
      " Solutioning and Program Delivery management for customers across Telecom, Utilities and\n",
      " manufacturing for digital services\n",
      " Building Digital Aftermarket Service solutions for customers across domains (Telecom NOC,\n",
      " Energy & Utilities, Manufacturing)\n",
      " Customer engagement and driving the customer satisfaction\n",
      " People Management\n",
      "\n",
      "\n",
      "Current: HCL Technologies Aug’2020 –\n",
      "Dec’2021\n",
      "Role: General Manager/Solution Architect Presales and Solutioning\n",
      "\n",
      "Technical Skills – Energy & Utilities, Digital Transformation, Managed Services\n",
      "\n",
      " Presales solutioning and managing RFP bids for utilities domain – Bids contain cloud\n",
      " migrations, digital transformation initiatives, enterprise platform implementations and\n",
      " managed services\n",
      " Account mining for identifying proactive opportunities for existing customers\n",
      " Practice Management\n",
      " o Sales Collateral (white papers, blogs, marketing collaterals)\n",
      " o Value Propositions\n",
      " o Automation Opportunities\n",
      " People Management and competency development\n",
      ",Past: Honeywell July’2018 – Aug’2020\n",
      "\n",
      "Role: Digital Transformation CoE Leader\n",
      "\n",
      "Technical Skills – Enterprise Architecture, Cloud Platform (Microsoft Azure), Python, SaaS for\n",
      "Honeywell Forge solution suite (Data Lake, Asset Performance Management, Process Monitoring\n",
      "solutions, Data Analytics, Dashboard), Oil&Gas domain\n",
      "\n",
      " Industry 4.0 solutioning\n",
      " Solutioning and architecture vision, creating architecture blueprint and architecture\n",
      " strategy for digital transformation projects (IIOT, cloud, analytics)\n",
      " Provide Strategical advice and guidance to the Solution Architects and regional sales team.\n",
      " RFP and Presales support\n",
      " Engineering Delivery Management\n",
      " o Agile product development leading scrum teams and leading product backlog\n",
      " o Lead the digital engineering project deliveries and KPIs (Quality, schedule,\n",
      " productivity)\n",
      " Responsible for Cloud Operations and customer implementations for Honeywell Forge\n",
      " Platform (Microsoft Azure)\n",
      " Leading engineering team of size of 60+ members\n",
      " Global stakeholder management (managing EMEA, RNAM and APAC regional stakeholders)\n",
      "\n",
      "Past: Ericsson Oct’2010 –\n",
      "July’2018\n",
      "\n",
      "Role: Strategic Product Manager\n",
      "Technical Skills – Cloud Technologies (Microsoft Azure), Telecom OSS (Service Assurance and\n",
      "Fulfilment), Mobility Solutions for Field Services (MWFM)\n",
      "\n",
      " Solutioning and architecture vision, creating architecture blueprint and architecture\n",
      " strategy.\n",
      " Product Requirements & Strategy by leveraging market and customer analysis.\n",
      " Strategic Product roadmap for SD Tools (Product IT strategy, Roadmap planning &\n",
      " development)\n",
      " Agile product development leading scrum teams and leading product backlog\n",
      " Solutioning to evolve OSS platform to NFV/SDN (Network Cloud Platform) implementation\n",
      " strategy.\n",
      " Identify the products/solutions for NFV/SDN transformation and impact analysis for the\n",
      " Service Assurance and Fulfilment\n",
      " Customer and Business line interfacing for requirements management for existing and new\n",
      " services, planning the requirements in the roadmap, working with internal delivery teams\n",
      " and 3pp vendors for solution delivery.\n",
      " Customer and stakeholder relationship management and driver for managing their\n",
      " requirements.\n",
      " Enterprise Architecture evolution – As Is and To Be Analysis.\n",
      " Developed WFM practice from scratch (upto 60 members) and driven the competency\n",
      " development.\n",
      " Lead and mentor team for technical issues & operational stability of the cloud platform\n",
      "\n",
      "Past: Wipro Technologies June’ 2009 – Oct’ 2010\n",
      "Role: Consultant\n",
      "Technical skills – Field Service Management, Mobility Solutions, Asset Management, Energy &\n",
      "Utilities Domain\n",
      " Presales support (RFP proposals, Customer Demos)\n",
      " Requirement Management use case development – Writing Business and Product\n",
      " Requirements\n",
      " Solution Architecture & Design, Technical Architecture\n",
      " Deliver end to end transformation programmes for Mobile Workforce Management Projects\n",
      " Competency Development and primary driver for Centre of Excellence (CoE) team\n",
      " Consulting assignments for Mobile Workforce Management Solutions\n",
      " Business Development - Was responsible for tapping new business / assignments within\n",
      " existing accounts\n",
      "\n",
      "Past: Satyam Computers Oct’ 2008 – June’ 2009\n",
      "\n",
      "Role: Project Lead\n",
      "Technical skills – Presales, Project Management\n",
      "Technical skills – Project Management\n",
      ", Project Management\n",
      " Presales and solutioning support\n",
      "\n",
      "Past: Infosys Technologies Ltd Oct’ 2000 – Oct’ 2008\n",
      "\n",
      "Role: Programmer Analyst/Functional Lead\n",
      "Technical skills – Java, Field Service Management, Mobility Solutions, Oracle, SQL Server, Energy &\n",
      "Utilities Domain, Asset Management, Smart Metering Solutions\n",
      "\n",
      " Customer Requirement Management, use case development – Writing Business and\n",
      " Product Requirements\n",
      " Solution Architecture & Design, Technical Architecture\n",
      " Application Development, Testing, Deployment and Maintenance\n",
      " 3pp Product Configurations, Customizations and Deployment\n",
      " Technical leadership for the team\n",
      " Hands on experience in coding, product configurations, testing and operations support\n",
      " 4+ yrs. at onsite assignments (US) working closely with customers for end to end delivery\n",
      " of customer requirements through ofshore delivery model and onsite operations\n",
      " Project and delivery management for utilities customers\n",
      "\n",
      "Academic Credentials & Certifcations\n",
      "Bachelor of Engineering (Mechanical Engineering) from CET, Bhubaneswar, Orissa in 2000\n",
      "\n",
      "Pursuing Executive PG Diploma from IIIT B in Artificial Intelligence and Machine Learning (AI & ML)\n",
      "\n",
      "Certifcations – Important professional certifications completed\n",
      "Enterprise Architecture\n",
      " o Enterprise Architecture certification by Cordial Sweden\n",
      " o TOGAF Training/certification\n",
      "Technical\n",
      " o CLF-C01 - AWS Certified Cloud Practitioner\n",
      " o AI-900: Microsoft Azure AI Fundamentals\n",
      " o AZ-900: Microsoft Azure Fundamentals\n",
      " o Solution Architect Experienced from Ericsson\n",
      "Process\n",
      " o ITIL V3 Foundation, eTOM Process\n"
     ]
    }
   ],
   "source": [
    "rt = eval_df.sample()['resume'].values[0]\n",
    "rt = html.unescape(rt)\n",
    "print(rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "work_prompt = f'''\n",
    "You are an accurate agent working for a job platform. You will be given the raw \n",
    "unstructured text of a user's resume, and the task is to extract only the following details about the \n",
    "work experience of the user from the resume in a JSON style format: company name, designation, start date and the end date.\n",
    "Please provide the data in a concise and parseable JSON format. Ensure the JSON syntax is correct\n",
    "with proper use of double quotes, commas, and braces. Dates should be in \"mm/yyyy\" format\n",
    "\n",
    "This is the resume text:\\n{{resume_text}}\\n\n",
    "This is the output in the required_format:\\n\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "work_format = '''\n",
    "[\n",
    "    {\"company\":\"Example Company 1\",\n",
    "    \"role\":\"Example Role 1\",\n",
    "    \"start_date\":\"mm/yyyy\",\n",
    "    \"end_date\":\"mm/yyyy\"},\n",
    "    {\"company\":\"Example Company 2\",\n",
    "    \"role\":\"Example Role 2\",\"\n",
    "    start_date\":\"mm/yyyy\",\n",
    "    \"end_date\":\"mm/yyyy\"}\n",
    "]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_prompt = work_prompt.format(resume_text=rt,\n",
    "                  query_format=work_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1992"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_input['input_ids'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    full_document = tokenizer.decode(model.generate(**sample_input, max_new_tokens=1000)[0], skip_special_tokens=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are an accurate agent working for a job platform. You will be given the raw \n",
      "unstructured text of a user's resume, and the task is to extract only the following details about the \n",
      "work experience of the user from the resume in a JSON style format: company name, designation, start date and the end date.\n",
      "Please provide the data in a concise and parseable JSON format. Ensure the JSON syntax is correct\n",
      "with proper use of double quotes, commas, and braces. Dates should be in \"mm/yyyy\" format\n",
      "\n",
      "This is the resume text:\n",
      "Head Digital Solutions/Digital Transformation Leader\n",
      "Vijayasree Patnaik\n",
      "Email: vijayasreepatnaik1@gmail.com; Phone: +91 7410569056\n",
      "\n",
      "\n",
      "Career Highlights & Summary\n",
      "\n",
      " Overall 23+ years of experience in Solution Architecture, Presales, Product Management\n",
      " and Engineering delivery management for Enterprise solutions\n",
      " In depth experience in driving Digital transformation journey for Utilities, Oil&Gas and\n",
      " Telecom industries\n",
      " Digital transformation presales, solutioning and Program deliveries (cloud and analytics)\n",
      " Digital transformation presales, solutioning and project deliveries (ServiceNow and\n",
      " Salesforce enterprise platforms)\n",
      " Experience in Managed Services Delivery Platform for global customers (more than 200+\n",
      " customers). Managing global stakeholders\n",
      " Strategic product management experience working with business teams to develop IT\n",
      " strategy for new and existing services and automation opportunities\n",
      " Product lifecycle management experience (product roadmap, strategy, vendor\n",
      " management, delivery management, capacity planning and solution ownership)\n",
      " End-to-End experience in application lifecycle management, working closely with\n",
      " customers doing requirement analysis, use case development, solution architecture and\n",
      " project delivery\n",
      "\n",
      "Technical Skills\n",
      "\n",
      " Digital Transformation solutioning (Cloud, IIOT, analytics, Digital Utilities)\n",
      " Microsoft Azure Platform, GCP\n",
      " Domains – Oil&Gas, Manufacturing, Energy & Utilities, Telecom\n",
      " ServiceNow, Salesforce Platform experience\n",
      " AI & ML, Python\n",
      " Enterprise mobility solutions, Telecom OSS, NFV/SDN, Industry 4.0\n",
      "\n",
      "Professional Summary\n",
      "\n",
      "Current: Cyient Limited Dec’2021 – Till Date\n",
      "Role: Sr Director/Head Digital Aftermarket Services\n",
      "\n",
      "Technical Skills – Salesforce, ServiceNow, Analytics, Cloud Migration, FSM, Energy&Utilities, Python\n",
      "\n",
      " Industry 4.0 solutioning\n",
      " Solutioning and Program Delivery management for customers across Telecom, Utilities and\n",
      " manufacturing for digital services\n",
      " Building Digital Aftermarket Service solutions for customers across domains (Telecom NOC,\n",
      " Energy & Utilities, Manufacturing)\n",
      " Customer engagement and driving the customer satisfaction\n",
      " People Management\n",
      "\n",
      "\n",
      "Current: HCL Technologies Aug’2020 –\n",
      "Dec’2021\n",
      "Role: General Manager/Solution Architect Presales and Solutioning\n",
      "\n",
      "Technical Skills – Energy & Utilities, Digital Transformation, Managed Services\n",
      "\n",
      " Presales solutioning and managing RFP bids for utilities domain – Bids contain cloud\n",
      " migrations, digital transformation initiatives, enterprise platform implementations and\n",
      " managed services\n",
      " Account mining for identifying proactive opportunities for existing customers\n",
      " Practice Management\n",
      " o Sales Collateral (white papers, blogs, marketing collaterals)\n",
      " o Value Propositions\n",
      " o Automation Opportunities\n",
      " People Management and competency development\n",
      ",Past: Honeywell July’2018 – Aug’2020\n",
      "\n",
      "Role: Digital Transformation CoE Leader\n",
      "\n",
      "Technical Skills – Enterprise Architecture, Cloud Platform (Microsoft Azure), Python, SaaS for\n",
      "Honeywell Forge solution suite (Data Lake, Asset Performance Management, Process Monitoring\n",
      "solutions, Data Analytics, Dashboard), Oil&Gas domain\n",
      "\n",
      " Industry 4.0 solutioning\n",
      " Solutioning and architecture vision, creating architecture blueprint and architecture\n",
      " strategy for digital transformation projects (IIOT, cloud, analytics)\n",
      " Provide Strategical advice and guidance to the Solution Architects and regional sales team.\n",
      " RFP and Presales support\n",
      " Engineering Delivery Management\n",
      " o Agile product development leading scrum teams and leading product backlog\n",
      " o Lead the digital engineering project deliveries and KPIs (Quality, schedule,\n",
      " productivity)\n",
      " Responsible for Cloud Operations and customer implementations for Honeywell Forge\n",
      " Platform (Microsoft Azure)\n",
      " Leading engineering team of size of 60+ members\n",
      " Global stakeholder management (managing EMEA, RNAM and APAC regional stakeholders)\n",
      "\n",
      "Past: Ericsson Oct’2010 –\n",
      "July’2018\n",
      "\n",
      "Role: Strategic Product Manager\n",
      "Technical Skills – Cloud Technologies (Microsoft Azure), Telecom OSS (Service Assurance and\n",
      "Fulfilment), Mobility Solutions for Field Services (MWFM)\n",
      "\n",
      " Solutioning and architecture vision, creating architecture blueprint and architecture\n",
      " strategy.\n",
      " Product Requirements & Strategy by leveraging market and customer analysis.\n",
      " Strategic Product roadmap for SD Tools (Product IT strategy, Roadmap planning &\n",
      " development)\n",
      " Agile product development leading scrum teams and leading product backlog\n",
      " Solutioning to evolve OSS platform to NFV/SDN (Network Cloud Platform) implementation\n",
      " strategy.\n",
      " Identify the products/solutions for NFV/SDN transformation and impact analysis for the\n",
      " Service Assurance and Fulfilment\n",
      " Customer and Business line interfacing for requirements management for existing and new\n",
      " services, planning the requirements in the roadmap, working with internal delivery teams\n",
      " and 3pp vendors for solution delivery.\n",
      " Customer and stakeholder relationship management and driver for managing their\n",
      " requirements.\n",
      " Enterprise Architecture evolution – As Is and To Be Analysis.\n",
      " Developed WFM practice from scratch (upto 60 members) and driven the competency\n",
      " development.\n",
      " Lead and mentor team for technical issues & operational stability of the cloud platform\n",
      "\n",
      "Past: Wipro Technologies June’ 2009 – Oct’ 2010\n",
      "Role: Consultant\n",
      "Technical skills – Field Service Management, Mobility Solutions, Asset Management, Energy &\n",
      "Utilities Domain\n",
      " Presales support (RFP proposals, Customer Demos)\n",
      " Requirement Management use case development – Writing Business and Product\n",
      " Requirements\n",
      " Solution Architecture & Design, Technical Architecture\n",
      " Deliver end to end transformation programmes for Mobile Workforce Management Projects\n",
      " Competency Development and primary driver for Centre of Excellence (CoE) team\n",
      " Consulting assignments for Mobile Workforce Management Solutions\n",
      " Business Development - Was responsible for tapping new business / assignments within\n",
      " existing accounts\n",
      "\n",
      "Past: Satyam Computers Oct’ 2008 – June’ 2009\n",
      "\n",
      "Role: Project Lead\n",
      "Technical skills – Presales, Project Management\n",
      "Technical skills – Project Management\n",
      ", Project Management\n",
      " Presales and solutioning support\n",
      "\n",
      "Past: Infosys Technologies Ltd Oct’ 2000 – Oct’ 2008\n",
      "\n",
      "Role: Programmer Analyst/Functional Lead\n",
      "Technical skills – Java, Field Service Management, Mobility Solutions, Oracle, SQL Server, Energy &\n",
      "Utilities Domain, Asset Management, Smart Metering Solutions\n",
      "\n",
      " Customer Requirement Management, use case development – Writing Business and\n",
      " Product Requirements\n",
      " Solution Architecture & Design, Technical Architecture\n",
      " Application Development, Testing, Deployment and Maintenance\n",
      " 3pp Product Configurations, Customizations and Deployment\n",
      " Technical leadership for the team\n",
      " Hands on experience in coding, product configurations, testing and operations support\n",
      " 4+ yrs. at onsite assignments (US) working closely with customers for end to end delivery\n",
      " of customer requirements through ofshore delivery model and onsite operations\n",
      " Project and delivery management for utilities customers\n",
      "\n",
      "Academic Credentials & Certifcations\n",
      "Bachelor of Engineering (Mechanical Engineering) from CET, Bhubaneswar, Orissa in 2000\n",
      "\n",
      "Pursuing Executive PG Diploma from IIIT B in Artificial Intelligence and Machine Learning (AI & ML)\n",
      "\n",
      "Certifcations – Important professional certifications completed\n",
      "Enterprise Architecture\n",
      " o Enterprise Architecture certification by Cordial Sweden\n",
      " o TOGAF Training/certification\n",
      "Technical\n",
      " o CLF-C01 - AWS Certified Cloud Practitioner\n",
      " o AI-900: Microsoft Azure AI Fundamentals\n",
      " o AZ-900: Microsoft Azure Fundamentals\n",
      " o Solution Architect Experienced from Ericsson\n",
      "Process\n",
      " o ITIL V3 Foundation, eTOM Process\n",
      "\n",
      "This is the output in the required_format:\n",
      "\n",
      "[{'company': 'Cyient Limited', 'role': 'Sr Director/Head Digital Aftermarket Services', 'start_date': 'Dec 2021', 'end_date': 'Till Date'}, {'company': 'HCL Technologies', 'role': 'General Manager/Solution Architect Presales and Solutioning', 'start_date': 'Aug 2020', 'end_date': 'Dec 2021'}, {'company': 'Honeywell', 'role': 'Digital Transformation CoE Leader', 'start_date': 'Jul 2018', 'end_date': 'Aug 2020'}, {'company': 'Ericsson', 'role': 'Strategic Product Manager', 'start_date': 'Oct 2010', 'end_date': 'Jul 2018'}, {'company': 'Wipro Technologies', 'role': 'Consultant', 'start_date': 'Jun 2009', 'end_date': 'Oct 2010'}, {'company': 'Satyam Computers', 'role': 'Project Lead', 'start_date': 'Oct 2008', 'end_date': 'Jun 2009'}, {'company': 'Infosys Technologies Ltd', 'role': 'Programmer Analyst/Functional Lead', 'start_date': 'Oct 2000', 'end_date': 'Oct 2008'}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(full_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken :77.33337330818176\n"
     ]
    }
   ],
   "source": [
    "out_str = full_document.replace(eval_prompt,\"\")\n",
    "print(f'Time taken :{time.time()-start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "res = out_str.replace('\\n','')\n",
    "r = ast.literal_eval(res) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'company': 'Cyient Limited',\n",
       "  'role': 'Sr Director/Head Digital Aftermarket Services',\n",
       "  'start_date': 'Dec 2021',\n",
       "  'end_date': 'Till Date'},\n",
       " {'company': 'HCL Technologies',\n",
       "  'role': 'General Manager/Solution Architect Presales and Solutioning',\n",
       "  'start_date': 'Aug 2020',\n",
       "  'end_date': 'Dec 2021'},\n",
       " {'company': 'Honeywell',\n",
       "  'role': 'Digital Transformation CoE Leader',\n",
       "  'start_date': 'Jul 2018',\n",
       "  'end_date': 'Aug 2020'},\n",
       " {'company': 'Ericsson',\n",
       "  'role': 'Strategic Product Manager',\n",
       "  'start_date': 'Oct 2010',\n",
       "  'end_date': 'Jul 2018'},\n",
       " {'company': 'Wipro Technologies',\n",
       "  'role': 'Consultant',\n",
       "  'start_date': 'Jun 2009',\n",
       "  'end_date': 'Oct 2010'},\n",
       " {'company': 'Satyam Computers',\n",
       "  'role': 'Project Lead',\n",
       "  'start_date': 'Oct 2008',\n",
       "  'end_date': 'Jun 2009'},\n",
       " {'company': 'Infosys Technologies Ltd',\n",
       "  'role': 'Programmer Analyst/Functional Lead',\n",
       "  'start_date': 'Oct 2000',\n",
       "  'end_date': 'Oct 2008'}]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(json.dumps(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7ead75fc4f2453aab269120efe8103f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/134M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/lakshay/work-details-peft/commit/d5e9c31b246648708b2fa67814d3d9920ab1fdb0', commit_message='Upload model', commit_description='', oid='d5e9c31b246648708b2fa67814d3d9920ab1fdb0', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub('lakshay/work-details-peft',token='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Personal Information Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from string import Template\n",
    "pi_eval_prompt = Template('''You are a helpful language model working for a job platform. You will be given the raw \n",
    " unstructured text of a user's resume, and the task is to extract the personal information (name, phone number, email ID and the location) of the \n",
    " user from the raw text in the following format: \\n${pi_format}\\n\n",
    " If the information is not available, return 'NA'\n",
    " This is the resume text:\\n${resume_text}\\n\n",
    " This is the output in the required_format:\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pi_format = '''{\n",
    "    'personal_information': {'name': \"Name\",\n",
    "                         'email_id': \"Valid Email ID\",\n",
    "                         'phone_number': \"10 Digit phone number\",\n",
    "                         'location': \"User's current location\"}\n",
    "}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rt = eval_df.sample()['resume'].values[0]\n",
    "print(rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "eval_prompt = pi_eval_prompt.substitute(\n",
    "            pi_format=pi_format,\n",
    "            resume_text=rt)\n",
    "\n",
    "sample_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    full_document = tokenizer.decode(model.generate(**sample_input, max_new_tokens=200)[0], skip_special_tokens=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(full_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75804f0963d448fbb0e7ba1e1d423bba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/16.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/lakshay/llama2-test/commit/9460af41bdcca6c6b9cafac27d3ee09a4bd6c36a', commit_message='Upload model', commit_description='', oid='9460af41bdcca6c6b9cafac27d3ee09a4bd6c36a', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub('lakshay/llama2-test',token='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', max_shard_size='2GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PI validation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_data = pd.read_csv('custom_data/validation_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_data.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_data.resume.values[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "error_list = list()\n",
    "correct_list = list()\n",
    "\n",
    "for uid,rt in tqdm(validation_data[['id','resume']].sample(frac=1).values[:200]):\n",
    "\n",
    "    eval_prompt = pi_eval_prompt.substitute(\n",
    "                pi_format=pi_format,\n",
    "                resume_text=rt)\n",
    "\n",
    "    sample_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    try:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            full_document = tokenizer.decode(model.generate(**sample_input, max_new_tokens=200)[0], skip_special_tokens=True)\n",
    "    except:\n",
    "        print('feck')\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        out_str = full_document.replace(eval_prompt,'').replace('$','')\n",
    "        out_json = ast.literal_eval(out_str)\n",
    "        u_info = {}\n",
    "        u_info[uid] = out_json\n",
    "        correct_list.append(u_info)\n",
    "    except:\n",
    "        error_list.append(full_document)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# correct_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'hello there, $, yes'.replace('there,','').replace('$','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(correct_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct_list\n",
    "\n",
    "with open('custom_data/validation_output.pkl','wb') as f:\n",
    "    pickle.dump(correct_list,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65b66f79022e4d62b7980aaa0d6e8ae4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_config.json:   0%|          | 0.00/581 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "\n                        Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit\n                        the quantized model. If you want to dispatch the model on the CPU or the disk while keeping\n                        these modules in 32-bit, you need to set `load_in_8bit_fp32_cpu_offload=True` and pass a custom\n                        `device_map` to `from_pretrained`. Check\n                        https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu\n                        for more details.\n                        ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m model_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlakshay/llama2-test\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# tokenizer = LlamaTokenizer.from_pretrained(model_id)\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mLlamaForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_in_8bit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat16\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhf_rthVXJBMwUqJSEayJxkiKZtRSIwFLEVwot\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/modeling_utils.py:3646\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3642\u001b[0m         device_map_without_lm_head \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   3643\u001b[0m             key: device_map[key] \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m device_map\u001b[38;5;241m.\u001b[39mkeys() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m modules_to_not_convert\n\u001b[1;32m   3644\u001b[0m         }\n\u001b[1;32m   3645\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map_without_lm_head\u001b[38;5;241m.\u001b[39mvalues() \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisk\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map_without_lm_head\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[0;32m-> 3646\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3647\u001b[0m \u001b[38;5;250m                \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3648\u001b[0m \u001b[38;5;124;03m                Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit\u001b[39;00m\n\u001b[1;32m   3649\u001b[0m \u001b[38;5;124;03m                the quantized model. If you want to dispatch the model on the CPU or the disk while keeping\u001b[39;00m\n\u001b[1;32m   3650\u001b[0m \u001b[38;5;124;03m                these modules in 32-bit, you need to set `load_in_8bit_fp32_cpu_offload=True` and pass a custom\u001b[39;00m\n\u001b[1;32m   3651\u001b[0m \u001b[38;5;124;03m                `device_map` to `from_pretrained`. Check\u001b[39;00m\n\u001b[1;32m   3652\u001b[0m \u001b[38;5;124;03m                https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu\u001b[39;00m\n\u001b[1;32m   3653\u001b[0m \u001b[38;5;124;03m                for more details.\u001b[39;00m\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;124;03m                \"\"\"\u001b[39;00m\n\u001b[1;32m   3655\u001b[0m             )\n\u001b[1;32m   3656\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m device_map_without_lm_head\n\u001b[1;32m   3658\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m device_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: \n                        Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit\n                        the quantized model. If you want to dispatch the model on the CPU or the disk while keeping\n                        these modules in 32-bit, you need to set `load_in_8bit_fp32_cpu_offload=True` and pass a custom\n                        `device_map` to `from_pretrained`. Check\n                        https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu\n                        for more details.\n                        "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer\n",
    "\n",
    "model_id=\"lakshay/llama2-test\"\n",
    "\n",
    "# tokenizer = LlamaTokenizer.from_pretrained(model_id)\n",
    "\n",
    "model = LlamaForCausalLM.from_pretrained(model_id, load_in_8bit=True, device_map='auto', torch_dtype=torch.float16, token='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "2d58e898dde0263bc564c6968b04150abacfd33eed9b19aaa8e45c040360e146"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
