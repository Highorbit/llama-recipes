{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5e59bd2-d0a9-43c0-9961-f06f4ed2dff2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import json \n",
    "import gradio as gr\n",
    "from user_info import get_user_info\n",
    "import ast, html, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b51dc7-0b66-43d7-bda9-bc0b02bbbce6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f7c47a7-837e-467d-b0eb-cc183648e597",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sampling_params = SamplingParams(temperature=0, max_tokens=4096)\n",
    "# llm = LLM(model=\"lakshay/work-model\")\n",
    "\n",
    "# eval_df = pd.read_csv('custom_data/iimjobs_eval_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc92b8d-3376-4486-871d-72913beb9d8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156c678a-a37c-45c7-986f-399695532d05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448a405c-5e63-4280-aa03-fe64e32fdd4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f5436a-b7d1-44b6-b4da-0d78a1dd0ed7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d9624b96-05ca-43d9-a8f5-c67fa853f29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import re\n",
    "\n",
    "# def convert_to_json(input_string):\n",
    "#     # Replace single quotes at the start and end of keys and values with double quotes\n",
    "#     # This regex specifically targets the start of keys/values and the end of keys/values\n",
    "#     corrected_string = re.sub(r\"(\\{|\\,)\\s*\\'\", r'\\1 \"', input_string)  # Start of key/value\n",
    "#     corrected_string = re.sub(r\"\\'\\s*(\\,|\\})\", r'\" \\1', corrected_string)  # End of key/value\n",
    "#     corrected_string = re.sub(r\"\\'\\s*:\", r'\":', corrected_string)  # Key end\n",
    "#     corrected_string = re.sub(r\":\\s*\\'\", r': \"', corrected_string)  # Value start\n",
    "\n",
    "#     try:\n",
    "#         # Convert the string to a valid JSON\n",
    "#         valid_json = json.loads(corrected_string)\n",
    "#         return valid_json\n",
    "#     except json.JSONDecodeError as e:\n",
    "#         return input_string\n",
    "\n",
    "\n",
    "import json\n",
    "import re\n",
    "\n",
    "def convert_to_json(input_string):\n",
    "    # Replace single quotes at the start and end of keys and values with double quotes\n",
    "    # This regex specifically targets the start of keys/values and the end of keys/values\n",
    "    corrected_string = re.sub(r\"(\\{|\\,)\\s*\\'\", r'\\1 \"', input_string)  # Start of key/value\n",
    "    corrected_string = re.sub(r\"\\'\\s*(\\,|\\})\", r'\" \\1', corrected_string)  # End of key/value\n",
    "    corrected_string = re.sub(r\"\\'\\s*:\", r'\":', corrected_string)  # Key end\n",
    "    corrected_string = re.sub(r\":\\s*\\'\", r': \"', corrected_string)  # Value start\n",
    "\n",
    "    try:\n",
    "        # Convert the string to a valid JSON\n",
    "        valid_json = json.loads(corrected_string)\n",
    "        return valid_json\n",
    "    except json.JSONDecodeError as e:\n",
    "        return input_string\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "82f9d13b-278d-4b65-ba4f-3ef8484fb8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "eg_str = '''\n",
    " [{'company': 'Aditi Tech Consulting Pvt Ltd.', 'role': 'Specialist - People and Culture', 'start_date': 'June 22, 2023', 'end_date': 'Aug 23, 2023', 'description': 'In my previous role, I was a part of the People Department Team (HR), where my responsibilities centered around the entire employee life cycle, from onboarding to offboarding. During this role, I managed new hire orientation sessions, ensured compliance with statutory regulations through document handling, served as the Single Point of Contact (SPOC) for insurance-related matters, addressed HRMS queries encompassing attendance, leave, payroll, and expenses, handled employee grievances, facilitated new hire integration sessions, and conducted daily pulse checks to monitor and proactively address attrition concerns.'}, {'company': 'Health Vista India Pvt Ltd', 'role': 'Talent Acquisition Executive', 'start_date': 'March 22, 2022', 'end_date': 'June 22, 2022', 'description': 'I was responsible for managing sales and corporate hiring, which included B2B, B2C, dealer sales, and senior-level positions.'}, {'company': 'Dropkaffe Food and Beverages Pvt Ltd., Bangalore, Karnataka', 'role': 'Human Resource Executive: Brand SLAY COFFEE', 'start_date': 'Jan 20, 2022', 'end_date': 'Feb 22, 2022', 'description': 'As a member of the corporate team, I worked within a company with a workforce exceeding 350 employees spread across 14 different cities in India, with ongoing growth. I closely collaborated with the company's co-founders, actively contributing to the drafting and implementation of new policies and the development of various strategies aimed at achieving more target-oriented results.'}, {'company': 'Dropkaffe Food and Beverages Pvt Ltd., Bangalore, Karnataka', 'role': 'Human Resource Intern: Brand SLAY COFFEE', 'start_date': 'Oct 19, 2021', 'end_date': 'Dec 19, 2021', 'description': 'Worked on all levels of Recruitment and Hiring for Corporate as well as Unit Teams. Maintenance of attendance and leaves for all the employees, conducting inductions, and all exit formalities for an employee.'}, {'company': 'Lemon Tree Premier, Aerocity, New Delhi', 'role': 'Human Resource Intern: Lemon Tree Premier', 'start_date': 'June 18, 2021', 'end_date': 'Aug 18, 2021', 'description': 'Worked on my Academic Internship whilst pursuing my Post Graduation, roles and responsibilities included - Employee and Trainee joining formalities, Maintaining Employee details in database, Handling employee queries, and Compliance check. Maintaining employee leave records, Town Hall preparations, etc.'}, {'company': 'Concentrix India Pvt.Ltd, Gurgaon, Haryana', 'role': 'Customer Relations Executive, Client: Amazon.in and Amazon.UK', 'start_date': 'Dec 16, 2016', 'end_date': 'May 17, 2017', 'description': 'Was part of a CRM team for Amazon and was responsible for handling the customers of India and later the United Kingdom. The work was basically related to customer grievance handling and providing them support on their quarries.'}]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b22a72e7-6d2e-46b6-a3e8-3f1a2c302856",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = '''\n",
    "{'1005073': [{'company': 'MAHINDRA COMVIVA',\n",
    "   'role': 'IT Lead Engineer',\n",
    "   'start_date': 'Dec/2009',\n",
    "   'end_date': 'Oct/2015',\n",
    "   'description': 'Handled post development activities through extensive interaction with client. Overseeing new patch implementation and migration programs of products. Managing 23 clients through online (24*7) direct reports. Supervising daily/monthly reports/stats and monitoring.'},\n",
    "  {'company': 'Ericsson Global Services India Pvt. Ltd.',\n",
    "   'role': 'Senior Engineer',\n",
    "   'start_date': 'Nov/2015',\n",
    "   'end_date': 'Oct/2016',\n",
    "   'description': 'To work/lead efficiently on Ericssonâ€™s Wallet platform, which is part of Prepaid Systems (Intelligent Network CS5.0). Basic Knowledge of SDP/IN/AIR and CCN nodes.'},\n",
    "  {'company': 'Orange Business Services',\n",
    "   'role': 'Senior System Specialist',\n",
    "   'start_date': 'Nov/2016',\n",
    "   'end_date': 'present',\n",
    "   'description': 'Working as Project transition Lead for getting handover of various projects ( related to Systems, Network and Dev-ops ) from France and Spain to India. System and Network support is my core strength.'}],\n",
    " 'status': 1}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "629da50a-af6a-42ba-8506-863c6316f764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'company': 'Aditi Tech Consulting Pvt Ltd.',\n",
       "  'role': 'Specialist - People and Culture',\n",
       "  'start_date': 'June 22, 2023',\n",
       "  'end_date': 'Aug 23, 2023',\n",
       "  'description': 'In my previous role, I was a part of the People Department Team (HR), where my responsibilities centered around the entire employee life cycle, from onboarding to offboarding. During this role, I managed new hire orientation sessions, ensured compliance with statutory regulations through document handling, served as the Single Point of Contact (SPOC) for insurance-related matters, addressed HRMS queries encompassing attendance, leave, payroll, and expenses, handled employee grievances, facilitated new hire integration sessions, and conducted daily pulse checks to monitor and proactively address attrition concerns.'},\n",
       " {'company': 'Health Vista India Pvt Ltd',\n",
       "  'role': 'Talent Acquisition Executive',\n",
       "  'start_date': 'March 22, 2022',\n",
       "  'end_date': 'June 22, 2022',\n",
       "  'description': 'I was responsible for managing sales and corporate hiring, which included B2B, B2C, dealer sales, and senior-level positions.'},\n",
       " {'company': 'Dropkaffe Food and Beverages Pvt Ltd., Bangalore, Karnataka',\n",
       "  'role': 'Human Resource Executive: Brand SLAY COFFEE',\n",
       "  'start_date': 'Jan 20, 2022',\n",
       "  'end_date': 'Feb 22, 2022',\n",
       "  'description': \"As a member of the corporate team, I worked within a company with a workforce exceeding 350 employees spread across 14 different cities in India, with ongoing growth. I closely collaborated with the company's co-founders, actively contributing to the drafting and implementation of new policies and the development of various strategies aimed at achieving more target-oriented results.\"},\n",
       " {'company': 'Dropkaffe Food and Beverages Pvt Ltd., Bangalore, Karnataka',\n",
       "  'role': 'Human Resource Intern: Brand SLAY COFFEE',\n",
       "  'start_date': 'Oct 19, 2021',\n",
       "  'end_date': 'Dec 19, 2021',\n",
       "  'description': 'Worked on all levels of Recruitment and Hiring for Corporate as well as Unit Teams. Maintenance of attendance and leaves for all the employees, conducting inductions, and all exit formalities for an employee.'},\n",
       " {'company': 'Lemon Tree Premier, Aerocity, New Delhi',\n",
       "  'role': 'Human Resource Intern: Lemon Tree Premier',\n",
       "  'start_date': 'June 18, 2021',\n",
       "  'end_date': 'Aug 18, 2021',\n",
       "  'description': 'Worked on my Academic Internship whilst pursuing my Post Graduation, roles and responsibilities included - Employee and Trainee joining formalities, Maintaining Employee details in database, Handling employee queries, and Compliance check. Maintaining employee leave records, Town Hall preparations, etc.'},\n",
       " {'company': 'Concentrix India Pvt.Ltd, Gurgaon, Haryana',\n",
       "  'role': 'Customer Relations Executive, Client: Amazon.in and Amazon.UK',\n",
       "  'start_date': 'Dec 16, 2016',\n",
       "  'end_date': 'May 17, 2017',\n",
       "  'description': 'Was part of a CRM team for Amazon and was responsible for handling the customers of India and later the United Kingdom. The work was basically related to customer grievance handling and providing them support on their quarries.'}]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_to_json(eg_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032098d1-dd6d-4543-91c4-45ca457a2e8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac918bab-3e42-409c-a9f3-1cb8f30e5fc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7ad448-2e2d-40af-845a-65e238364c3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4a69d0ea-da0c-4757-abbc-f29c87d0aace",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting property name enclosed in double quotes: line 2 column 4 (char 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m/usr/lib/python3.10/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m/usr/lib/python3.10/json/decoder.py:353\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;124;03ma JSON document) and return a 2-tuple of the Python\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;124;03mrepresentation and the index in ``s`` where the document ended.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    350\u001b[0m \n\u001b[1;32m    351\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscan_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting property name enclosed in double quotes: line 2 column 4 (char 4)"
     ]
    }
   ],
   "source": [
    "json.loads(es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a704b3-4a05-413a-ad1c-c403e181cfee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb5aecb-eb55-495e-a675-3af2042eb442",
   "metadata": {},
   "outputs": [],
   "source": [
    "4458"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90becbd-ebae-42f2-9961-0d20cc303b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "28101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59e709f8-90cf-416f-af8d-2f75f42aec5e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7863\n",
      "Running on public URL: https://83464f0987f50e4c88.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://83464f0987f50e4c88.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:09<00:00,  9.52s/it]\n",
      "Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:05<00:00,  5.37s/it]\n"
     ]
    }
   ],
   "source": [
    "def make_eval_prompt(raw_text):\n",
    "    \n",
    "    work_format = '''{\n",
    "        \"work_experience\": [{\"company\": \"company Name 1\",\n",
    "        \"role\": \"job designation 1\",\n",
    "        \"start_date\": \"mm/yyyy\",\n",
    "        \"end_date\": \"mm/yyyy\",\n",
    "        \"description\": \"complete Job description taken from resume\"},\n",
    "        {\"company\": \"company name 2\",\n",
    "        \"role\": \"job designation 2\",\n",
    "        \"start_date\": \"mm/yyyy\",\n",
    "        \"end_date\": \"mm/yyyy\",\n",
    "        \"description\": \"complete Job description taken from resume\"}]\n",
    "    }'''\n",
    "    \n",
    "    eval_prompt = f'''\n",
    "    You are a helpful language model working for a job platform. You will be given the raw \n",
    "     unstructured text of a user's resume, and the task is to extract the work experience of the \n",
    "     user from the raw text in the following format as a properly formatted JSON which can be\n",
    "     properly parsed. ONLY use double quotes while generating the output JSON : \\n{{work_format}}\\n.\n",
    "    \n",
    "     This is the resume text:\\n{{resume_text}}\\n\n",
    "     This is the output in the required format:\\n\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    eval_prompt = eval_prompt.format(work_format=work_format,\n",
    "                                     resume_text=raw_text)\n",
    "\n",
    "    return eval_prompt\n",
    "\n",
    "\n",
    "def get_response_from_model(user_id):\n",
    "\n",
    "    es_output = get_user_info(user_id)\n",
    "    resume_text = es_output['resume'][0]\n",
    "    if resume_text:\n",
    "        eval_prompt = make_eval_prompt(resume_text)\n",
    "    \n",
    "    outputs = llm.generate(eval_prompt, sampling_params)\n",
    "    out_text = outputs[0].outputs[0].text\n",
    "    ot = html.unescape(out_text)\n",
    "    generated_text = ot\n",
    "    # generated_text = convert_to_valid_json(out_text)\n",
    "    \n",
    "    try:\n",
    "        out_json = ast.literal_eval(generated_text)\n",
    "        return json.dumps(out_json,indent=4)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'couldnt make a dataframe {e}')\n",
    "        return generated_text\n",
    "\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=get_response_from_model,\n",
    "    inputs=[\"text\"],\n",
    "    outputs=[\"text\"],\n",
    ")\n",
    "\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b712573a-2d35-462e-9232-36b6715f02a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a14a49-1d2a-4a32-b6bf-071bef61bd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "2159599"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9777b1fc-19b9-4891-aae9-04a179ee8420",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_string = re.sub(r'(?<!\")(\\b\\w+\\b)(?!\"):', r'\"\\1\":', json_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1393e29f-c11b-4972-ad30-af944c451182",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import LlamaForCausalLM, LlamaTokenizer\n",
    "\n",
    "model_id=\"meta-llama/Llama-2-7b-chat-hf\"\n",
    "tokenizer = LlamaTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45bfa0b7-d161-4b81-a788-ee0f4c9b147a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_df = pd.read_csv('custom_data/iimjobs_eval_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b54e02c-2584-46de-89fa-4dd9ddd998df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e62e081-fdfb-4ff5-be85-d66cb713d5db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTACT\n",
      "PHONE:\n",
      "+91 8600026139\n",
      "EMAIL:\n",
      "amrutashamraj@gmail.com\n",
      "Linked In:\n",
      "https://www.linkedin.com/in/amruta-\n",
      "shamraj-99a69417\n",
      "WORK ASSOCIATION\n",
      "Fiserv India Private Ltd [Jun 2018 till\n",
      "date]\n",
      "Sr Manager HR\n",
      "Tata Consultancy Services [Dec\n",
      "2009 -Jun 2018]\n",
      "Assistant Manager- HR Generalist [Mar\n",
      "2016- Jun 2018]\n",
      "Specialist  Talent Offboarding [Mar\n",
      "2015  Mar 2016]\n",
      "Specialist  Talent Integration [Jan 2012\n",
      " Mar 2015]\n",
      "Executive  HR Generalist [Dec 2009 \n",
      "Jan 2012]\n",
      "AMRUTA SHAMRAJ\n",
      "HumanResourceProfessional\n",
      "PROFILE OVERVIEW\n",
      "13 Years of experience in managing workforce in Matrix and Global\n",
      "organizations overseeing End to End Employee Lifecycle |HR Business\n",
      "Partnering | Talent Engagement | ER |HR Program Management |\n",
      "Change &amp; Transformation Enablement | Entity Harmonization |\n",
      "Performance Management | Organizational Development | Leadership\n",
      "Enabler\n",
      "EXPERIENCE\n",
      "HR Business Partner\n",
      " Design and execute talent Charter for the business group\n",
      " Diagnose, scope, develop and execute initiatives that aid in\n",
      "forwarding the business strategy and mitigate identified risks\n",
      " Coach/advise/draw data insights/ influence / collaborate with\n",
      "senior leaders to advance talent strategy\n",
      " Talent Reviews, Promotions &amp; strategic hiring of senior leadership\n",
      " Influence &amp; deploy practices to increase employee\n",
      "engagement and experience\n",
      " Manage Spans &amp; Layers for management efficiencies\n",
      " Ensuring Job Architecture alignments\n",
      " New Talent Integration across levels\n",
      " Manage Workforce ramp up &amp; ramp downs\n",
      " Leverage and build people data analytics to aid sound decision\n",
      "making\n",
      " Drive local chapters of employee resource group to align with\n",
      "org D&amp;I strategy\n",
      " Use talent management tools to effectively weave D&amp;I principles\n",
      "into the fabric of the organization.\n",
      " Train and sensitive managers on engaging and nurturing a\n",
      "diverse employee\n",
      " Collaboration with Talent Acquisition, L&amp;D teams, Total Rewards,\n",
      "HR Operations to drive holistic HR agenda\n",
      "Change &amp; Transformation Enablement\n",
      " Managing Structural Interventions post M&amp;A\n",
      " Entity Harmonization  Collaboration with corporate groups for\n",
      "Policy &amp; Process benchmarking, compensation benchmarking\n",
      " Drive Policy &amp; Benefits harmonization\n",
      " Driving Engagement, Integration, Cultural assimilation\n",
      " Partner with corporate teams to design and execute\n",
      "communication strategy to aid seamless transformation for\n",
      "various change management initiatives\n",
      " Assist &amp; drive the strategic initiatives concerning headcount,\n",
      "locations strategies &amp; rationalization\n",
      "&quot;,&quot;EDUCATION\n",
      "Master in Business Administration\n",
      "Department of Management\n",
      "Sciences, Savitribai Phule Pune\n",
      "University\n",
      "[2007 -2009]\n",
      "BE Instrumentation Engineering\n",
      "Swami Ramanand Tirth Marathwada\n",
      "University, Nanded\n",
      "[2002- 2006]\n",
      "ACCOLADES\n",
      "Winner of @ Our Best Annual Award\n",
      "2021 for Fiserv India Pvt Ltd - For Entity\n",
      "Harmonization efforts &amp; change\n",
      "management\n",
      "Winner of Special Recognition 2020\n",
      "from Fiserv India Leadership  for\n",
      "leading Elevate Associate\n",
      "Engagement pan India Location and\n",
      "creating deeper connect &amp; sense of\n",
      "belonging with associates\n",
      "Winner of Living Proof award by Fiserv\n",
      "Leadership 2019  in recognition of\n",
      "efforts done for driving strategic\n",
      "initiatives creating Organizational\n",
      "Effectiveness\n",
      "Special Recognition Award 2011\n",
      "from Tata Consultancy Services senior\n",
      "leadership for Creating &amp; Driving\n",
      "Organization wide initiatives on\n",
      "Business Ethics and Code of Conduct\n",
      "Organizational Development &amp; Talent Transformation\n",
      " Collaborate with leaders to create efficient Organizational\n",
      "Design\n",
      " Conduct annual Talent Reviews for leadership roles\n",
      " Facilitate Succession Planning for leadership roles and critical\n",
      "talent\n",
      " Collaborate with leaders for creation and execution of Talent\n",
      "Development roadmaps as an outcome of Talent reviews and\n",
      "Succession planning\n",
      "Program Management\n",
      " Ideate, design and drive end to end strategic HR programs to\n",
      "improve associate engagement across locations\n",
      " Worked with cross functional, cross locational teams for\n",
      "execution of project that have org wide impact such as Annual\n",
      "Recognition Awards, Entity Integration, other Engagement\n",
      "initiatives\n",
      " Project Status tracking, Timeline adherence, timely\n",
      "communication, and closures\n",
      " Ideate, design &amp; execute program such as Predictive Attrition\n",
      "Management &amp; retention strategies\n",
      "Performance &amp; Rewards Management\n",
      " Drive impactful annual and mid-year performance\n",
      "management process &amp; outcome calibrations at leadership\n",
      "level\n",
      " Managing Annual Merit, Incentive cycles to promote High\n",
      "Performance culture\n",
      " Nurture &amp; promote continuous feedback/conversations\n",
      " Worked with Compensation Partners to execute all Total rewards\n",
      "related initiatives, communications &amp; change management\n",
      " Promote Associate career development planning across levels\n",
      " Effectively design &amp; deploy existing (performance management\n",
      "etc) and new programs (Rewards &amp; Recognition, promotions\n",
      "etc) to nurture a highly engaged environment\n",
      "Employee Relations\n",
      " Provide counsel and guidance for complex employee\n",
      " matters.\n",
      " Act as a trusted partner and lead investigations, difficult\n",
      " conversations, alertline cases and grievances.\n",
      " Anti-Workplace harassment practices - set up, implementation\n",
      "and governance.\n",
      " Worked with Legal and Compliance team on special projects to\n",
      "create guideline, policies for process improvements\n",
      "Employee Well Being\n",
      " To advocate and drive various pandemic response programs to\n",
      "promote employee well-being.\n",
      "Talent Integration &amp; Offboarding\n",
      " Design &amp; Deploy strategy to meet Organizations talent demand\n",
      "&amp; Onboarding target\n",
      "&quot;,&quot; Attracting talent and adhering to high - offer to joiner conversion\n",
      "ratio\n",
      " Track and manage new joiner Integration process for initial\n",
      "defined timelines\n",
      " Managing onboarding process, Induction and employee\n",
      "documentation compliances\n",
      " Managing offboarding process, activities &amp; compliances for the\n",
      "location.\n",
      "&quot;,&quot;\n"
     ]
    }
   ],
   "source": [
    "rt = eval_df.sample()['resume'].values[0]\n",
    "print(rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14f1df32-f2a2-4efd-b427-0e49389925a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "work_format = '''{\n",
    "    'work_experience': [{'company': 'company Name 1',\n",
    "                         'role': 'job designation 1',\n",
    "                         'start_date': 'mm/yyyy',\n",
    "                         'end_date': 'mm/yyyy',\n",
    "                         'description': 'complete Job description taken from resume'},\n",
    "                        {'company': 'company name 2',\n",
    "                         'role': 'job designation 2',\n",
    "                         'start_date': mm/yyyy',\n",
    "                         'end_date': 'mm/yyyy',\n",
    "                         'description': 'complete Job description taken from resume'}]\n",
    "}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "251cfd05-ddd7-416f-92ec-1649da76dd87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_prompt = f'''\n",
    "You are a helpful language model working for a job platform. You will be given the raw \n",
    " unstructured text of a user's resume, and the task is to extract the work experience of the \n",
    " user from the raw text in the following format: \\n{{work_format}}\\n\n",
    "\n",
    " This is the resume text:\\n{{resume_text}}\\n\n",
    " This is the output in the required format:\\n\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f402be7-4546-4784-a3db-e4ab26ee9344",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "eval_prompt = eval_prompt.format(\n",
    "            work_format=work_format,\n",
    "            resume_text=rt)\n",
    "\n",
    "sample_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5a39a5-6649-40c5-8d81-2d3030ed5cca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa2b5eae-9924-4e1f-90d3-9d854b0569d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/ubuntu/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "from transformers import LlamaTokenizer\n",
    "login(token='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')\n",
    "\n",
    "def work_experience_parsing(resume_text):\n",
    "    \n",
    "\n",
    "    model_id=\"meta-llama/Llama-2-7b-chat-hf\"\n",
    "    tokenizer = LlamaTokenizer.from_pretrained(model_id)\n",
    "    \n",
    "    work_format = '''{\n",
    "        'work_experience': [{'company': 'company Name 1',\n",
    "                             'role': 'job designation 1',\n",
    "                             'start_date': 'mm/yyyy',\n",
    "                             'end_date': 'mm/yyyy',\n",
    "                             'description': 'complete Job description taken from resume'},\n",
    "                            {'company': 'company name 2',\n",
    "                             'role': 'job designation 2',\n",
    "                             'start_date': mm/yyyy',\n",
    "                             'end_date': 'mm/yyyy',\n",
    "                             'description': 'complete Job description taken from resume'}]\n",
    "    }'''\n",
    "    \n",
    "    eval_prompt = f'''\n",
    "    You are a helpful language model working for a job platform. You will be given the raw \n",
    "     unstructured text of a user's resume, and the task is to extract the work experience of the \n",
    "     user from the raw text in the following format: \\n{{work_format}}\\n\n",
    "    \n",
    "     This is the resume text:\\n{{resume_text}}\\n\n",
    "     This is the output in the required format:\\n\n",
    "    '''\n",
    "    \n",
    "    sample_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e06b260-2499-4fe5-a9fb-cac18a95fb3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7f18a05-016b-4249-8130-6d9661e2ac46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sample_input['input_ids'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd033a6d-dc6b-4e23-8f65-3ee97785be45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "670a0cac-a249-4bbb-b022-6db45c0b2033",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 01-08 13:22:17 llm_engine.py:73] Initializing an LLM engine with config: model='lakshay/work-model', tokenizer='lakshay/work-model', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=1, quantization=None, enforce_eager=False, seed=0)\n",
      "INFO 01-08 13:22:28 llm_engine.py:223] # GPU blocks: 814, # CPU blocks: 512\n",
      "INFO 01-08 13:22:31 model_runner.py:394] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 01-08 13:22:37 model_runner.py:437] Graph capturing finished in 6 secs.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sampling_params = SamplingParams(temperature=0, max_tokens=4096)\n",
    "llm = LLM(model=\"lakshay/work-model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706cc0b6-6dc1-42c2-a9d8-b0be28c1bd73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4799065a-f8ea-42d3-b49f-ca174a044d59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b907c9-4c4c-45ac-b448-0d71881596bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3dbb839-2078-4466-a734-ff0797386277",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.45s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "outputs = llm.generate(eval_prompt, sampling_params)\n",
    "\n",
    "# with open('custom_data/vllm_test.txt','w') as f:\n",
    "#     f.write(str(outputs))\n",
    "    \n",
    "generated_text = outputs[0].outputs[0].text\n",
    "# for output in outputs:\n",
    "#     # prompt = output.prompt\n",
    "#     generated_text = output.outputs[0].text\n",
    "#     print(f\"Prompt: {eval_prompt!r}, Generated text: {generated_text!r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0f4c55-4ef1-4d11-9add-230aae623868",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0cc545-896a-416a-ae84-fb2311555053",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5016fdd-ad9c-4db9-8bf4-4074e9991104",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7685a534-19bc-4685-99ce-f3c599bb6baf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'company': 'Fiserv India Private Ltd', 'role': 'Sr Manager HR', 'start_date': 'Jun 2018', 'end_date': 'Present', 'description': 'Design and execute talent Charter for the business group. Diagnose, scope, develop and execute initiatives that aid in forwarding the business strategy and mitigate identified risks. Coach/advise/draw data insights/ influence / collaborate with senior leaders to advance talent strategy. Talent Reviews, Promotions & strategic hiring of senior leadership. Influence & deploy practices to increase employee engagement and experience. Manage Spans & Layers for management efficiencies. Ensuring Job Architecture alignments. New Talent Integration across levels. Manage Workforce ramp up & ramp downs. Leverage and build people data analytics to aid sound decision making. Drive local chapters of employee resource group to align with org D&I strategy. Use talent management tools to effectively weave D&I principles into the fabric of the organization. Train and sensitive managers on engaging and nurturing a diverse employee. Collaboration with Talent Acquisition, L&D teams, Total Rewards, HR Operations to drive holistic HR agenda.'}, {'company': 'Tata Consultancy Services', 'role': 'Assistant Manager- HR Generalist', 'start_date': 'Mar 2016', 'end_date': 'Jun 2018', 'description': 'Specialist  Talent Offboarding. Specialist  Talent Integration. Executive  HR Generalist.'}, {'company': 'Tata Consultancy Services', 'role': 'Specialist  Talent Integration', 'start_date': 'Jan 2012', 'end_date': 'Mar 2016', 'description': 'Specialist  Talent Integration. Influence & deploy practices to increase employee engagement and experience. Manage Spans & Layers for management efficiencies. Ensuring Job Architecture alignments. New Talent Integration across levels. Manage Workforce ramp up & ramp downs.'}, {'company': 'Tata Consultancy Services', 'role': 'Executive  HR Generalist', 'start_date': 'Dec 2009', 'end_date': 'Jan 2012', 'description': 'Influence & deploy practices to increase employee engagement and experience. Manage Spans & Layers for management efficiencies. Ensuring Job Architecture alignments. New Talent Integration across levels. Manage Workforce ramp up & ramp downs.'}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5dfc6c7e-f3cc-4ac4-b884-47dae76c48cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e42c8386-a4ca-4978-b59f-1439f91f8072",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'company': 'Fiserv India Private Ltd',\n",
       "  'role': 'Sr Manager HR',\n",
       "  'start_date': 'Jun 2018',\n",
       "  'end_date': 'Present',\n",
       "  'description': 'Design and execute talent Charter for the business group. Diagnose, scope, develop and execute initiatives that aid in forwarding the business strategy and mitigate identified risks. Coach/advise/draw data insights/ influence / collaborate with senior leaders to advance talent strategy. Talent Reviews, Promotions & strategic hiring of senior leadership. Influence & deploy practices to increase employee engagement and experience. Manage Spans & Layers for management efficiencies. Ensuring Job Architecture alignments. New Talent Integration across levels. Manage Workforce ramp up & ramp downs. Leverage and build people data analytics to aid sound decision making. Drive local chapters of employee resource group to align with org D&I strategy. Use talent management tools to effectively weave D&I principles into the fabric of the organization. Train and sensitive managers on engaging and nurturing a diverse employee. Collaboration with Talent Acquisition, L&D teams, Total Rewards, HR Operations to drive holistic HR agenda.'},\n",
       " {'company': 'Tata Consultancy Services',\n",
       "  'role': 'Assistant Manager- HR Generalist',\n",
       "  'start_date': 'Mar 2016',\n",
       "  'end_date': 'Jun 2018',\n",
       "  'description': 'Specialist  Talent Offboarding. Specialist  Talent Integration. Executive  HR Generalist.'},\n",
       " {'company': 'Tata Consultancy Services',\n",
       "  'role': 'Specialist  Talent Integration',\n",
       "  'start_date': 'Jan 2012',\n",
       "  'end_date': 'Mar 2016',\n",
       "  'description': 'Specialist  Talent Integration. Influence & deploy practices to increase employee engagement and experience. Manage Spans & Layers for management efficiencies. Ensuring Job Architecture alignments. New Talent Integration across levels. Manage Workforce ramp up & ramp downs.'},\n",
       " {'company': 'Tata Consultancy Services',\n",
       "  'role': 'Executive  HR Generalist',\n",
       "  'start_date': 'Dec 2009',\n",
       "  'end_date': 'Jan 2012',\n",
       "  'description': 'Influence & deploy practices to increase employee engagement and experience. Manage Spans & Layers for management efficiencies. Ensuring Job Architecture alignments. New Talent Integration across levels. Manage Workforce ramp up & ramp downs.'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ast.literal_eval(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c15f5d-0616-4b88-9994-7a0be73907d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
